{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pennylane as qml\n",
    "\n",
    "import math\n",
    "\n",
    "from pennylane.optimize import AdamOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Variables for the PDE\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m num_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEnter the number of variables for the PDE: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m all_variable_orders \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      4\u001b[0m all_variable_coefficients \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "\n",
    "# Variables for the PDE\n",
    "num_variables = int(input(\"Enter the number of variables for the PDE: \"))\n",
    "all_variable_orders = []\n",
    "all_variable_coefficients = []\n",
    "variable_names = []\n",
    "variable_indices = []\n",
    "variable_values = {}\n",
    "\n",
    "# varible names, their order of differentiation, and coefficients of those variables's derivatives\n",
    "for i in range(num_variables):\n",
    "    variable_name = input(f\"Enter the name for variable {i + 1}: \")\n",
    "    variable_names.append(variable_name)\n",
    "    variable_indices.append(i)\n",
    "    num_orders = int(input(f\"Enter the number of derivatives for variable {variable_name}: \"))\n",
    "    orders = []\n",
    "    coefficients = []\n",
    "\n",
    "    print(f\"Variable: {variable_name}\")\n",
    "    for j in range(num_orders):\n",
    "        order = int(input(f\"Enter the order for derivative {j + 1} with respect to {variable_name}: \"))\n",
    "        coefficient = input(f\"Enter the coefficient for derivative {j + 1} with respect to {variable_name} (as a function of {variable_name}): \")\n",
    "        orders.append(order)\n",
    "        coefficients.append(coefficient)\n",
    "\n",
    "    # To get the range values of variables\n",
    "    low_value = float(input(f\"Enter the low value for variable {variable_name}: \"))\n",
    "    high_value = float(input(f\"Enter the high value for variable {variable_name}: \"))\n",
    "    # Discretizing the range with certain step size value\n",
    "    step_size = float(input(f\"Enter the step size for generating random numbers for variable {variable_name}: \"))\n",
    "\n",
    "    random_values = np.linspace(low_value, high_value, int((high_value - low_value) / step_size) + 1)\n",
    "    print(f\"Values for {variable_name}:\")\n",
    "    for value in random_values:\n",
    "        print(value)\n",
    "\n",
    "    all_variable_orders.append(orders)\n",
    "    all_variable_coefficients.append(coefficients)\n",
    "    variable_values[variable_name] = random_values.tolist()  \n",
    "\n",
    "# Collect terms that are not derivatives in the PDE(e.g., u**2, sin(u), u, etc....)\n",
    "non_derivative_terms = []\n",
    "add_non_derivative_terms = input(\"Are there any non-derivative terms? type (yes/no): \").strip().lower()\n",
    "\n",
    "while add_non_derivative_terms == \"yes\":\n",
    "    term = input(\"Enter the non-derivative term : \")\n",
    "    non_derivative_terms.append(term)\n",
    "    add_non_derivative_terms = input(\"Is there any more non-derivative terms? (yes/no): \").strip().lower()\n",
    "\n",
    "# To print all info;\n",
    "print(\"Variable Names:\", variable_names)\n",
    "print(\"Variable Values:\", variable_values)\n",
    "print(\"Variable Orders:\", all_variable_orders)\n",
    "print(\"Variable Coefficients:\", all_variable_coefficients)\n",
    "print(\"Non-Derivative Terms:\", non_derivative_terms)\n",
    "\n",
    "# To construct the PDE expression\n",
    "def construct_pde_expression(variable_names, all_variable_orders, all_variable_coefficients, non_derivative_terms):\n",
    "    pde_expression = \"\"\n",
    "    \n",
    "    for i, (variable_name, orders, coefficients) in enumerate(zip(variable_names, all_variable_orders, all_variable_coefficients)):\n",
    "        for order, coeff in zip(orders, coefficients):\n",
    "            if \"lambda\" in coeff:  \n",
    "                term = f\"{coeff}*d^{order}u/d{variable_name}^{order}\"\n",
    "            else:\n",
    "                term = f\"{coeff}*d^{order}u/d{variable_name}^{order}\"\n",
    "            pde_expression += term + \" + \"\n",
    "\n",
    "    \n",
    "    for term in non_derivative_terms:\n",
    "        pde_expression += term + \" + \"\n",
    "    pde_expression = pde_expression[:-3] \n",
    "    return pde_expression\n",
    "\n",
    "\n",
    "pde_expression = construct_pde_expression(variable_names, all_variable_orders, all_variable_coefficients, non_derivative_terms)\n",
    "print(\"Constructed PDE:\", pde_expression)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = [0.0, 0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009000000000000001, 0.01, 0.011, 0.012, 0.013000000000000001, 0.014, 0.015, 0.016, 0.017, 0.018000000000000002, 0.019, 0.02, 0.021, 0.022, 0.023, 0.024, 0.025, 0.026000000000000002, 0.027, 0.028, 0.029, 0.03, 0.031, 0.032, 0.033, 0.034, 0.035, 0.036000000000000004, 0.037, 0.038, 0.039, 0.04, 0.041, 0.042, 0.043000000000000003, 0.044, 0.045, 0.046, 0.047, 0.048, 0.049, 0.05, 0.051000000000000004, 0.052000000000000005, 0.053, 0.054, 0.055, 0.056, 0.057, 0.058, 0.059000000000000004, 0.06, 0.061, 0.062, 0.063, 0.064, 0.065, 0.066, 0.067, 0.068, 0.069, 0.07, 0.07100000000000001, 0.07200000000000001, 0.073, 0.074, 0.075, 0.076, 0.077, 0.078, 0.079, 0.08, 0.081, 0.082, 0.083, 0.084, 0.085, 0.08600000000000001, 0.08700000000000001, 0.088, 0.089, 0.09, 0.091, 0.092, 0.093, 0.094, 0.095, 0.096, 0.097, 0.098, 0.099, 0.1, 0.101, 0.10200000000000001, 0.10300000000000001, 0.10400000000000001, 0.105, 0.106, 0.107, 0.108, 0.109, 0.11, 0.111, 0.112, 0.113, 0.114, 0.115, 0.116, 0.117, 0.11800000000000001, 0.11900000000000001, 0.12, 0.121, 0.122, 0.123, 0.124, 0.125, 0.126, 0.127, 0.128, 0.129, 0.13, 0.131, 0.132, 0.133, 0.134, 0.135, 0.136, 0.137, 0.138, 0.139, 0.14, 0.14100000000000001, 0.14200000000000002, 0.14300000000000002, 0.14400000000000002, 0.145, 0.146, 0.147, 0.148, 0.149, 0.15, 0.151, 0.152, 0.153, 0.154, 0.155, 0.156, 0.157, 0.158, 0.159, 0.16, 0.161, 0.162, 0.163, 0.164, 0.165, 0.166, 0.167, 0.168, 0.169, 0.17, 0.171, 0.17200000000000001, 0.17300000000000001, 0.17400000000000002, 0.17500000000000002, 0.176, 0.177, 0.178, 0.179, 0.18, 0.181, 0.182, 0.183, 0.184, 0.185, 0.186, 0.187, 0.188, 0.189, 0.19, 0.191, 0.192, 0.193, 0.194, 0.195, 0.196, 0.197, 0.198, 0.199, 0.2, 0.201, 0.202, 0.203, 0.20400000000000001, 0.20500000000000002, 0.20600000000000002, 0.20700000000000002, 0.20800000000000002, 0.209, 0.21, 0.211, 0.212, 0.213, 0.214, 0.215, 0.216, 0.217, 0.218, 0.219, 0.22, 0.221, 0.222, 0.223, 0.224, 0.225, 0.226, 0.227, 0.228, 0.229, 0.23, 0.231, 0.232, 0.233, 0.234, 0.23500000000000001, 0.23600000000000002, 0.23700000000000002, 0.23800000000000002, 0.23900000000000002, 0.24, 0.241, 0.242, 0.243, 0.244, 0.245, 0.246, 0.247, 0.248, 0.249, 0.25, 0.251, 0.252, 0.253, 0.254, 0.255, 0.256, 0.257, 0.258, 0.259, 0.26, 0.261, 0.262, 0.263, 0.264, 0.265, 0.266, 0.267, 0.268, 0.269, 0.27, 0.271, 0.272, 0.273, 0.274, 0.275, 0.276, 0.277, 0.278, 0.279, 0.28, 0.281, 0.28200000000000003, 0.28300000000000003, 0.28400000000000003, 0.28500000000000003, 0.28600000000000003, 0.28700000000000003, 0.28800000000000003, 0.289, 0.29, 0.291, 0.292, 0.293, 0.294, 0.295, 0.296, 0.297, 0.298, 0.299, 0.3, 0.301, 0.302, 0.303, 0.304, 0.305, 0.306, 0.307, 0.308, 0.309, 0.31, 0.311, 0.312, 0.313, 0.314, 0.315, 0.316, 0.317, 0.318, 0.319, 0.32, 0.321, 0.322, 0.323, 0.324, 0.325, 0.326, 0.327, 0.328, 0.329, 0.33, 0.331, 0.332, 0.333, 0.334, 0.335, 0.336, 0.337, 0.338, 0.339, 0.34, 0.341, 0.342, 0.343, 0.34400000000000003, 0.34500000000000003, 0.34600000000000003, 0.34700000000000003, 0.34800000000000003, 0.34900000000000003, 0.35000000000000003, 0.35100000000000003, 0.352, 0.353, 0.354, 0.355, 0.356, 0.357, 0.358, 0.359, 0.36, 0.361, 0.362, 0.363, 0.364, 0.365, 0.366, 0.367, 0.368, 0.369, 0.37, 0.371, 0.372, 0.373, 0.374, 0.375, 0.376, 0.377, 0.378, 0.379, 0.38, 0.381, 0.382, 0.383, 0.384, 0.385, 0.386, 0.387, 0.388, 0.389, 0.39, 0.391, 0.392, 0.393, 0.394, 0.395, 0.396, 0.397, 0.398, 0.399, 0.4, 0.401, 0.402, 0.403, 0.404, 0.405, 0.406, 0.40700000000000003, 0.40800000000000003, 0.40900000000000003, 0.41000000000000003, 0.41100000000000003, 0.41200000000000003, 0.41300000000000003, 0.41400000000000003, 0.41500000000000004, 0.41600000000000004, 0.417, 0.418, 0.419, 0.42, 0.421, 0.422, 0.423, 0.424, 0.425, 0.426, 0.427, 0.428, 0.429, 0.43, 0.431, 0.432, 0.433, 0.434, 0.435, 0.436, 0.437, 0.438, 0.439, 0.44, 0.441, 0.442, 0.443, 0.444, 0.445, 0.446, 0.447, 0.448, 0.449, 0.45, 0.451, 0.452, 0.453, 0.454, 0.455, 0.456, 0.457, 0.458, 0.459, 0.46, 0.461, 0.462, 0.463, 0.464, 0.465, 0.466, 0.467, 0.468, 0.46900000000000003, 0.47000000000000003, 0.47100000000000003, 0.47200000000000003, 0.47300000000000003, 0.47400000000000003, 0.47500000000000003, 0.47600000000000003, 0.47700000000000004, 0.47800000000000004, 0.47900000000000004, 0.48, 0.481, 0.482, 0.483, 0.484, 0.485, 0.486, 0.487, 0.488, 0.489, 0.49, 0.491, 0.492, 0.493, 0.494, 0.495, 0.496, 0.497, 0.498, 0.499, 0.5, 0.501, 0.502, 0.503, 0.504, 0.505, 0.506, 0.507, 0.508, 0.509, 0.51, 0.511, 0.512, 0.513, 0.514, 0.515, 0.516, 0.517, 0.518, 0.519, 0.52, 0.521, 0.522, 0.523, 0.524, 0.525, 0.526, 0.527, 0.528, 0.529, 0.53, 0.531, 0.532, 0.533, 0.534, 0.535, 0.536, 0.537, 0.538, 0.539, 0.54, 0.541, 0.542, 0.543, 0.544, 0.545, 0.546, 0.547, 0.548, 0.549, 0.55, 0.551, 0.552, 0.553, 0.554, 0.555, 0.556, 0.557, 0.558, 0.559, 0.56, 0.561, 0.562, 0.5630000000000001, 0.5640000000000001, 0.5650000000000001, 0.5660000000000001, 0.5670000000000001, 0.5680000000000001, 0.5690000000000001, 0.5700000000000001, 0.5710000000000001, 0.5720000000000001, 0.5730000000000001, 0.5740000000000001, 0.5750000000000001, 0.5760000000000001, 0.577, 0.578, 0.579, 0.58, 0.581, 0.582, 0.583, 0.584, 0.585, 0.586, 0.587, 0.588, 0.589, 0.59, 0.591, 0.592, 0.593, 0.594, 0.595, 0.596, 0.597, 0.598, 0.599, 0.6, 0.601, 0.602, 0.603, 0.604, 0.605, 0.606, 0.607, 0.608, 0.609, 0.61, 0.611, 0.612, 0.613, 0.614, 0.615, 0.616, 0.617, 0.618, 0.619, 0.62, 0.621, 0.622, 0.623, 0.624, 0.625, 0.626, 0.627, 0.628, 0.629, 0.63, 0.631, 0.632, 0.633, 0.634, 0.635, 0.636, 0.637, 0.638, 0.639, 0.64, 0.641, 0.642, 0.643, 0.644, 0.645, 0.646, 0.647, 0.648, 0.649, 0.65, 0.651, 0.652, 0.653, 0.654, 0.655, 0.656, 0.657, 0.658, 0.659, 0.66, 0.661, 0.662, 0.663, 0.664, 0.665, 0.666, 0.667, 0.668, 0.669, 0.67, 0.671, 0.672, 0.673, 0.674, 0.675, 0.676, 0.677, 0.678, 0.679, 0.68, 0.681, 0.682, 0.683, 0.684, 0.685, 0.686, 0.687, 0.6880000000000001, 0.6890000000000001, 0.6900000000000001, 0.6910000000000001, 0.6920000000000001, 0.6930000000000001, 0.6940000000000001, 0.6950000000000001, 0.6960000000000001, 0.6970000000000001, 0.6980000000000001, 0.6990000000000001, 0.7000000000000001, 0.7010000000000001, 0.7020000000000001, 0.7030000000000001, 0.704, 0.705, 0.706, 0.707, 0.708, 0.709, 0.71, 0.711, 0.712, 0.713, 0.714, 0.715, 0.716, 0.717, 0.718, 0.719, 0.72, 0.721, 0.722, 0.723, 0.724, 0.725, 0.726, 0.727, 0.728, 0.729, 0.73, 0.731, 0.732, 0.733, 0.734, 0.735, 0.736, 0.737, 0.738, 0.739, 0.74, 0.741, 0.742, 0.743, 0.744, 0.745, 0.746, 0.747, 0.748, 0.749, 0.75, 0.751, 0.752, 0.753, 0.754, 0.755, 0.756, 0.757, 0.758, 0.759, 0.76, 0.761, 0.762, 0.763, 0.764, 0.765, 0.766, 0.767, 0.768, 0.769, 0.77, 0.771, 0.772, 0.773, 0.774, 0.775, 0.776, 0.777, 0.778, 0.779, 0.78, 0.781, 0.782, 0.783, 0.784, 0.785, 0.786, 0.787, 0.788, 0.789, 0.79, 0.791, 0.792, 0.793, 0.794, 0.795, 0.796, 0.797, 0.798, 0.799, 0.8, 0.801, 0.802, 0.803, 0.804, 0.805, 0.806, 0.807, 0.808, 0.809, 0.81, 0.811, 0.812, 0.8130000000000001, 0.8140000000000001, 0.8150000000000001, 0.8160000000000001, 0.8170000000000001, 0.8180000000000001, 0.8190000000000001, 0.8200000000000001, 0.8210000000000001, 0.8220000000000001, 0.8230000000000001, 0.8240000000000001, 0.8250000000000001, 0.8260000000000001, 0.8270000000000001, 0.8280000000000001, 0.8290000000000001, 0.8300000000000001, 0.8310000000000001, 0.8320000000000001, 0.833, 0.834, 0.835, 0.836, 0.837, 0.838, 0.839, 0.84, 0.841, 0.842, 0.843, 0.844, 0.845, 0.846, 0.847, 0.848, 0.849, 0.85, 0.851, 0.852, 0.853, 0.854, 0.855, 0.856, 0.857, 0.858, 0.859, 0.86, 0.861, 0.862, 0.863, 0.864, 0.865, 0.866, 0.867, 0.868, 0.869, 0.87, 0.871, 0.872, 0.873, 0.874, 0.875, 0.876, 0.877, 0.878, 0.879, 0.88, 0.881, 0.882, 0.883, 0.884, 0.885, 0.886, 0.887, 0.888, 0.889, 0.89, 0.891, 0.892, 0.893, 0.894, 0.895, 0.896, 0.897, 0.898, 0.899, 0.9, 0.901, 0.902, 0.903, 0.904, 0.905, 0.906, 0.907, 0.908, 0.909, 0.91, 0.911, 0.912, 0.913, 0.914, 0.915, 0.916, 0.917, 0.918, 0.919, 0.92, 0.921, 0.922, 0.923, 0.924, 0.925, 0.926, 0.927, 0.928, 0.929, 0.93, 0.931, 0.932, 0.933, 0.934, 0.935, 0.936, 0.937, 0.9380000000000001, 0.9390000000000001, 0.9400000000000001, 0.9410000000000001, 0.9420000000000001, 0.9430000000000001, 0.9440000000000001, 0.9450000000000001, 0.9460000000000001, 0.9470000000000001, 0.9480000000000001, 0.9490000000000001, 0.9500000000000001, 0.9510000000000001, 0.9520000000000001, 0.9530000000000001, 0.9540000000000001, 0.9550000000000001, 0.9560000000000001, 0.9570000000000001, 0.9580000000000001, 0.9590000000000001, 0.96, 0.961, 0.962, 0.963, 0.964, 0.965, 0.966, 0.967, 0.968, 0.969, 0.97, 0.971, 0.972, 0.973, 0.974, 0.975, 0.976, 0.977, 0.978, 0.979, 0.98, 0.981, 0.982, 0.983, 0.984, 0.985, 0.986, 0.987, 0.988, 0.989, 0.99, 0.991, 0.992, 0.993, 0.994, 0.995, 0.996, 0.997, 0.998, 0.999, 1.0]\n",
      "1001\n",
      "x = [0.0, 0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009000000000000001, 0.01, 0.011, 0.012, 0.013000000000000001, 0.014, 0.015, 0.016, 0.017, 0.018000000000000002, 0.019, 0.02, 0.021, 0.022, 0.023, 0.024, 0.025, 0.026000000000000002, 0.027, 0.028, 0.029, 0.03, 0.031, 0.032, 0.033, 0.034, 0.035, 0.036000000000000004, 0.037, 0.038, 0.039, 0.04, 0.041, 0.042, 0.043000000000000003, 0.044, 0.045, 0.046, 0.047, 0.048, 0.049, 0.05, 0.051000000000000004, 0.052000000000000005, 0.053, 0.054, 0.055, 0.056, 0.057, 0.058, 0.059000000000000004, 0.06, 0.061, 0.062, 0.063, 0.064, 0.065, 0.066, 0.067, 0.068, 0.069, 0.07, 0.07100000000000001, 0.07200000000000001, 0.073, 0.074, 0.075, 0.076, 0.077, 0.078, 0.079, 0.08, 0.081, 0.082, 0.083, 0.084, 0.085, 0.08600000000000001, 0.08700000000000001, 0.088, 0.089, 0.09, 0.091, 0.092, 0.093, 0.094, 0.095, 0.096, 0.097, 0.098, 0.099, 0.1, 0.101, 0.10200000000000001, 0.10300000000000001, 0.10400000000000001, 0.105, 0.106, 0.107, 0.108, 0.109, 0.11, 0.111, 0.112, 0.113, 0.114, 0.115, 0.116, 0.117, 0.11800000000000001, 0.11900000000000001, 0.12, 0.121, 0.122, 0.123, 0.124, 0.125, 0.126, 0.127, 0.128, 0.129, 0.13, 0.131, 0.132, 0.133, 0.134, 0.135, 0.136, 0.137, 0.138, 0.139, 0.14, 0.14100000000000001, 0.14200000000000002, 0.14300000000000002, 0.14400000000000002, 0.145, 0.146, 0.147, 0.148, 0.149, 0.15, 0.151, 0.152, 0.153, 0.154, 0.155, 0.156, 0.157, 0.158, 0.159, 0.16, 0.161, 0.162, 0.163, 0.164, 0.165, 0.166, 0.167, 0.168, 0.169, 0.17, 0.171, 0.17200000000000001, 0.17300000000000001, 0.17400000000000002, 0.17500000000000002, 0.176, 0.177, 0.178, 0.179, 0.18, 0.181, 0.182, 0.183, 0.184, 0.185, 0.186, 0.187, 0.188, 0.189, 0.19, 0.191, 0.192, 0.193, 0.194, 0.195, 0.196, 0.197, 0.198, 0.199, 0.2, 0.201, 0.202, 0.203, 0.20400000000000001, 0.20500000000000002, 0.20600000000000002, 0.20700000000000002, 0.20800000000000002, 0.209, 0.21, 0.211, 0.212, 0.213, 0.214, 0.215, 0.216, 0.217, 0.218, 0.219, 0.22, 0.221, 0.222, 0.223, 0.224, 0.225, 0.226, 0.227, 0.228, 0.229, 0.23, 0.231, 0.232, 0.233, 0.234, 0.23500000000000001, 0.23600000000000002, 0.23700000000000002, 0.23800000000000002, 0.23900000000000002, 0.24, 0.241, 0.242, 0.243, 0.244, 0.245, 0.246, 0.247, 0.248, 0.249, 0.25, 0.251, 0.252, 0.253, 0.254, 0.255, 0.256, 0.257, 0.258, 0.259, 0.26, 0.261, 0.262, 0.263, 0.264, 0.265, 0.266, 0.267, 0.268, 0.269, 0.27, 0.271, 0.272, 0.273, 0.274, 0.275, 0.276, 0.277, 0.278, 0.279, 0.28, 0.281, 0.28200000000000003, 0.28300000000000003, 0.28400000000000003, 0.28500000000000003, 0.28600000000000003, 0.28700000000000003, 0.28800000000000003, 0.289, 0.29, 0.291, 0.292, 0.293, 0.294, 0.295, 0.296, 0.297, 0.298, 0.299, 0.3, 0.301, 0.302, 0.303, 0.304, 0.305, 0.306, 0.307, 0.308, 0.309, 0.31, 0.311, 0.312, 0.313, 0.314, 0.315, 0.316, 0.317, 0.318, 0.319, 0.32, 0.321, 0.322, 0.323, 0.324, 0.325, 0.326, 0.327, 0.328, 0.329, 0.33, 0.331, 0.332, 0.333, 0.334, 0.335, 0.336, 0.337, 0.338, 0.339, 0.34, 0.341, 0.342, 0.343, 0.34400000000000003, 0.34500000000000003, 0.34600000000000003, 0.34700000000000003, 0.34800000000000003, 0.34900000000000003, 0.35000000000000003, 0.35100000000000003, 0.352, 0.353, 0.354, 0.355, 0.356, 0.357, 0.358, 0.359, 0.36, 0.361, 0.362, 0.363, 0.364, 0.365, 0.366, 0.367, 0.368, 0.369, 0.37, 0.371, 0.372, 0.373, 0.374, 0.375, 0.376, 0.377, 0.378, 0.379, 0.38, 0.381, 0.382, 0.383, 0.384, 0.385, 0.386, 0.387, 0.388, 0.389, 0.39, 0.391, 0.392, 0.393, 0.394, 0.395, 0.396, 0.397, 0.398, 0.399, 0.4, 0.401, 0.402, 0.403, 0.404, 0.405, 0.406, 0.40700000000000003, 0.40800000000000003, 0.40900000000000003, 0.41000000000000003, 0.41100000000000003, 0.41200000000000003, 0.41300000000000003, 0.41400000000000003, 0.41500000000000004, 0.41600000000000004, 0.417, 0.418, 0.419, 0.42, 0.421, 0.422, 0.423, 0.424, 0.425, 0.426, 0.427, 0.428, 0.429, 0.43, 0.431, 0.432, 0.433, 0.434, 0.435, 0.436, 0.437, 0.438, 0.439, 0.44, 0.441, 0.442, 0.443, 0.444, 0.445, 0.446, 0.447, 0.448, 0.449, 0.45, 0.451, 0.452, 0.453, 0.454, 0.455, 0.456, 0.457, 0.458, 0.459, 0.46, 0.461, 0.462, 0.463, 0.464, 0.465, 0.466, 0.467, 0.468, 0.46900000000000003, 0.47000000000000003, 0.47100000000000003, 0.47200000000000003, 0.47300000000000003, 0.47400000000000003, 0.47500000000000003, 0.47600000000000003, 0.47700000000000004, 0.47800000000000004, 0.47900000000000004, 0.48, 0.481, 0.482, 0.483, 0.484, 0.485, 0.486, 0.487, 0.488, 0.489, 0.49, 0.491, 0.492, 0.493, 0.494, 0.495, 0.496, 0.497, 0.498, 0.499, 0.5, 0.501, 0.502, 0.503, 0.504, 0.505, 0.506, 0.507, 0.508, 0.509, 0.51, 0.511, 0.512, 0.513, 0.514, 0.515, 0.516, 0.517, 0.518, 0.519, 0.52, 0.521, 0.522, 0.523, 0.524, 0.525, 0.526, 0.527, 0.528, 0.529, 0.53, 0.531, 0.532, 0.533, 0.534, 0.535, 0.536, 0.537, 0.538, 0.539, 0.54, 0.541, 0.542, 0.543, 0.544, 0.545, 0.546, 0.547, 0.548, 0.549, 0.55, 0.551, 0.552, 0.553, 0.554, 0.555, 0.556, 0.557, 0.558, 0.559, 0.56, 0.561, 0.562, 0.5630000000000001, 0.5640000000000001, 0.5650000000000001, 0.5660000000000001, 0.5670000000000001, 0.5680000000000001, 0.5690000000000001, 0.5700000000000001, 0.5710000000000001, 0.5720000000000001, 0.5730000000000001, 0.5740000000000001, 0.5750000000000001, 0.5760000000000001, 0.577, 0.578, 0.579, 0.58, 0.581, 0.582, 0.583, 0.584, 0.585, 0.586, 0.587, 0.588, 0.589, 0.59, 0.591, 0.592, 0.593, 0.594, 0.595, 0.596, 0.597, 0.598, 0.599, 0.6, 0.601, 0.602, 0.603, 0.604, 0.605, 0.606, 0.607, 0.608, 0.609, 0.61, 0.611, 0.612, 0.613, 0.614, 0.615, 0.616, 0.617, 0.618, 0.619, 0.62, 0.621, 0.622, 0.623, 0.624, 0.625, 0.626, 0.627, 0.628, 0.629, 0.63, 0.631, 0.632, 0.633, 0.634, 0.635, 0.636, 0.637, 0.638, 0.639, 0.64, 0.641, 0.642, 0.643, 0.644, 0.645, 0.646, 0.647, 0.648, 0.649, 0.65, 0.651, 0.652, 0.653, 0.654, 0.655, 0.656, 0.657, 0.658, 0.659, 0.66, 0.661, 0.662, 0.663, 0.664, 0.665, 0.666, 0.667, 0.668, 0.669, 0.67, 0.671, 0.672, 0.673, 0.674, 0.675, 0.676, 0.677, 0.678, 0.679, 0.68, 0.681, 0.682, 0.683, 0.684, 0.685, 0.686, 0.687, 0.6880000000000001, 0.6890000000000001, 0.6900000000000001, 0.6910000000000001, 0.6920000000000001, 0.6930000000000001, 0.6940000000000001, 0.6950000000000001, 0.6960000000000001, 0.6970000000000001, 0.6980000000000001, 0.6990000000000001, 0.7000000000000001, 0.7010000000000001, 0.7020000000000001, 0.7030000000000001, 0.704, 0.705, 0.706, 0.707, 0.708, 0.709, 0.71, 0.711, 0.712, 0.713, 0.714, 0.715, 0.716, 0.717, 0.718, 0.719, 0.72, 0.721, 0.722, 0.723, 0.724, 0.725, 0.726, 0.727, 0.728, 0.729, 0.73, 0.731, 0.732, 0.733, 0.734, 0.735, 0.736, 0.737, 0.738, 0.739, 0.74, 0.741, 0.742, 0.743, 0.744, 0.745, 0.746, 0.747, 0.748, 0.749, 0.75, 0.751, 0.752, 0.753, 0.754, 0.755, 0.756, 0.757, 0.758, 0.759, 0.76, 0.761, 0.762, 0.763, 0.764, 0.765, 0.766, 0.767, 0.768, 0.769, 0.77, 0.771, 0.772, 0.773, 0.774, 0.775, 0.776, 0.777, 0.778, 0.779, 0.78, 0.781, 0.782, 0.783, 0.784, 0.785, 0.786, 0.787, 0.788, 0.789, 0.79, 0.791, 0.792, 0.793, 0.794, 0.795, 0.796, 0.797, 0.798, 0.799, 0.8, 0.801, 0.802, 0.803, 0.804, 0.805, 0.806, 0.807, 0.808, 0.809, 0.81, 0.811, 0.812, 0.8130000000000001, 0.8140000000000001, 0.8150000000000001, 0.8160000000000001, 0.8170000000000001, 0.8180000000000001, 0.8190000000000001, 0.8200000000000001, 0.8210000000000001, 0.8220000000000001, 0.8230000000000001, 0.8240000000000001, 0.8250000000000001, 0.8260000000000001, 0.8270000000000001, 0.8280000000000001, 0.8290000000000001, 0.8300000000000001, 0.8310000000000001, 0.8320000000000001, 0.833, 0.834, 0.835, 0.836, 0.837, 0.838, 0.839, 0.84, 0.841, 0.842, 0.843, 0.844, 0.845, 0.846, 0.847, 0.848, 0.849, 0.85, 0.851, 0.852, 0.853, 0.854, 0.855, 0.856, 0.857, 0.858, 0.859, 0.86, 0.861, 0.862, 0.863, 0.864, 0.865, 0.866, 0.867, 0.868, 0.869, 0.87, 0.871, 0.872, 0.873, 0.874, 0.875, 0.876, 0.877, 0.878, 0.879, 0.88, 0.881, 0.882, 0.883, 0.884, 0.885, 0.886, 0.887, 0.888, 0.889, 0.89, 0.891, 0.892, 0.893, 0.894, 0.895, 0.896, 0.897, 0.898, 0.899, 0.9, 0.901, 0.902, 0.903, 0.904, 0.905, 0.906, 0.907, 0.908, 0.909, 0.91, 0.911, 0.912, 0.913, 0.914, 0.915, 0.916, 0.917, 0.918, 0.919, 0.92, 0.921, 0.922, 0.923, 0.924, 0.925, 0.926, 0.927, 0.928, 0.929, 0.93, 0.931, 0.932, 0.933, 0.934, 0.935, 0.936, 0.937, 0.9380000000000001, 0.9390000000000001, 0.9400000000000001, 0.9410000000000001, 0.9420000000000001, 0.9430000000000001, 0.9440000000000001, 0.9450000000000001, 0.9460000000000001, 0.9470000000000001, 0.9480000000000001, 0.9490000000000001, 0.9500000000000001, 0.9510000000000001, 0.9520000000000001, 0.9530000000000001, 0.9540000000000001, 0.9550000000000001, 0.9560000000000001, 0.9570000000000001, 0.9580000000000001, 0.9590000000000001, 0.96, 0.961, 0.962, 0.963, 0.964, 0.965, 0.966, 0.967, 0.968, 0.969, 0.97, 0.971, 0.972, 0.973, 0.974, 0.975, 0.976, 0.977, 0.978, 0.979, 0.98, 0.981, 0.982, 0.983, 0.984, 0.985, 0.986, 0.987, 0.988, 0.989, 0.99, 0.991, 0.992, 0.993, 0.994, 0.995, 0.996, 0.997, 0.998, 0.999, 1.0]\n",
      "1001\n"
     ]
    }
   ],
   "source": [
    "#Check\n",
    "variable_data = [(key, values) for key, values in variable_values.items()]\n",
    "for variable, values in variable_data:\n",
    "    print(f\"{variable} = {values}\")\n",
    "    print(int(len(values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cost = [tensor(0.64751049, requires_grad=True), tensor(0.64785988, requires_grad=True), tensor(0.64820668, requires_grad=True), tensor(0.64855089, requires_grad=True), tensor(0.64889251, requires_grad=True), tensor(0.64923153, requires_grad=True), tensor(0.64956796, requires_grad=True), tensor(0.64990179, requires_grad=True), tensor(0.65023303, requires_grad=True), tensor(0.65056166, requires_grad=True), tensor(0.6508877, requires_grad=True), tensor(0.65121113, requires_grad=True), tensor(0.65153197, requires_grad=True), tensor(0.6518502, requires_grad=True), tensor(0.65216583, requires_grad=True), tensor(0.65247885, requires_grad=True), tensor(0.65278927, requires_grad=True), tensor(0.65309708, requires_grad=True), tensor(0.65340228, requires_grad=True), tensor(0.65370487, requires_grad=True), tensor(0.65400485, requires_grad=True), tensor(0.65430223, requires_grad=True), tensor(0.65459699, requires_grad=True), tensor(0.65488913, requires_grad=True), tensor(0.65517867, requires_grad=True), tensor(0.65546558, requires_grad=True), tensor(0.65574988, requires_grad=True), tensor(0.65603157, requires_grad=True), tensor(0.65631063, requires_grad=True), tensor(0.65658708, requires_grad=True), tensor(0.6568609, requires_grad=True), tensor(0.6571321, requires_grad=True), tensor(0.65740068, requires_grad=True), tensor(0.65766664, requires_grad=True), tensor(0.65792997, requires_grad=True), tensor(0.65819068, requires_grad=True), tensor(0.65844876, requires_grad=True), tensor(0.65870421, requires_grad=True), tensor(0.65895703, requires_grad=True), tensor(0.65920722, requires_grad=True), tensor(0.65945478, requires_grad=True), tensor(0.65969971, requires_grad=True), tensor(0.65994201, requires_grad=True), tensor(0.66018167, requires_grad=True), tensor(0.6604187, requires_grad=True), tensor(0.66065309, requires_grad=True), tensor(0.66088484, requires_grad=True), tensor(0.66111395, requires_grad=True), tensor(0.66134042, requires_grad=True), tensor(0.66156426, requires_grad=True), tensor(0.66178545, requires_grad=True), tensor(0.662004, requires_grad=True), tensor(0.6622199, requires_grad=True), tensor(0.66243316, requires_grad=True), tensor(0.66264378, requires_grad=True), tensor(0.66285174, requires_grad=True), tensor(0.66305706, requires_grad=True), tensor(0.66325973, requires_grad=True), tensor(0.66345975, requires_grad=True), tensor(0.66365712, requires_grad=True), tensor(0.66385184, requires_grad=True), tensor(0.6640439, requires_grad=True), tensor(0.66423331, requires_grad=True), tensor(0.66442006, requires_grad=True), tensor(0.66460416, requires_grad=True), tensor(0.6647856, requires_grad=True), tensor(0.66496438, requires_grad=True), tensor(0.6651405, requires_grad=True), tensor(0.66531396, requires_grad=True), tensor(0.66548476, requires_grad=True), tensor(0.66565289, requires_grad=True), tensor(0.66581836, requires_grad=True), tensor(0.66598117, requires_grad=True), tensor(0.66614131, requires_grad=True), tensor(0.66629878, requires_grad=True), tensor(0.66645359, requires_grad=True), tensor(0.66660572, requires_grad=True), tensor(0.66675519, requires_grad=True), tensor(0.66690198, requires_grad=True), tensor(0.6670461, requires_grad=True), tensor(0.66718755, requires_grad=True), tensor(0.66732632, requires_grad=True), tensor(0.66746242, requires_grad=True), tensor(0.66759584, requires_grad=True), tensor(0.66772658, requires_grad=True), tensor(0.66785464, requires_grad=True), tensor(0.66798002, requires_grad=True), tensor(0.66810273, requires_grad=True), tensor(0.66822275, requires_grad=True), tensor(0.66834008, requires_grad=True), tensor(0.66845474, requires_grad=True), tensor(0.6685667, requires_grad=True), tensor(0.66867598, requires_grad=True), tensor(0.66878258, requires_grad=True), tensor(0.66888648, requires_grad=True), tensor(0.66898769, requires_grad=True), tensor(0.66908622, requires_grad=True), tensor(0.66918205, requires_grad=True), tensor(0.66927519, requires_grad=True), tensor(0.66936564, requires_grad=True), tensor(0.66945339, requires_grad=True), tensor(0.66953844, requires_grad=True), tensor(0.6696208, requires_grad=True), tensor(0.66970046, requires_grad=True), tensor(0.66977741, requires_grad=True), tensor(0.66985167, requires_grad=True), tensor(0.66992323, requires_grad=True), tensor(0.66999208, requires_grad=True), tensor(0.67005824, requires_grad=True), tensor(0.67012168, requires_grad=True), tensor(0.67018242, requires_grad=True), tensor(0.67024046, requires_grad=True), tensor(0.67029578, requires_grad=True), tensor(0.6703484, requires_grad=True), tensor(0.6703983, requires_grad=True), tensor(0.6704455, requires_grad=True), tensor(0.67048998, requires_grad=True), tensor(0.67053175, requires_grad=True), tensor(0.6705708, requires_grad=True), tensor(0.67060714, requires_grad=True), tensor(0.67064076, requires_grad=True), tensor(0.67067167, requires_grad=True), tensor(0.67069985, requires_grad=True), tensor(0.67072532, requires_grad=True), tensor(0.67074806, requires_grad=True), tensor(0.67076808, requires_grad=True), tensor(0.67078538, requires_grad=True), tensor(0.67079996, requires_grad=True), tensor(0.6708118, requires_grad=True), tensor(0.67082093, requires_grad=True), tensor(0.67082732, requires_grad=True), tensor(0.67083099, requires_grad=True), tensor(0.67083192, requires_grad=True), tensor(0.67083013, requires_grad=True), tensor(0.6708256, requires_grad=True), tensor(0.67081834, requires_grad=True), tensor(0.67080834, requires_grad=True), tensor(0.67079561, requires_grad=True), tensor(0.67078015, requires_grad=True), tensor(0.67076194, requires_grad=True), tensor(0.670741, requires_grad=True), tensor(0.67071732, requires_grad=True), tensor(0.67069089, requires_grad=True), tensor(0.67066173, requires_grad=True), tensor(0.67062982, requires_grad=True), tensor(0.67059517, requires_grad=True), tensor(0.67055777, requires_grad=True), tensor(0.67051762, requires_grad=True), tensor(0.67047473, requires_grad=True), tensor(0.67042909, requires_grad=True), tensor(0.6703807, requires_grad=True), tensor(0.67032956, requires_grad=True), tensor(0.67027567, requires_grad=True), tensor(0.67021902, requires_grad=True), tensor(0.67015962, requires_grad=True), tensor(0.67009746, requires_grad=True), tensor(0.67003255, requires_grad=True), tensor(0.66996488, requires_grad=True), tensor(0.66989445, requires_grad=True), tensor(0.66982126, requires_grad=True), tensor(0.66974531, requires_grad=True), tensor(0.6696666, requires_grad=True), tensor(0.66958513, requires_grad=True), tensor(0.66950089, requires_grad=True), tensor(0.66941388, requires_grad=True), tensor(0.66932411, requires_grad=True), tensor(0.66923157, requires_grad=True), tensor(0.66913626, requires_grad=True), tensor(0.66903819, requires_grad=True), tensor(0.66893734, requires_grad=True), tensor(0.66883372, requires_grad=True), tensor(0.66872732, requires_grad=True), tensor(0.66861815, requires_grad=True), tensor(0.66850621, requires_grad=True), tensor(0.66839149, requires_grad=True), tensor(0.66827399, requires_grad=True), tensor(0.66815371, requires_grad=True), tensor(0.66803065, requires_grad=True), tensor(0.66790481, requires_grad=True), tensor(0.66777619, requires_grad=True), tensor(0.66764479, requires_grad=True), tensor(0.6675106, requires_grad=True), tensor(0.66737362, requires_grad=True), tensor(0.66723386, requires_grad=True), tensor(0.66709131, requires_grad=True), tensor(0.66694597, requires_grad=True), tensor(0.66679783, requires_grad=True), tensor(0.66664691, requires_grad=True), tensor(0.6664932, requires_grad=True), tensor(0.66633669, requires_grad=True), tensor(0.66617738, requires_grad=True), tensor(0.66601528, requires_grad=True), tensor(0.66585039, requires_grad=True), tensor(0.66568269, requires_grad=True), tensor(0.66551219, requires_grad=True), tensor(0.6653389, requires_grad=True), tensor(0.6651628, requires_grad=True), tensor(0.6649839, requires_grad=True), tensor(0.66480219, requires_grad=True), tensor(0.66461768, requires_grad=True), tensor(0.66443036, requires_grad=True), tensor(0.66424024, requires_grad=True), tensor(0.6640473, requires_grad=True), tensor(0.66385156, requires_grad=True), tensor(0.663653, requires_grad=True), tensor(0.66345163, requires_grad=True), tensor(0.66324745, requires_grad=True), tensor(0.66304045, requires_grad=True), tensor(0.66283064, requires_grad=True), tensor(0.66261801, requires_grad=True), tensor(0.66240256, requires_grad=True), tensor(0.6621843, requires_grad=True), tensor(0.66196321, requires_grad=True), tensor(0.6617393, requires_grad=True), tensor(0.66151256, requires_grad=True), tensor(0.66128301, requires_grad=True), tensor(0.66105062, requires_grad=True), tensor(0.66081541, requires_grad=True), tensor(0.66057738, requires_grad=True), tensor(0.66033651, requires_grad=True), tensor(0.66009281, requires_grad=True), tensor(0.65984629, requires_grad=True), tensor(0.65959693, requires_grad=True), tensor(0.65934473, requires_grad=True), tensor(0.6590897, requires_grad=True), tensor(0.65883184, requires_grad=True), tensor(0.65857114, requires_grad=True), tensor(0.65830759, requires_grad=True), tensor(0.65804121, requires_grad=True), tensor(0.65777199, requires_grad=True), tensor(0.65749993, requires_grad=True), tensor(0.65722502, requires_grad=True), tensor(0.65694727, requires_grad=True), tensor(0.65666667, requires_grad=True), tensor(0.65638323, requires_grad=True), tensor(0.65609694, requires_grad=True), tensor(0.6558078, requires_grad=True), tensor(0.6555158, requires_grad=True), tensor(0.65522096, requires_grad=True), tensor(0.65492326, requires_grad=True), tensor(0.65462271, requires_grad=True), tensor(0.65431931, requires_grad=True), tensor(0.65401304, requires_grad=True), tensor(0.65370392, requires_grad=True), tensor(0.65339194, requires_grad=True), tensor(0.6530771, requires_grad=True), tensor(0.6527594, requires_grad=True), tensor(0.65243883, requires_grad=True), tensor(0.65211541, requires_grad=True), tensor(0.65178911, requires_grad=True), tensor(0.65145995, requires_grad=True), tensor(0.65112792, requires_grad=True), tensor(0.65079302, requires_grad=True), tensor(0.65045526, requires_grad=True), tensor(0.65011462, requires_grad=True), tensor(0.64977111, requires_grad=True), tensor(0.64942472, requires_grad=True), tensor(0.64907546, requires_grad=True), tensor(0.64872332, requires_grad=True), tensor(0.64836831, requires_grad=True), tensor(0.64801042, requires_grad=True), tensor(0.64764964, requires_grad=True), tensor(0.64728599, requires_grad=True), tensor(0.64691945, requires_grad=True), tensor(0.64655003, requires_grad=True), tensor(0.64617772, requires_grad=True), tensor(0.64580253, requires_grad=True), tensor(0.64542444, requires_grad=True), tensor(0.64504347, requires_grad=True), tensor(0.64465961, requires_grad=True), tensor(0.64427286, requires_grad=True), tensor(0.64388322, requires_grad=True), tensor(0.64349068, requires_grad=True), tensor(0.64309524, requires_grad=True), tensor(0.64269691, requires_grad=True), tensor(0.64229568, requires_grad=True), tensor(0.64189156, requires_grad=True), tensor(0.64148453, requires_grad=True), tensor(0.6410746, requires_grad=True), tensor(0.64066176, requires_grad=True), tensor(0.64024603, requires_grad=True), tensor(0.63982738, requires_grad=True), tensor(0.63940583, requires_grad=True), tensor(0.63898138, requires_grad=True), tensor(0.63855401, requires_grad=True), tensor(0.63812373, requires_grad=True), tensor(0.63769054, requires_grad=True), tensor(0.63725444, requires_grad=True), tensor(0.63681542, requires_grad=True), tensor(0.63637348, requires_grad=True), tensor(0.63592863, requires_grad=True), tensor(0.63548086, requires_grad=True), tensor(0.63503017, requires_grad=True), tensor(0.63457656, requires_grad=True), tensor(0.63412003, requires_grad=True), tensor(0.63366057, requires_grad=True), tensor(0.63319819, requires_grad=True), tensor(0.63273288, requires_grad=True), tensor(0.63226464, requires_grad=True), tensor(0.63179347, requires_grad=True), tensor(0.63131937, requires_grad=True), tensor(0.63084235, requires_grad=True), tensor(0.63036238, requires_grad=True), tensor(0.62987949, requires_grad=True), tensor(0.62939366, requires_grad=True), tensor(0.62890489, requires_grad=True), tensor(0.62841318, requires_grad=True), tensor(0.62791853, requires_grad=True), tensor(0.62742094, requires_grad=True), tensor(0.62692041, requires_grad=True), tensor(0.62641694, requires_grad=True), tensor(0.62591051, requires_grad=True), tensor(0.62540115, requires_grad=True), tensor(0.62488883, requires_grad=True), tensor(0.62437357, requires_grad=True), tensor(0.62385535, requires_grad=True), tensor(0.62333419, requires_grad=True), tensor(0.62281007, requires_grad=True), tensor(0.62228299, requires_grad=True), tensor(0.62175296, requires_grad=True), tensor(0.62121997, requires_grad=True), tensor(0.62068402, requires_grad=True), tensor(0.62014511, requires_grad=True), tensor(0.61960324, requires_grad=True), tensor(0.61905841, requires_grad=True), tensor(0.61851061, requires_grad=True), tensor(0.61795985, requires_grad=True), tensor(0.61740612, requires_grad=True), tensor(0.61684942, requires_grad=True), tensor(0.61628975, requires_grad=True), tensor(0.61572711, requires_grad=True), tensor(0.6151615, requires_grad=True), tensor(0.61459291, requires_grad=True), tensor(0.61402135, requires_grad=True), tensor(0.61344681, requires_grad=True), tensor(0.61286929, requires_grad=True), tensor(0.61228879, requires_grad=True), tensor(0.61170531, requires_grad=True), tensor(0.61111885, requires_grad=True), tensor(0.6105294, requires_grad=True), tensor(0.60993697, requires_grad=True), tensor(0.60934155, requires_grad=True), tensor(0.60874314, requires_grad=True), tensor(0.60814175, requires_grad=True), tensor(0.60753736, requires_grad=True), tensor(0.60692998, requires_grad=True), tensor(0.6063196, requires_grad=True), tensor(0.60570623, requires_grad=True), tensor(0.60508986, requires_grad=True), tensor(0.6044705, requires_grad=True), tensor(0.60384813, requires_grad=True), tensor(0.60322276, requires_grad=True), tensor(0.60259439, requires_grad=True), tensor(0.60196302, requires_grad=True), tensor(0.60132864, requires_grad=True), tensor(0.60069125, requires_grad=True), tensor(0.60005085, requires_grad=True), tensor(0.59940744, requires_grad=True), tensor(0.59876102, requires_grad=True), tensor(0.59811159, requires_grad=True), tensor(0.59745915, requires_grad=True), tensor(0.59680368, requires_grad=True), tensor(0.5961452, requires_grad=True), tensor(0.5954837, requires_grad=True), tensor(0.59481918, requires_grad=True), tensor(0.59415164, requires_grad=True), tensor(0.59348107, requires_grad=True), tensor(0.59280748, requires_grad=True), tensor(0.59213086, requires_grad=True), tensor(0.59145122, requires_grad=True), tensor(0.59076854, requires_grad=True), tensor(0.59008284, requires_grad=True), tensor(0.5893941, requires_grad=True), tensor(0.58870232, requires_grad=True), tensor(0.58800751, requires_grad=True), tensor(0.58730966, requires_grad=True), tensor(0.58660878, requires_grad=True), tensor(0.58590485, requires_grad=True), tensor(0.58519788, requires_grad=True), tensor(0.58448787, requires_grad=True), tensor(0.58377482, requires_grad=True), tensor(0.58305871, requires_grad=True), tensor(0.58233956, requires_grad=True), tensor(0.58161736, requires_grad=True), tensor(0.58089211, requires_grad=True), tensor(0.5801638, requires_grad=True), tensor(0.57943244, requires_grad=True), tensor(0.57869803, requires_grad=True), tensor(0.57796056, requires_grad=True), tensor(0.57722002, requires_grad=True), tensor(0.57647643, requires_grad=True), tensor(0.57572978, requires_grad=True), tensor(0.57498006, requires_grad=True), tensor(0.57422727, requires_grad=True), tensor(0.57347142, requires_grad=True), tensor(0.5727125, requires_grad=True), tensor(0.57195051, requires_grad=True), tensor(0.57118545, requires_grad=True), tensor(0.57041731, requires_grad=True), tensor(0.5696461, requires_grad=True), tensor(0.56887182, requires_grad=True), tensor(0.56809445, requires_grad=True), tensor(0.56731401, requires_grad=True), tensor(0.56653048, requires_grad=True), tensor(0.56574387, requires_grad=True), tensor(0.56495417, requires_grad=True), tensor(0.56416139, requires_grad=True), tensor(0.56336552, requires_grad=True), tensor(0.56256656, requires_grad=True), tensor(0.56176451, requires_grad=True), tensor(0.56095936, requires_grad=True), tensor(0.56015112, requires_grad=True), tensor(0.55933979, requires_grad=True), tensor(0.55852535, requires_grad=True), tensor(0.55770782, requires_grad=True), tensor(0.55688718, requires_grad=True), tensor(0.55606344, requires_grad=True), tensor(0.5552366, requires_grad=True), tensor(0.55440665, requires_grad=True), tensor(0.55357359, requires_grad=True), tensor(0.55273742, requires_grad=True), tensor(0.55189814, requires_grad=True), tensor(0.55105575, requires_grad=True), tensor(0.55021024, requires_grad=True), tensor(0.54936162, requires_grad=True), tensor(0.54850987, requires_grad=True), tensor(0.54765501, requires_grad=True), tensor(0.54679702, requires_grad=True), tensor(0.54593591, requires_grad=True), tensor(0.54507167, requires_grad=True), tensor(0.54420431, requires_grad=True), tensor(0.54333382, requires_grad=True), tensor(0.5424602, requires_grad=True), tensor(0.54158344, requires_grad=True), tensor(0.54070355, requires_grad=True), tensor(0.53982052, requires_grad=True), tensor(0.53893436, requires_grad=True), tensor(0.53804506, requires_grad=True), tensor(0.53715261, requires_grad=True), tensor(0.53625703, requires_grad=True), tensor(0.53535829, requires_grad=True), tensor(0.53445641, requires_grad=True), tensor(0.53355139, requires_grad=True), tensor(0.53264321, requires_grad=True), tensor(0.53173188, requires_grad=True), tensor(0.53081739, requires_grad=True), tensor(0.52989975, requires_grad=True), tensor(0.52897895, requires_grad=True), tensor(0.52805499, requires_grad=True), tensor(0.52712788, requires_grad=True), tensor(0.52619759, requires_grad=True), tensor(0.52526415, requires_grad=True), tensor(0.52432753, requires_grad=True), tensor(0.52338775, requires_grad=True), tensor(0.52244479, requires_grad=True), tensor(0.52149867, requires_grad=True), tensor(0.52054937, requires_grad=True), tensor(0.51959689, requires_grad=True), tensor(0.51864124, requires_grad=True), tensor(0.5176824, requires_grad=True), tensor(0.51672038, requires_grad=True), tensor(0.51575518, requires_grad=True), tensor(0.5147868, requires_grad=True), tensor(0.51381522, requires_grad=True), tensor(0.51284046, requires_grad=True), tensor(0.5118625, requires_grad=True), tensor(0.51088135, requires_grad=True), tensor(0.50989701, requires_grad=True), tensor(0.50890947, requires_grad=True), tensor(0.50791873, requires_grad=True), tensor(0.50692478, requires_grad=True), tensor(0.50592764, requires_grad=True), tensor(0.50492729, requires_grad=True), tensor(0.50392373, requires_grad=True), tensor(0.50291696, requires_grad=True), tensor(0.50190699, requires_grad=True), tensor(0.5008938, requires_grad=True), tensor(0.49987739, requires_grad=True), tensor(0.49885777, requires_grad=True), tensor(0.49783492, requires_grad=True), tensor(0.49680886, requires_grad=True), tensor(0.49577958, requires_grad=True), tensor(0.49474706, requires_grad=True), tensor(0.49371133, requires_grad=True), tensor(0.49267236, requires_grad=True), tensor(0.49163016, requires_grad=True), tensor(0.49058473, requires_grad=True), tensor(0.48953606, requires_grad=True), tensor(0.48848415, requires_grad=True), tensor(0.48742901, requires_grad=True), tensor(0.48637062, requires_grad=True), tensor(0.48530899, requires_grad=True), tensor(0.48424411, requires_grad=True), tensor(0.48317599, requires_grad=True), tensor(0.48210462, requires_grad=True), tensor(0.48102999, requires_grad=True), tensor(0.47995211, requires_grad=True), tensor(0.47887097, requires_grad=True), tensor(0.47778658, requires_grad=True), tensor(0.47669892, requires_grad=True), tensor(0.475608, requires_grad=True), tensor(0.47451382, requires_grad=True), tensor(0.47341637, requires_grad=True), tensor(0.47231565, requires_grad=True), tensor(0.47121166, requires_grad=True), tensor(0.47010439, requires_grad=True), tensor(0.46899385, requires_grad=True), tensor(0.46788004, requires_grad=True), tensor(0.46676294, requires_grad=True), tensor(0.46564255, requires_grad=True), tensor(0.46451889, requires_grad=True), tensor(0.46339194, requires_grad=True), tensor(0.46226169, requires_grad=True), tensor(0.46112816, requires_grad=True), tensor(0.45999133, requires_grad=True), tensor(0.45885121, requires_grad=True), tensor(0.45770779, requires_grad=True), tensor(0.45656107, requires_grad=True), tensor(0.45541104, requires_grad=True), tensor(0.45425771, requires_grad=True), tensor(0.45310107, requires_grad=True), tensor(0.45194113, requires_grad=True), tensor(0.45077787, requires_grad=True), tensor(0.4496113, requires_grad=True), tensor(0.44844141, requires_grad=True), tensor(0.4472682, requires_grad=True), tensor(0.44609167, requires_grad=True), tensor(0.44491182, requires_grad=True), tensor(0.44372864, requires_grad=True), tensor(0.44254213, requires_grad=True), tensor(0.44135229, requires_grad=True), tensor(0.44015912, requires_grad=True), tensor(0.43896261, requires_grad=True), tensor(0.43776277, requires_grad=True), tensor(0.43655958, requires_grad=True), tensor(0.43535305, requires_grad=True), tensor(0.43414318, requires_grad=True), tensor(0.43292995, requires_grad=True), tensor(0.43171338, requires_grad=True), tensor(0.43049346, requires_grad=True), tensor(0.42927018, requires_grad=True), tensor(0.42804354, requires_grad=True), tensor(0.42681354, requires_grad=True), tensor(0.42558018, requires_grad=True), tensor(0.42434346, requires_grad=True), tensor(0.42310336, requires_grad=True), tensor(0.4218599, requires_grad=True), tensor(0.42061306, requires_grad=True), tensor(0.41936285, requires_grad=True), tensor(0.41810926, requires_grad=True), tensor(0.41685229, requires_grad=True), tensor(0.41559194, requires_grad=True), tensor(0.4143282, requires_grad=True), tensor(0.41306107, requires_grad=True), tensor(0.41179056, requires_grad=True), tensor(0.41051664, requires_grad=True), tensor(0.40923934, requires_grad=True), tensor(0.40795863, requires_grad=True), tensor(0.40667452, requires_grad=True), tensor(0.40538701, requires_grad=True), tensor(0.40409609, requires_grad=True), tensor(0.40280177, requires_grad=True), tensor(0.40150403, requires_grad=True), tensor(0.40020287, requires_grad=True), tensor(0.3988983, requires_grad=True), tensor(0.39759031, requires_grad=True), tensor(0.39627889, requires_grad=True), tensor(0.39496405, requires_grad=True), tensor(0.39364578, requires_grad=True), tensor(0.39232408, requires_grad=True), tensor(0.39099894, requires_grad=True), tensor(0.38967037, requires_grad=True), tensor(0.38833836, requires_grad=True), tensor(0.3870029, requires_grad=True), tensor(0.385664, requires_grad=True), tensor(0.38432165, requires_grad=True), tensor(0.38297585, requires_grad=True), tensor(0.3816266, requires_grad=True), tensor(0.38027388, requires_grad=True), tensor(0.37891771, requires_grad=True), tensor(0.37755808, requires_grad=True), tensor(0.37619498, requires_grad=True), tensor(0.37482841, requires_grad=True), tensor(0.37345837, requires_grad=True), tensor(0.37208486, requires_grad=True), tensor(0.37070787, requires_grad=True), tensor(0.36932739, requires_grad=True), tensor(0.36794344, requires_grad=True), tensor(0.366556, requires_grad=True), tensor(0.36516506, requires_grad=True), tensor(0.36377064, requires_grad=True), tensor(0.36237272, requires_grad=True), tensor(0.3609713, requires_grad=True), tensor(0.35956638, requires_grad=True), tensor(0.35815796, requires_grad=True), tensor(0.35674602, requires_grad=True), tensor(0.35533058, requires_grad=True), tensor(0.35391162, requires_grad=True), tensor(0.35248914, requires_grad=True), tensor(0.35106314, requires_grad=True), tensor(0.34963362, requires_grad=True), tensor(0.34820057, requires_grad=True), tensor(0.346764, requires_grad=True), tensor(0.34532388, requires_grad=True), tensor(0.34388024, requires_grad=True), tensor(0.34243305, requires_grad=True), tensor(0.34098232, requires_grad=True), tensor(0.33952804, requires_grad=True), tensor(0.33807021, requires_grad=True), tensor(0.33660883, requires_grad=True), tensor(0.33514389, requires_grad=True), tensor(0.33367539, requires_grad=True), tensor(0.33220333, requires_grad=True), tensor(0.3307277, requires_grad=True), tensor(0.3292485, requires_grad=True), tensor(0.32776573, requires_grad=True), tensor(0.32627938, requires_grad=True), tensor(0.32478945, requires_grad=True), tensor(0.32329594, requires_grad=True), tensor(0.32179884, requires_grad=True), tensor(0.32029815, requires_grad=True), tensor(0.31879386, requires_grad=True), tensor(0.31728598, requires_grad=True), tensor(0.31577449, requires_grad=True), tensor(0.3142594, requires_grad=True), tensor(0.31274071, requires_grad=True), tensor(0.31121839, requires_grad=True), tensor(0.30969247, requires_grad=True), tensor(0.30816292, requires_grad=True), tensor(0.30662975, requires_grad=True), tensor(0.30509295, requires_grad=True), tensor(0.30355252, requires_grad=True), tensor(0.30200846, requires_grad=True), tensor(0.30046076, requires_grad=True), tensor(0.29890942, requires_grad=True), tensor(0.29735443, requires_grad=True), tensor(0.29579579, requires_grad=True), tensor(0.2942335, requires_grad=True), tensor(0.29266755, requires_grad=True), tensor(0.29109794, requires_grad=True), tensor(0.28952466, requires_grad=True), tensor(0.28794772, requires_grad=True), tensor(0.2863671, requires_grad=True), tensor(0.28478281, requires_grad=True), tensor(0.28319483, requires_grad=True), tensor(0.28160317, requires_grad=True), tensor(0.28000782, requires_grad=True), tensor(0.27840878, requires_grad=True), tensor(0.27680604, requires_grad=True), tensor(0.2751996, requires_grad=True), tensor(0.27358946, requires_grad=True), tensor(0.27197561, requires_grad=True), tensor(0.27035804, requires_grad=True), tensor(0.26873675, requires_grad=True), tensor(0.26711174, requires_grad=True), tensor(0.26548301, requires_grad=True), tensor(0.26385055, requires_grad=True), tensor(0.26221435, requires_grad=True), tensor(0.26057441, requires_grad=True), tensor(0.25893073, requires_grad=True), tensor(0.2572833, requires_grad=True), tensor(0.25563212, requires_grad=True), tensor(0.25397718, requires_grad=True), tensor(0.25231848, requires_grad=True), tensor(0.25065602, requires_grad=True), tensor(0.24898979, requires_grad=True), tensor(0.24731978, requires_grad=True), tensor(0.24564599, requires_grad=True), tensor(0.24396842, requires_grad=True), tensor(0.24228706, requires_grad=True), tensor(0.24060191, requires_grad=True), tensor(0.23891296, requires_grad=True), tensor(0.23722021, requires_grad=True), tensor(0.23552365, requires_grad=True), tensor(0.23382328, requires_grad=True), tensor(0.2321191, requires_grad=True), tensor(0.23041109, requires_grad=True), tensor(0.22869926, requires_grad=True), tensor(0.2269836, requires_grad=True), tensor(0.2252641, requires_grad=True), tensor(0.22354076, requires_grad=True), tensor(0.22181358, requires_grad=True), tensor(0.22008254, requires_grad=True), tensor(0.21834765, requires_grad=True), tensor(0.2166089, requires_grad=True), tensor(0.21486628, requires_grad=True), tensor(0.2131198, requires_grad=True), tensor(0.21136943, requires_grad=True), tensor(0.20961519, requires_grad=True), tensor(0.20785706, requires_grad=True), tensor(0.20609503, requires_grad=True), tensor(0.20432912, requires_grad=True), tensor(0.20255929, requires_grad=True), tensor(0.20078557, requires_grad=True), tensor(0.19900793, requires_grad=True), tensor(0.19722637, requires_grad=True), tensor(0.19544088, requires_grad=True), tensor(0.19365147, requires_grad=True), tensor(0.19185812, requires_grad=True), tensor(0.19006084, requires_grad=True), tensor(0.1882596, requires_grad=True), tensor(0.18645442, requires_grad=True), tensor(0.18464528, requires_grad=True), tensor(0.18283217, requires_grad=True), tensor(0.1810151, requires_grad=True), tensor(0.17919405, requires_grad=True), tensor(0.17736902, requires_grad=True), tensor(0.17554001, requires_grad=True), tensor(0.173707, requires_grad=True), tensor(0.17186999, requires_grad=True), tensor(0.17002898, requires_grad=True), tensor(0.16818396, requires_grad=True), tensor(0.16633493, requires_grad=True), tensor(0.16448187, requires_grad=True), tensor(0.16262478, requires_grad=True), tensor(0.16076366, requires_grad=True), tensor(0.1588985, requires_grad=True), tensor(0.15702929, requires_grad=True), tensor(0.15515602, requires_grad=True), tensor(0.1532787, requires_grad=True), tensor(0.15139731, requires_grad=True), tensor(0.14951185, requires_grad=True), tensor(0.1476223, requires_grad=True), tensor(0.14572867, requires_grad=True), tensor(0.14383095, requires_grad=True), tensor(0.14192912, requires_grad=True), tensor(0.14002319, requires_grad=True), tensor(0.13811315, requires_grad=True), tensor(0.13619899, requires_grad=True), tensor(0.1342807, requires_grad=True), tensor(0.13235827, requires_grad=True), tensor(0.13043171, requires_grad=True), tensor(0.12850099, requires_grad=True), tensor(0.12656613, requires_grad=True), tensor(0.12462709, requires_grad=True), tensor(0.12268389, requires_grad=True), tensor(0.12073651, requires_grad=True), tensor(0.11878495, requires_grad=True), tensor(0.1168292, requires_grad=True), tensor(0.11486924, requires_grad=True), tensor(0.11290508, requires_grad=True), tensor(0.11093671, requires_grad=True), tensor(0.10896411, requires_grad=True), tensor(0.10698728, requires_grad=True), tensor(0.10500621, requires_grad=True), tensor(0.1030209, requires_grad=True), tensor(0.10103134, requires_grad=True), tensor(0.09903751, requires_grad=True), tensor(0.09703942, requires_grad=True), tensor(0.09503704, requires_grad=True), tensor(0.09303038, requires_grad=True), tensor(0.09101943, requires_grad=True), tensor(0.08900417, requires_grad=True), tensor(0.0869846, requires_grad=True), tensor(0.08496072, requires_grad=True), tensor(0.0829325, requires_grad=True), tensor(0.08089995, requires_grad=True), tensor(0.07886305, requires_grad=True), tensor(0.0768218, requires_grad=True), tensor(0.07477619, requires_grad=True), tensor(0.0727262, requires_grad=True), tensor(0.07067183, requires_grad=True), tensor(0.06861308, requires_grad=True), tensor(0.06654992, requires_grad=True), tensor(0.06448235, requires_grad=True), tensor(0.06241037, requires_grad=True), tensor(0.06033396, requires_grad=True), tensor(0.05825311, requires_grad=True), tensor(0.05616781, requires_grad=True), tensor(0.05407806, requires_grad=True), tensor(0.05198385, requires_grad=True), tensor(0.04988515, requires_grad=True), tensor(0.04778197, requires_grad=True), tensor(0.0456743, requires_grad=True), tensor(0.04356211, requires_grad=True), tensor(0.04144542, requires_grad=True), tensor(0.03932419, requires_grad=True), tensor(0.03719843, requires_grad=True), tensor(0.03506812, requires_grad=True), tensor(0.03293325, requires_grad=True), tensor(0.03079381, requires_grad=True), tensor(0.02864979, requires_grad=True), tensor(0.02650117, requires_grad=True), tensor(0.02434796, requires_grad=True), tensor(0.02219013, requires_grad=True), tensor(0.02002768, requires_grad=True), tensor(0.01786059, requires_grad=True), tensor(0.01568885, requires_grad=True), tensor(0.01351245, requires_grad=True), tensor(0.01133138, requires_grad=True), tensor(0.00914563, requires_grad=True), tensor(0.00695518, requires_grad=True), tensor(0.00476002, requires_grad=True), tensor(0.00256014, requires_grad=True), tensor(0.00035553, requires_grad=True), tensor(-0.00185383, requires_grad=True), tensor(-0.00406795, requires_grad=True), tensor(-0.00628683, requires_grad=True), tensor(-0.0085105, requires_grad=True), tensor(-0.01073897, requires_grad=True), tensor(-0.01297225, requires_grad=True), tensor(-0.01521035, requires_grad=True), tensor(-0.01745329, requires_grad=True), tensor(-0.01970108, requires_grad=True), tensor(-0.02195374, requires_grad=True), tensor(-0.02421128, requires_grad=True), tensor(-0.02647371, requires_grad=True), tensor(-0.02874105, requires_grad=True), tensor(-0.03101331, requires_grad=True), tensor(-0.03329051, requires_grad=True), tensor(-0.03557266, requires_grad=True), tensor(-0.03785977, requires_grad=True), tensor(-0.04015188, requires_grad=True), tensor(-0.04244897, requires_grad=True), tensor(-0.04475109, requires_grad=True), tensor(-0.04705823, requires_grad=True), tensor(-0.04937041, requires_grad=True), tensor(-0.05168766, requires_grad=True), tensor(-0.05400999, requires_grad=True), tensor(-0.05633741, requires_grad=True), tensor(-0.05866994, requires_grad=True), tensor(-0.06100761, requires_grad=True), tensor(-0.06335041, requires_grad=True), tensor(-0.06569838, requires_grad=True), tensor(-0.06805154, requires_grad=True), tensor(-0.07040989, requires_grad=True), tensor(-0.07277345, requires_grad=True), tensor(-0.07514225, requires_grad=True), tensor(-0.07751631, requires_grad=True), tensor(-0.07989564, requires_grad=True), tensor(-0.08228026, requires_grad=True), tensor(-0.08467019, requires_grad=True), tensor(-0.08706546, requires_grad=True), tensor(-0.08946607, requires_grad=True), tensor(-0.09187205, requires_grad=True), tensor(-0.09428343, requires_grad=True), tensor(-0.09670022, requires_grad=True), tensor(-0.09912244, requires_grad=True), tensor(-0.10155012, requires_grad=True), tensor(-0.10398327, requires_grad=True), tensor(-0.10642192, requires_grad=True), tensor(-0.10886608, requires_grad=True), tensor(-0.1113158, requires_grad=True), tensor(-0.11377107, requires_grad=True), tensor(-0.11623194, requires_grad=True), tensor(-0.11869842, requires_grad=True), tensor(-0.12117053, requires_grad=True), tensor(-0.12364831, requires_grad=True), tensor(-0.12613177, requires_grad=True), tensor(-0.12862093, requires_grad=True), tensor(-0.13111584, requires_grad=True), tensor(-0.1336165, requires_grad=True), tensor(-0.13612296, requires_grad=True), tensor(-0.13863522, requires_grad=True), tensor(-0.14115333, requires_grad=True), tensor(-0.1436773, requires_grad=True), tensor(-0.14620717, requires_grad=True), tensor(-0.14874297, requires_grad=True), tensor(-0.15128471, requires_grad=True), tensor(-0.15383244, requires_grad=True), tensor(-0.15638618, requires_grad=True), tensor(-0.15894596, requires_grad=True), tensor(-0.16151182, requires_grad=True), tensor(-0.16408378, requires_grad=True), tensor(-0.16666187, requires_grad=True), tensor(-0.16924613, requires_grad=True), tensor(-0.17183659, requires_grad=True), tensor(-0.17443329, requires_grad=True), tensor(-0.17703625, requires_grad=True), tensor(-0.17964552, requires_grad=True), tensor(-0.18226112, requires_grad=True), tensor(-0.18488309, requires_grad=True), tensor(-0.18751148, requires_grad=True), tensor(-0.19014631, requires_grad=True), tensor(-0.19278763, requires_grad=True), tensor(-0.19543547, requires_grad=True), tensor(-0.19808987, requires_grad=True), tensor(-0.20075087, requires_grad=True), tensor(-0.20341852, requires_grad=True), tensor(-0.20609285, requires_grad=True), tensor(-0.2087739, requires_grad=True), tensor(-0.21146173, requires_grad=True), tensor(-0.21415637, requires_grad=True), tensor(-0.21685787, requires_grad=True), tensor(-0.21956627, requires_grad=True), tensor(-0.22228162, requires_grad=True), tensor(-0.22500398, requires_grad=True), tensor(-0.22773337, requires_grad=True), tensor(-0.23046987, requires_grad=True), tensor(-0.23321351, requires_grad=True), tensor(-0.23596435, requires_grad=True), tensor(-0.23872244, requires_grad=True), tensor(-0.24148784, requires_grad=True), tensor(-0.2442606, requires_grad=True), tensor(-0.24704078, requires_grad=True), tensor(-0.24982843, requires_grad=True), tensor(-0.25262361, requires_grad=True), tensor(-0.25542639, requires_grad=True), tensor(-0.25823683, requires_grad=True), tensor(-0.26105498, requires_grad=True), tensor(-0.26388092, requires_grad=True), tensor(-0.2667147, requires_grad=True), tensor(-0.26955641, requires_grad=True), tensor(-0.27240609, requires_grad=True), tensor(-0.27526384, requires_grad=True), tensor(-0.27812972, requires_grad=True), tensor(-0.2810038, requires_grad=True), tensor(-0.28388616, requires_grad=True), tensor(-0.28677688, requires_grad=True), tensor(-0.28967604, requires_grad=True), tensor(-0.29258373, requires_grad=True), tensor(-0.29550002, requires_grad=True), tensor(-0.298425, requires_grad=True), tensor(-0.30135877, requires_grad=True), tensor(-0.30430142, requires_grad=True), tensor(-0.30725303, requires_grad=True), tensor(-0.31021371, requires_grad=True), tensor(-0.31318356, requires_grad=True), tensor(-0.31616268, requires_grad=True), tensor(-0.31915117, requires_grad=True), tensor(-0.32214915, requires_grad=True), tensor(-0.32515672, requires_grad=True), tensor(-0.32817401, requires_grad=True), tensor(-0.33120113, requires_grad=True), tensor(-0.3342382, requires_grad=True), tensor(-0.33728535, requires_grad=True), tensor(-0.34034271, requires_grad=True), tensor(-0.34341042, requires_grad=True), tensor(-0.34648861, requires_grad=True), tensor(-0.34957743, requires_grad=True), tensor(-0.35267703, requires_grad=True), tensor(-0.35578757, requires_grad=True), tensor(-0.35890919, requires_grad=True), tensor(-0.36204208, requires_grad=True), tensor(-0.36518639, requires_grad=True), tensor(-0.36834231, requires_grad=True), tensor(-0.37151003, requires_grad=True), tensor(-0.37468972, requires_grad=True), tensor(-0.37788159, requires_grad=True), tensor(-0.38108585, requires_grad=True), tensor(-0.38430271, requires_grad=True), tensor(-0.3875324, requires_grad=True), tensor(-0.39077514, requires_grad=True), tensor(-0.39403118, requires_grad=True), tensor(-0.39730077, requires_grad=True), tensor(-0.40058417, requires_grad=True), tensor(-0.40388167, requires_grad=True), tensor(-0.40719354, requires_grad=True), tensor(-0.41052008, requires_grad=True), tensor(-0.41386163, requires_grad=True), tensor(-0.41721849, requires_grad=True), tensor(-0.42059102, requires_grad=True), tensor(-0.42397958, requires_grad=True), tensor(-0.42738456, requires_grad=True), tensor(-0.43080635, requires_grad=True), tensor(-0.43424538, requires_grad=True), tensor(-0.4377021, requires_grad=True), tensor(-0.44117697, requires_grad=True), tensor(-0.4446705, requires_grad=True), tensor(-0.44818321, requires_grad=True), tensor(-0.45171566, requires_grad=True), tensor(-0.45526844, requires_grad=True), tensor(-0.45884219, requires_grad=True), tensor(-0.46243758, requires_grad=True), tensor(-0.46605532, requires_grad=True), tensor(-0.46969617, requires_grad=True), tensor(-0.47336097, requires_grad=True), tensor(-0.47705059, requires_grad=True), tensor(-0.48076597, requires_grad=True), tensor(-0.48450813, requires_grad=True), tensor(-0.48827817, requires_grad=True), tensor(-0.49207729, requires_grad=True), tensor(-0.49590677, requires_grad=True), tensor(-0.49976803, requires_grad=True), tensor(-0.5036626, requires_grad=True), tensor(-0.50759216, requires_grad=True), tensor(-0.51155857, requires_grad=True), tensor(-0.51556388, requires_grad=True), tensor(-0.51961035, requires_grad=True), tensor(-0.5237005, requires_grad=True), tensor(-0.52783717, requires_grad=True), tensor(-0.53202352, requires_grad=True), tensor(-0.53626317, requires_grad=True), tensor(-0.5405602, requires_grad=True), tensor(-0.54491934, requires_grad=True), tensor(-0.54934603, requires_grad=True), tensor(-0.55384665, requires_grad=True), tensor(-0.5584287, requires_grad=True), tensor(-0.56310119, requires_grad=True), tensor(-0.56787498, requires_grad=True), tensor(-0.57276352, requires_grad=True), tensor(-0.57778363, requires_grad=True), tensor(-0.58295697, requires_grad=True), tensor(-0.5883122, requires_grad=True), tensor(-0.59388863, requires_grad=True), tensor(-0.59974275, requires_grad=True), tensor(-0.60596119, requires_grad=True), tensor(-0.61268958, requires_grad=True), tensor(-0.6202115, requires_grad=True), tensor(-0.62925806, requires_grad=True), tensor(-0.64751049, requires_grad=True), tensor(0.64751049, requires_grad=True), tensor(0.64785988, requires_grad=True), tensor(0.64820668, requires_grad=True), tensor(0.64855089, requires_grad=True), tensor(0.64889251, requires_grad=True), tensor(0.64923153, requires_grad=True), tensor(0.64956796, requires_grad=True), tensor(0.64990179, requires_grad=True), tensor(0.65023303, requires_grad=True), tensor(0.65056166, requires_grad=True), tensor(0.6508877, requires_grad=True), tensor(0.65121113, requires_grad=True), tensor(0.65153197, requires_grad=True), tensor(0.6518502, requires_grad=True), tensor(0.65216583, requires_grad=True), tensor(0.65247885, requires_grad=True), tensor(0.65278927, requires_grad=True), tensor(0.65309708, requires_grad=True), tensor(0.65340228, requires_grad=True), tensor(0.65370487, requires_grad=True), tensor(0.65400485, requires_grad=True), tensor(0.65430223, requires_grad=True), tensor(0.65459699, requires_grad=True), tensor(0.65488913, requires_grad=True), tensor(0.65517867, requires_grad=True), tensor(0.65546558, requires_grad=True), tensor(0.65574988, requires_grad=True), tensor(0.65603157, requires_grad=True), tensor(0.65631063, requires_grad=True), tensor(0.65658708, requires_grad=True), tensor(0.6568609, requires_grad=True), tensor(0.6571321, requires_grad=True), tensor(0.65740068, requires_grad=True), tensor(0.65766664, requires_grad=True), tensor(0.65792997, requires_grad=True), tensor(0.65819068, requires_grad=True), tensor(0.65844876, requires_grad=True), tensor(0.65870421, requires_grad=True), tensor(0.65895703, requires_grad=True), tensor(0.65920722, requires_grad=True), tensor(0.65945478, requires_grad=True), tensor(0.65969971, requires_grad=True), tensor(0.65994201, requires_grad=True), tensor(0.66018167, requires_grad=True), tensor(0.6604187, requires_grad=True), tensor(0.66065309, requires_grad=True), tensor(0.66088484, requires_grad=True), tensor(0.66111395, requires_grad=True), tensor(0.66134042, requires_grad=True), tensor(0.66156426, requires_grad=True), tensor(0.66178545, requires_grad=True), tensor(0.662004, requires_grad=True), tensor(0.6622199, requires_grad=True), tensor(0.66243316, requires_grad=True), tensor(0.66264378, requires_grad=True), tensor(0.66285174, requires_grad=True), tensor(0.66305706, requires_grad=True), tensor(0.66325973, requires_grad=True), tensor(0.66345975, requires_grad=True), tensor(0.66365712, requires_grad=True), tensor(0.66385184, requires_grad=True), tensor(0.6640439, requires_grad=True), tensor(0.66423331, requires_grad=True), tensor(0.66442006, requires_grad=True), tensor(0.66460416, requires_grad=True), tensor(0.6647856, requires_grad=True), tensor(0.66496438, requires_grad=True), tensor(0.6651405, requires_grad=True), tensor(0.66531396, requires_grad=True), tensor(0.66548476, requires_grad=True), tensor(0.66565289, requires_grad=True), tensor(0.66581836, requires_grad=True), tensor(0.66598117, requires_grad=True), tensor(0.66614131, requires_grad=True), tensor(0.66629878, requires_grad=True), tensor(0.66645359, requires_grad=True), tensor(0.66660572, requires_grad=True), tensor(0.66675519, requires_grad=True), tensor(0.66690198, requires_grad=True), tensor(0.6670461, requires_grad=True), tensor(0.66718755, requires_grad=True), tensor(0.66732632, requires_grad=True), tensor(0.66746242, requires_grad=True), tensor(0.66759584, requires_grad=True), tensor(0.66772658, requires_grad=True), tensor(0.66785464, requires_grad=True), tensor(0.66798002, requires_grad=True), tensor(0.66810273, requires_grad=True), tensor(0.66822275, requires_grad=True), tensor(0.66834008, requires_grad=True), tensor(0.66845474, requires_grad=True), tensor(0.6685667, requires_grad=True), tensor(0.66867598, requires_grad=True), tensor(0.66878258, requires_grad=True), tensor(0.66888648, requires_grad=True), tensor(0.66898769, requires_grad=True), tensor(0.66908622, requires_grad=True), tensor(0.66918205, requires_grad=True), tensor(0.66927519, requires_grad=True), tensor(0.66936564, requires_grad=True), tensor(0.66945339, requires_grad=True), tensor(0.66953844, requires_grad=True), tensor(0.6696208, requires_grad=True), tensor(0.66970046, requires_grad=True), tensor(0.66977741, requires_grad=True), tensor(0.66985167, requires_grad=True), tensor(0.66992323, requires_grad=True), tensor(0.66999208, requires_grad=True), tensor(0.67005824, requires_grad=True), tensor(0.67012168, requires_grad=True), tensor(0.67018242, requires_grad=True), tensor(0.67024046, requires_grad=True), tensor(0.67029578, requires_grad=True), tensor(0.6703484, requires_grad=True), tensor(0.6703983, requires_grad=True), tensor(0.6704455, requires_grad=True), tensor(0.67048998, requires_grad=True), tensor(0.67053175, requires_grad=True), tensor(0.6705708, requires_grad=True), tensor(0.67060714, requires_grad=True), tensor(0.67064076, requires_grad=True), tensor(0.67067167, requires_grad=True), tensor(0.67069985, requires_grad=True), tensor(0.67072532, requires_grad=True), tensor(0.67074806, requires_grad=True), tensor(0.67076808, requires_grad=True), tensor(0.67078538, requires_grad=True), tensor(0.67079996, requires_grad=True), tensor(0.6708118, requires_grad=True), tensor(0.67082093, requires_grad=True), tensor(0.67082732, requires_grad=True), tensor(0.67083099, requires_grad=True), tensor(0.67083192, requires_grad=True), tensor(0.67083013, requires_grad=True), tensor(0.6708256, requires_grad=True), tensor(0.67081834, requires_grad=True), tensor(0.67080834, requires_grad=True), tensor(0.67079561, requires_grad=True), tensor(0.67078015, requires_grad=True), tensor(0.67076194, requires_grad=True), tensor(0.670741, requires_grad=True), tensor(0.67071732, requires_grad=True), tensor(0.67069089, requires_grad=True), tensor(0.67066173, requires_grad=True), tensor(0.67062982, requires_grad=True), tensor(0.67059517, requires_grad=True), tensor(0.67055777, requires_grad=True), tensor(0.67051762, requires_grad=True), tensor(0.67047473, requires_grad=True), tensor(0.67042909, requires_grad=True), tensor(0.6703807, requires_grad=True), tensor(0.67032956, requires_grad=True), tensor(0.67027567, requires_grad=True), tensor(0.67021902, requires_grad=True), tensor(0.67015962, requires_grad=True), tensor(0.67009746, requires_grad=True), tensor(0.67003255, requires_grad=True), tensor(0.66996488, requires_grad=True), tensor(0.66989445, requires_grad=True), tensor(0.66982126, requires_grad=True), tensor(0.66974531, requires_grad=True), tensor(0.6696666, requires_grad=True), tensor(0.66958513, requires_grad=True), tensor(0.66950089, requires_grad=True), tensor(0.66941388, requires_grad=True), tensor(0.66932411, requires_grad=True), tensor(0.66923157, requires_grad=True), tensor(0.66913626, requires_grad=True), tensor(0.66903819, requires_grad=True), tensor(0.66893734, requires_grad=True), tensor(0.66883372, requires_grad=True), tensor(0.66872732, requires_grad=True), tensor(0.66861815, requires_grad=True), tensor(0.66850621, requires_grad=True), tensor(0.66839149, requires_grad=True), tensor(0.66827399, requires_grad=True), tensor(0.66815371, requires_grad=True), tensor(0.66803065, requires_grad=True), tensor(0.66790481, requires_grad=True), tensor(0.66777619, requires_grad=True), tensor(0.66764479, requires_grad=True), tensor(0.6675106, requires_grad=True), tensor(0.66737362, requires_grad=True), tensor(0.66723386, requires_grad=True), tensor(0.66709131, requires_grad=True), tensor(0.66694597, requires_grad=True), tensor(0.66679783, requires_grad=True), tensor(0.66664691, requires_grad=True), tensor(0.6664932, requires_grad=True), tensor(0.66633669, requires_grad=True), tensor(0.66617738, requires_grad=True), tensor(0.66601528, requires_grad=True), tensor(0.66585039, requires_grad=True), tensor(0.66568269, requires_grad=True), tensor(0.66551219, requires_grad=True), tensor(0.6653389, requires_grad=True), tensor(0.6651628, requires_grad=True), tensor(0.6649839, requires_grad=True), tensor(0.66480219, requires_grad=True), tensor(0.66461768, requires_grad=True), tensor(0.66443036, requires_grad=True), tensor(0.66424024, requires_grad=True), tensor(0.6640473, requires_grad=True), tensor(0.66385156, requires_grad=True), tensor(0.663653, requires_grad=True), tensor(0.66345163, requires_grad=True), tensor(0.66324745, requires_grad=True), tensor(0.66304045, requires_grad=True), tensor(0.66283064, requires_grad=True), tensor(0.66261801, requires_grad=True), tensor(0.66240256, requires_grad=True), tensor(0.6621843, requires_grad=True), tensor(0.66196321, requires_grad=True), tensor(0.6617393, requires_grad=True), tensor(0.66151256, requires_grad=True), tensor(0.66128301, requires_grad=True), tensor(0.66105062, requires_grad=True), tensor(0.66081541, requires_grad=True), tensor(0.66057738, requires_grad=True), tensor(0.66033651, requires_grad=True), tensor(0.66009281, requires_grad=True), tensor(0.65984629, requires_grad=True), tensor(0.65959693, requires_grad=True), tensor(0.65934473, requires_grad=True), tensor(0.6590897, requires_grad=True), tensor(0.65883184, requires_grad=True), tensor(0.65857114, requires_grad=True), tensor(0.65830759, requires_grad=True), tensor(0.65804121, requires_grad=True), tensor(0.65777199, requires_grad=True), tensor(0.65749993, requires_grad=True), tensor(0.65722502, requires_grad=True), tensor(0.65694727, requires_grad=True), tensor(0.65666667, requires_grad=True), tensor(0.65638323, requires_grad=True), tensor(0.65609694, requires_grad=True), tensor(0.6558078, requires_grad=True), tensor(0.6555158, requires_grad=True), tensor(0.65522096, requires_grad=True), tensor(0.65492326, requires_grad=True), tensor(0.65462271, requires_grad=True), tensor(0.65431931, requires_grad=True), tensor(0.65401304, requires_grad=True), tensor(0.65370392, requires_grad=True), tensor(0.65339194, requires_grad=True), tensor(0.6530771, requires_grad=True), tensor(0.6527594, requires_grad=True), tensor(0.65243883, requires_grad=True), tensor(0.65211541, requires_grad=True), tensor(0.65178911, requires_grad=True), tensor(0.65145995, requires_grad=True), tensor(0.65112792, requires_grad=True), tensor(0.65079302, requires_grad=True), tensor(0.65045526, requires_grad=True), tensor(0.65011462, requires_grad=True), tensor(0.64977111, requires_grad=True), tensor(0.64942472, requires_grad=True), tensor(0.64907546, requires_grad=True), tensor(0.64872332, requires_grad=True), tensor(0.64836831, requires_grad=True), tensor(0.64801042, requires_grad=True), tensor(0.64764964, requires_grad=True), tensor(0.64728599, requires_grad=True), tensor(0.64691945, requires_grad=True), tensor(0.64655003, requires_grad=True), tensor(0.64617772, requires_grad=True), tensor(0.64580253, requires_grad=True), tensor(0.64542444, requires_grad=True), tensor(0.64504347, requires_grad=True), tensor(0.64465961, requires_grad=True), tensor(0.64427286, requires_grad=True), tensor(0.64388322, requires_grad=True), tensor(0.64349068, requires_grad=True), tensor(0.64309524, requires_grad=True), tensor(0.64269691, requires_grad=True), tensor(0.64229568, requires_grad=True), tensor(0.64189156, requires_grad=True), tensor(0.64148453, requires_grad=True), tensor(0.6410746, requires_grad=True), tensor(0.64066176, requires_grad=True), tensor(0.64024603, requires_grad=True), tensor(0.63982738, requires_grad=True), tensor(0.63940583, requires_grad=True), tensor(0.63898138, requires_grad=True), tensor(0.63855401, requires_grad=True), tensor(0.63812373, requires_grad=True), tensor(0.63769054, requires_grad=True), tensor(0.63725444, requires_grad=True), tensor(0.63681542, requires_grad=True), tensor(0.63637348, requires_grad=True), tensor(0.63592863, requires_grad=True), tensor(0.63548086, requires_grad=True), tensor(0.63503017, requires_grad=True), tensor(0.63457656, requires_grad=True), tensor(0.63412003, requires_grad=True), tensor(0.63366057, requires_grad=True), tensor(0.63319819, requires_grad=True), tensor(0.63273288, requires_grad=True), tensor(0.63226464, requires_grad=True), tensor(0.63179347, requires_grad=True), tensor(0.63131937, requires_grad=True), tensor(0.63084235, requires_grad=True), tensor(0.63036238, requires_grad=True), tensor(0.62987949, requires_grad=True), tensor(0.62939366, requires_grad=True), tensor(0.62890489, requires_grad=True), tensor(0.62841318, requires_grad=True), tensor(0.62791853, requires_grad=True), tensor(0.62742094, requires_grad=True), tensor(0.62692041, requires_grad=True), tensor(0.62641694, requires_grad=True), tensor(0.62591051, requires_grad=True), tensor(0.62540115, requires_grad=True), tensor(0.62488883, requires_grad=True), tensor(0.62437357, requires_grad=True), tensor(0.62385535, requires_grad=True), tensor(0.62333419, requires_grad=True), tensor(0.62281007, requires_grad=True), tensor(0.62228299, requires_grad=True), tensor(0.62175296, requires_grad=True), tensor(0.62121997, requires_grad=True), tensor(0.62068402, requires_grad=True), tensor(0.62014511, requires_grad=True), tensor(0.61960324, requires_grad=True), tensor(0.61905841, requires_grad=True), tensor(0.61851061, requires_grad=True), tensor(0.61795985, requires_grad=True), tensor(0.61740612, requires_grad=True), tensor(0.61684942, requires_grad=True), tensor(0.61628975, requires_grad=True), tensor(0.61572711, requires_grad=True), tensor(0.6151615, requires_grad=True), tensor(0.61459291, requires_grad=True), tensor(0.61402135, requires_grad=True), tensor(0.61344681, requires_grad=True), tensor(0.61286929, requires_grad=True), tensor(0.61228879, requires_grad=True), tensor(0.61170531, requires_grad=True), tensor(0.61111885, requires_grad=True), tensor(0.6105294, requires_grad=True), tensor(0.60993697, requires_grad=True), tensor(0.60934155, requires_grad=True), tensor(0.60874314, requires_grad=True), tensor(0.60814175, requires_grad=True), tensor(0.60753736, requires_grad=True), tensor(0.60692998, requires_grad=True), tensor(0.6063196, requires_grad=True), tensor(0.60570623, requires_grad=True), tensor(0.60508986, requires_grad=True), tensor(0.6044705, requires_grad=True), tensor(0.60384813, requires_grad=True), tensor(0.60322276, requires_grad=True), tensor(0.60259439, requires_grad=True), tensor(0.60196302, requires_grad=True), tensor(0.60132864, requires_grad=True), tensor(0.60069125, requires_grad=True), tensor(0.60005085, requires_grad=True), tensor(0.59940744, requires_grad=True), tensor(0.59876102, requires_grad=True), tensor(0.59811159, requires_grad=True), tensor(0.59745915, requires_grad=True), tensor(0.59680368, requires_grad=True), tensor(0.5961452, requires_grad=True), tensor(0.5954837, requires_grad=True), tensor(0.59481918, requires_grad=True), tensor(0.59415164, requires_grad=True), tensor(0.59348107, requires_grad=True), tensor(0.59280748, requires_grad=True), tensor(0.59213086, requires_grad=True), tensor(0.59145122, requires_grad=True), tensor(0.59076854, requires_grad=True), tensor(0.59008284, requires_grad=True), tensor(0.5893941, requires_grad=True), tensor(0.58870232, requires_grad=True), tensor(0.58800751, requires_grad=True), tensor(0.58730966, requires_grad=True), tensor(0.58660878, requires_grad=True), tensor(0.58590485, requires_grad=True), tensor(0.58519788, requires_grad=True), tensor(0.58448787, requires_grad=True), tensor(0.58377482, requires_grad=True), tensor(0.58305871, requires_grad=True), tensor(0.58233956, requires_grad=True), tensor(0.58161736, requires_grad=True), tensor(0.58089211, requires_grad=True), tensor(0.5801638, requires_grad=True), tensor(0.57943244, requires_grad=True), tensor(0.57869803, requires_grad=True), tensor(0.57796056, requires_grad=True), tensor(0.57722002, requires_grad=True), tensor(0.57647643, requires_grad=True), tensor(0.57572978, requires_grad=True), tensor(0.57498006, requires_grad=True), tensor(0.57422727, requires_grad=True), tensor(0.57347142, requires_grad=True), tensor(0.5727125, requires_grad=True), tensor(0.57195051, requires_grad=True), tensor(0.57118545, requires_grad=True), tensor(0.57041731, requires_grad=True), tensor(0.5696461, requires_grad=True), tensor(0.56887182, requires_grad=True), tensor(0.56809445, requires_grad=True), tensor(0.56731401, requires_grad=True), tensor(0.56653048, requires_grad=True), tensor(0.56574387, requires_grad=True), tensor(0.56495417, requires_grad=True), tensor(0.56416139, requires_grad=True), tensor(0.56336552, requires_grad=True), tensor(0.56256656, requires_grad=True), tensor(0.56176451, requires_grad=True), tensor(0.56095936, requires_grad=True), tensor(0.56015112, requires_grad=True), tensor(0.55933979, requires_grad=True), tensor(0.55852535, requires_grad=True), tensor(0.55770782, requires_grad=True), tensor(0.55688718, requires_grad=True), tensor(0.55606344, requires_grad=True), tensor(0.5552366, requires_grad=True), tensor(0.55440665, requires_grad=True), tensor(0.55357359, requires_grad=True), tensor(0.55273742, requires_grad=True), tensor(0.55189814, requires_grad=True), tensor(0.55105575, requires_grad=True), tensor(0.55021024, requires_grad=True), tensor(0.54936162, requires_grad=True), tensor(0.54850987, requires_grad=True), tensor(0.54765501, requires_grad=True), tensor(0.54679702, requires_grad=True), tensor(0.54593591, requires_grad=True), tensor(0.54507167, requires_grad=True), tensor(0.54420431, requires_grad=True), tensor(0.54333382, requires_grad=True), tensor(0.5424602, requires_grad=True), tensor(0.54158344, requires_grad=True), tensor(0.54070355, requires_grad=True), tensor(0.53982052, requires_grad=True), tensor(0.53893436, requires_grad=True), tensor(0.53804506, requires_grad=True), tensor(0.53715261, requires_grad=True), tensor(0.53625703, requires_grad=True), tensor(0.53535829, requires_grad=True), tensor(0.53445641, requires_grad=True), tensor(0.53355139, requires_grad=True), tensor(0.53264321, requires_grad=True), tensor(0.53173188, requires_grad=True), tensor(0.53081739, requires_grad=True), tensor(0.52989975, requires_grad=True), tensor(0.52897895, requires_grad=True), tensor(0.52805499, requires_grad=True), tensor(0.52712788, requires_grad=True), tensor(0.52619759, requires_grad=True), tensor(0.52526415, requires_grad=True), tensor(0.52432753, requires_grad=True), tensor(0.52338775, requires_grad=True), tensor(0.52244479, requires_grad=True), tensor(0.52149867, requires_grad=True), tensor(0.52054937, requires_grad=True), tensor(0.51959689, requires_grad=True), tensor(0.51864124, requires_grad=True), tensor(0.5176824, requires_grad=True), tensor(0.51672038, requires_grad=True), tensor(0.51575518, requires_grad=True), tensor(0.5147868, requires_grad=True), tensor(0.51381522, requires_grad=True), tensor(0.51284046, requires_grad=True), tensor(0.5118625, requires_grad=True), tensor(0.51088135, requires_grad=True), tensor(0.50989701, requires_grad=True), tensor(0.50890947, requires_grad=True), tensor(0.50791873, requires_grad=True), tensor(0.50692478, requires_grad=True), tensor(0.50592764, requires_grad=True), tensor(0.50492729, requires_grad=True), tensor(0.50392373, requires_grad=True), tensor(0.50291696, requires_grad=True), tensor(0.50190699, requires_grad=True), tensor(0.5008938, requires_grad=True), tensor(0.49987739, requires_grad=True), tensor(0.49885777, requires_grad=True), tensor(0.49783492, requires_grad=True), tensor(0.49680886, requires_grad=True), tensor(0.49577958, requires_grad=True), tensor(0.49474706, requires_grad=True), tensor(0.49371133, requires_grad=True), tensor(0.49267236, requires_grad=True), tensor(0.49163016, requires_grad=True), tensor(0.49058473, requires_grad=True), tensor(0.48953606, requires_grad=True), tensor(0.48848415, requires_grad=True), tensor(0.48742901, requires_grad=True), tensor(0.48637062, requires_grad=True), tensor(0.48530899, requires_grad=True), tensor(0.48424411, requires_grad=True), tensor(0.48317599, requires_grad=True), tensor(0.48210462, requires_grad=True), tensor(0.48102999, requires_grad=True), tensor(0.47995211, requires_grad=True), tensor(0.47887097, requires_grad=True), tensor(0.47778658, requires_grad=True), tensor(0.47669892, requires_grad=True), tensor(0.475608, requires_grad=True), tensor(0.47451382, requires_grad=True), tensor(0.47341637, requires_grad=True), tensor(0.47231565, requires_grad=True), tensor(0.47121166, requires_grad=True), tensor(0.47010439, requires_grad=True), tensor(0.46899385, requires_grad=True), tensor(0.46788004, requires_grad=True), tensor(0.46676294, requires_grad=True), tensor(0.46564255, requires_grad=True), tensor(0.46451889, requires_grad=True), tensor(0.46339194, requires_grad=True), tensor(0.46226169, requires_grad=True), tensor(0.46112816, requires_grad=True), tensor(0.45999133, requires_grad=True), tensor(0.45885121, requires_grad=True), tensor(0.45770779, requires_grad=True), tensor(0.45656107, requires_grad=True), tensor(0.45541104, requires_grad=True), tensor(0.45425771, requires_grad=True), tensor(0.45310107, requires_grad=True), tensor(0.45194113, requires_grad=True), tensor(0.45077787, requires_grad=True), tensor(0.4496113, requires_grad=True), tensor(0.44844141, requires_grad=True), tensor(0.4472682, requires_grad=True), tensor(0.44609167, requires_grad=True), tensor(0.44491182, requires_grad=True), tensor(0.44372864, requires_grad=True), tensor(0.44254213, requires_grad=True), tensor(0.44135229, requires_grad=True), tensor(0.44015912, requires_grad=True), tensor(0.43896261, requires_grad=True), tensor(0.43776277, requires_grad=True), tensor(0.43655958, requires_grad=True), tensor(0.43535305, requires_grad=True), tensor(0.43414318, requires_grad=True), tensor(0.43292995, requires_grad=True), tensor(0.43171338, requires_grad=True), tensor(0.43049346, requires_grad=True), tensor(0.42927018, requires_grad=True), tensor(0.42804354, requires_grad=True), tensor(0.42681354, requires_grad=True), tensor(0.42558018, requires_grad=True), tensor(0.42434346, requires_grad=True), tensor(0.42310336, requires_grad=True), tensor(0.4218599, requires_grad=True), tensor(0.42061306, requires_grad=True), tensor(0.41936285, requires_grad=True), tensor(0.41810926, requires_grad=True), tensor(0.41685229, requires_grad=True), tensor(0.41559194, requires_grad=True), tensor(0.4143282, requires_grad=True), tensor(0.41306107, requires_grad=True), tensor(0.41179056, requires_grad=True), tensor(0.41051664, requires_grad=True), tensor(0.40923934, requires_grad=True), tensor(0.40795863, requires_grad=True), tensor(0.40667452, requires_grad=True), tensor(0.40538701, requires_grad=True), tensor(0.40409609, requires_grad=True), tensor(0.40280177, requires_grad=True), tensor(0.40150403, requires_grad=True), tensor(0.40020287, requires_grad=True), tensor(0.3988983, requires_grad=True), tensor(0.39759031, requires_grad=True), tensor(0.39627889, requires_grad=True), tensor(0.39496405, requires_grad=True), tensor(0.39364578, requires_grad=True), tensor(0.39232408, requires_grad=True), tensor(0.39099894, requires_grad=True), tensor(0.38967037, requires_grad=True), tensor(0.38833836, requires_grad=True), tensor(0.3870029, requires_grad=True), tensor(0.385664, requires_grad=True), tensor(0.38432165, requires_grad=True), tensor(0.38297585, requires_grad=True), tensor(0.3816266, requires_grad=True), tensor(0.38027388, requires_grad=True), tensor(0.37891771, requires_grad=True), tensor(0.37755808, requires_grad=True), tensor(0.37619498, requires_grad=True), tensor(0.37482841, requires_grad=True), tensor(0.37345837, requires_grad=True), tensor(0.37208486, requires_grad=True), tensor(0.37070787, requires_grad=True), tensor(0.36932739, requires_grad=True), tensor(0.36794344, requires_grad=True), tensor(0.366556, requires_grad=True), tensor(0.36516506, requires_grad=True), tensor(0.36377064, requires_grad=True), tensor(0.36237272, requires_grad=True), tensor(0.3609713, requires_grad=True), tensor(0.35956638, requires_grad=True), tensor(0.35815796, requires_grad=True), tensor(0.35674602, requires_grad=True), tensor(0.35533058, requires_grad=True), tensor(0.35391162, requires_grad=True), tensor(0.35248914, requires_grad=True), tensor(0.35106314, requires_grad=True), tensor(0.34963362, requires_grad=True), tensor(0.34820057, requires_grad=True), tensor(0.346764, requires_grad=True), tensor(0.34532388, requires_grad=True), tensor(0.34388024, requires_grad=True), tensor(0.34243305, requires_grad=True), tensor(0.34098232, requires_grad=True), tensor(0.33952804, requires_grad=True), tensor(0.33807021, requires_grad=True), tensor(0.33660883, requires_grad=True), tensor(0.33514389, requires_grad=True), tensor(0.33367539, requires_grad=True), tensor(0.33220333, requires_grad=True), tensor(0.3307277, requires_grad=True), tensor(0.3292485, requires_grad=True), tensor(0.32776573, requires_grad=True), tensor(0.32627938, requires_grad=True), tensor(0.32478945, requires_grad=True), tensor(0.32329594, requires_grad=True), tensor(0.32179884, requires_grad=True), tensor(0.32029815, requires_grad=True), tensor(0.31879386, requires_grad=True), tensor(0.31728598, requires_grad=True), tensor(0.31577449, requires_grad=True), tensor(0.3142594, requires_grad=True), tensor(0.31274071, requires_grad=True), tensor(0.31121839, requires_grad=True), tensor(0.30969247, requires_grad=True), tensor(0.30816292, requires_grad=True), tensor(0.30662975, requires_grad=True), tensor(0.30509295, requires_grad=True), tensor(0.30355252, requires_grad=True), tensor(0.30200846, requires_grad=True), tensor(0.30046076, requires_grad=True), tensor(0.29890942, requires_grad=True), tensor(0.29735443, requires_grad=True), tensor(0.29579579, requires_grad=True), tensor(0.2942335, requires_grad=True), tensor(0.29266755, requires_grad=True), tensor(0.29109794, requires_grad=True), tensor(0.28952466, requires_grad=True), tensor(0.28794772, requires_grad=True), tensor(0.2863671, requires_grad=True), tensor(0.28478281, requires_grad=True), tensor(0.28319483, requires_grad=True), tensor(0.28160317, requires_grad=True), tensor(0.28000782, requires_grad=True), tensor(0.27840878, requires_grad=True), tensor(0.27680604, requires_grad=True), tensor(0.2751996, requires_grad=True), tensor(0.27358946, requires_grad=True), tensor(0.27197561, requires_grad=True), tensor(0.27035804, requires_grad=True), tensor(0.26873675, requires_grad=True), tensor(0.26711174, requires_grad=True), tensor(0.26548301, requires_grad=True), tensor(0.26385055, requires_grad=True), tensor(0.26221435, requires_grad=True), tensor(0.26057441, requires_grad=True), tensor(0.25893073, requires_grad=True), tensor(0.2572833, requires_grad=True), tensor(0.25563212, requires_grad=True), tensor(0.25397718, requires_grad=True), tensor(0.25231848, requires_grad=True), tensor(0.25065602, requires_grad=True), tensor(0.24898979, requires_grad=True), tensor(0.24731978, requires_grad=True), tensor(0.24564599, requires_grad=True), tensor(0.24396842, requires_grad=True), tensor(0.24228706, requires_grad=True), tensor(0.24060191, requires_grad=True), tensor(0.23891296, requires_grad=True), tensor(0.23722021, requires_grad=True), tensor(0.23552365, requires_grad=True), tensor(0.23382328, requires_grad=True), tensor(0.2321191, requires_grad=True), tensor(0.23041109, requires_grad=True), tensor(0.22869926, requires_grad=True), tensor(0.2269836, requires_grad=True), tensor(0.2252641, requires_grad=True), tensor(0.22354076, requires_grad=True), tensor(0.22181358, requires_grad=True), tensor(0.22008254, requires_grad=True), tensor(0.21834765, requires_grad=True), tensor(0.2166089, requires_grad=True), tensor(0.21486628, requires_grad=True), tensor(0.2131198, requires_grad=True), tensor(0.21136943, requires_grad=True), tensor(0.20961519, requires_grad=True), tensor(0.20785706, requires_grad=True), tensor(0.20609503, requires_grad=True), tensor(0.20432912, requires_grad=True), tensor(0.20255929, requires_grad=True), tensor(0.20078557, requires_grad=True), tensor(0.19900793, requires_grad=True), tensor(0.19722637, requires_grad=True), tensor(0.19544088, requires_grad=True), tensor(0.19365147, requires_grad=True), tensor(0.19185812, requires_grad=True), tensor(0.19006084, requires_grad=True), tensor(0.1882596, requires_grad=True), tensor(0.18645442, requires_grad=True), tensor(0.18464528, requires_grad=True), tensor(0.18283217, requires_grad=True), tensor(0.1810151, requires_grad=True), tensor(0.17919405, requires_grad=True), tensor(0.17736902, requires_grad=True), tensor(0.17554001, requires_grad=True), tensor(0.173707, requires_grad=True), tensor(0.17186999, requires_grad=True), tensor(0.17002898, requires_grad=True), tensor(0.16818396, requires_grad=True), tensor(0.16633493, requires_grad=True), tensor(0.16448187, requires_grad=True), tensor(0.16262478, requires_grad=True), tensor(0.16076366, requires_grad=True), tensor(0.1588985, requires_grad=True), tensor(0.15702929, requires_grad=True), tensor(0.15515602, requires_grad=True), tensor(0.1532787, requires_grad=True), tensor(0.15139731, requires_grad=True), tensor(0.14951185, requires_grad=True), tensor(0.1476223, requires_grad=True), tensor(0.14572867, requires_grad=True), tensor(0.14383095, requires_grad=True), tensor(0.14192912, requires_grad=True), tensor(0.14002319, requires_grad=True), tensor(0.13811315, requires_grad=True), tensor(0.13619899, requires_grad=True), tensor(0.1342807, requires_grad=True), tensor(0.13235827, requires_grad=True), tensor(0.13043171, requires_grad=True), tensor(0.12850099, requires_grad=True), tensor(0.12656613, requires_grad=True), tensor(0.12462709, requires_grad=True), tensor(0.12268389, requires_grad=True), tensor(0.12073651, requires_grad=True), tensor(0.11878495, requires_grad=True), tensor(0.1168292, requires_grad=True), tensor(0.11486924, requires_grad=True), tensor(0.11290508, requires_grad=True), tensor(0.11093671, requires_grad=True), tensor(0.10896411, requires_grad=True), tensor(0.10698728, requires_grad=True), tensor(0.10500621, requires_grad=True), tensor(0.1030209, requires_grad=True), tensor(0.10103134, requires_grad=True), tensor(0.09903751, requires_grad=True), tensor(0.09703942, requires_grad=True), tensor(0.09503704, requires_grad=True), tensor(0.09303038, requires_grad=True), tensor(0.09101943, requires_grad=True), tensor(0.08900417, requires_grad=True), tensor(0.0869846, requires_grad=True), tensor(0.08496072, requires_grad=True), tensor(0.0829325, requires_grad=True), tensor(0.08089995, requires_grad=True), tensor(0.07886305, requires_grad=True), tensor(0.0768218, requires_grad=True), tensor(0.07477619, requires_grad=True), tensor(0.0727262, requires_grad=True), tensor(0.07067183, requires_grad=True), tensor(0.06861308, requires_grad=True), tensor(0.06654992, requires_grad=True), tensor(0.06448235, requires_grad=True), tensor(0.06241037, requires_grad=True), tensor(0.06033396, requires_grad=True), tensor(0.05825311, requires_grad=True), tensor(0.05616781, requires_grad=True), tensor(0.05407806, requires_grad=True), tensor(0.05198385, requires_grad=True), tensor(0.04988515, requires_grad=True), tensor(0.04778197, requires_grad=True), tensor(0.0456743, requires_grad=True), tensor(0.04356211, requires_grad=True), tensor(0.04144542, requires_grad=True), tensor(0.03932419, requires_grad=True), tensor(0.03719843, requires_grad=True), tensor(0.03506812, requires_grad=True), tensor(0.03293325, requires_grad=True), tensor(0.03079381, requires_grad=True), tensor(0.02864979, requires_grad=True), tensor(0.02650117, requires_grad=True), tensor(0.02434796, requires_grad=True), tensor(0.02219013, requires_grad=True), tensor(0.02002768, requires_grad=True), tensor(0.01786059, requires_grad=True), tensor(0.01568885, requires_grad=True), tensor(0.01351245, requires_grad=True), tensor(0.01133138, requires_grad=True), tensor(0.00914563, requires_grad=True), tensor(0.00695518, requires_grad=True), tensor(0.00476002, requires_grad=True), tensor(0.00256014, requires_grad=True), tensor(0.00035553, requires_grad=True), tensor(-0.00185383, requires_grad=True), tensor(-0.00406795, requires_grad=True), tensor(-0.00628683, requires_grad=True), tensor(-0.0085105, requires_grad=True), tensor(-0.01073897, requires_grad=True), tensor(-0.01297225, requires_grad=True), tensor(-0.01521035, requires_grad=True), tensor(-0.01745329, requires_grad=True), tensor(-0.01970108, requires_grad=True), tensor(-0.02195374, requires_grad=True), tensor(-0.02421128, requires_grad=True), tensor(-0.02647371, requires_grad=True), tensor(-0.02874105, requires_grad=True), tensor(-0.03101331, requires_grad=True), tensor(-0.03329051, requires_grad=True), tensor(-0.03557266, requires_grad=True), tensor(-0.03785977, requires_grad=True), tensor(-0.04015188, requires_grad=True), tensor(-0.04244897, requires_grad=True), tensor(-0.04475109, requires_grad=True), tensor(-0.04705823, requires_grad=True), tensor(-0.04937041, requires_grad=True), tensor(-0.05168766, requires_grad=True), tensor(-0.05400999, requires_grad=True), tensor(-0.05633741, requires_grad=True), tensor(-0.05866994, requires_grad=True), tensor(-0.06100761, requires_grad=True), tensor(-0.06335041, requires_grad=True), tensor(-0.06569838, requires_grad=True), tensor(-0.06805154, requires_grad=True), tensor(-0.07040989, requires_grad=True), tensor(-0.07277345, requires_grad=True), tensor(-0.07514225, requires_grad=True), tensor(-0.07751631, requires_grad=True), tensor(-0.07989564, requires_grad=True), tensor(-0.08228026, requires_grad=True), tensor(-0.08467019, requires_grad=True), tensor(-0.08706546, requires_grad=True), tensor(-0.08946607, requires_grad=True), tensor(-0.09187205, requires_grad=True), tensor(-0.09428343, requires_grad=True), tensor(-0.09670022, requires_grad=True), tensor(-0.09912244, requires_grad=True), tensor(-0.10155012, requires_grad=True), tensor(-0.10398327, requires_grad=True), tensor(-0.10642192, requires_grad=True), tensor(-0.10886608, requires_grad=True), tensor(-0.1113158, requires_grad=True), tensor(-0.11377107, requires_grad=True), tensor(-0.11623194, requires_grad=True), tensor(-0.11869842, requires_grad=True), tensor(-0.12117053, requires_grad=True), tensor(-0.12364831, requires_grad=True), tensor(-0.12613177, requires_grad=True), tensor(-0.12862093, requires_grad=True), tensor(-0.13111584, requires_grad=True), tensor(-0.1336165, requires_grad=True), tensor(-0.13612296, requires_grad=True), tensor(-0.13863522, requires_grad=True), tensor(-0.14115333, requires_grad=True), tensor(-0.1436773, requires_grad=True), tensor(-0.14620717, requires_grad=True), tensor(-0.14874297, requires_grad=True), tensor(-0.15128471, requires_grad=True), tensor(-0.15383244, requires_grad=True), tensor(-0.15638618, requires_grad=True), tensor(-0.15894596, requires_grad=True), tensor(-0.16151182, requires_grad=True), tensor(-0.16408378, requires_grad=True), tensor(-0.16666187, requires_grad=True), tensor(-0.16924613, requires_grad=True), tensor(-0.17183659, requires_grad=True), tensor(-0.17443329, requires_grad=True), tensor(-0.17703625, requires_grad=True), tensor(-0.17964552, requires_grad=True), tensor(-0.18226112, requires_grad=True), tensor(-0.18488309, requires_grad=True), tensor(-0.18751148, requires_grad=True), tensor(-0.19014631, requires_grad=True), tensor(-0.19278763, requires_grad=True), tensor(-0.19543547, requires_grad=True), tensor(-0.19808987, requires_grad=True), tensor(-0.20075087, requires_grad=True), tensor(-0.20341852, requires_grad=True), tensor(-0.20609285, requires_grad=True), tensor(-0.2087739, requires_grad=True), tensor(-0.21146173, requires_grad=True), tensor(-0.21415637, requires_grad=True), tensor(-0.21685787, requires_grad=True), tensor(-0.21956627, requires_grad=True), tensor(-0.22228162, requires_grad=True), tensor(-0.22500398, requires_grad=True), tensor(-0.22773337, requires_grad=True), tensor(-0.23046987, requires_grad=True), tensor(-0.23321351, requires_grad=True), tensor(-0.23596435, requires_grad=True), tensor(-0.23872244, requires_grad=True), tensor(-0.24148784, requires_grad=True), tensor(-0.2442606, requires_grad=True), tensor(-0.24704078, requires_grad=True), tensor(-0.24982843, requires_grad=True), tensor(-0.25262361, requires_grad=True), tensor(-0.25542639, requires_grad=True), tensor(-0.25823683, requires_grad=True), tensor(-0.26105498, requires_grad=True), tensor(-0.26388092, requires_grad=True), tensor(-0.2667147, requires_grad=True), tensor(-0.26955641, requires_grad=True), tensor(-0.27240609, requires_grad=True), tensor(-0.27526384, requires_grad=True), tensor(-0.27812972, requires_grad=True), tensor(-0.2810038, requires_grad=True), tensor(-0.28388616, requires_grad=True), tensor(-0.28677688, requires_grad=True), tensor(-0.28967604, requires_grad=True), tensor(-0.29258373, requires_grad=True), tensor(-0.29550002, requires_grad=True), tensor(-0.298425, requires_grad=True), tensor(-0.30135877, requires_grad=True), tensor(-0.30430142, requires_grad=True), tensor(-0.30725303, requires_grad=True), tensor(-0.31021371, requires_grad=True), tensor(-0.31318356, requires_grad=True), tensor(-0.31616268, requires_grad=True), tensor(-0.31915117, requires_grad=True), tensor(-0.32214915, requires_grad=True), tensor(-0.32515672, requires_grad=True), tensor(-0.32817401, requires_grad=True), tensor(-0.33120113, requires_grad=True), tensor(-0.3342382, requires_grad=True), tensor(-0.33728535, requires_grad=True), tensor(-0.34034271, requires_grad=True), tensor(-0.34341042, requires_grad=True), tensor(-0.34648861, requires_grad=True), tensor(-0.34957743, requires_grad=True), tensor(-0.35267703, requires_grad=True), tensor(-0.35578757, requires_grad=True), tensor(-0.35890919, requires_grad=True), tensor(-0.36204208, requires_grad=True), tensor(-0.36518639, requires_grad=True), tensor(-0.36834231, requires_grad=True), tensor(-0.37151003, requires_grad=True), tensor(-0.37468972, requires_grad=True), tensor(-0.37788159, requires_grad=True), tensor(-0.38108585, requires_grad=True), tensor(-0.38430271, requires_grad=True), tensor(-0.3875324, requires_grad=True), tensor(-0.39077514, requires_grad=True), tensor(-0.39403118, requires_grad=True), tensor(-0.39730077, requires_grad=True), tensor(-0.40058417, requires_grad=True), tensor(-0.40388167, requires_grad=True), tensor(-0.40719354, requires_grad=True), tensor(-0.41052008, requires_grad=True), tensor(-0.41386163, requires_grad=True), tensor(-0.41721849, requires_grad=True), tensor(-0.42059102, requires_grad=True), tensor(-0.42397958, requires_grad=True), tensor(-0.42738456, requires_grad=True), tensor(-0.43080635, requires_grad=True), tensor(-0.43424538, requires_grad=True), tensor(-0.4377021, requires_grad=True), tensor(-0.44117697, requires_grad=True), tensor(-0.4446705, requires_grad=True), tensor(-0.44818321, requires_grad=True), tensor(-0.45171566, requires_grad=True), tensor(-0.45526844, requires_grad=True), tensor(-0.45884219, requires_grad=True), tensor(-0.46243758, requires_grad=True), tensor(-0.46605532, requires_grad=True), tensor(-0.46969617, requires_grad=True), tensor(-0.47336097, requires_grad=True), tensor(-0.47705059, requires_grad=True), tensor(-0.48076597, requires_grad=True), tensor(-0.48450813, requires_grad=True), tensor(-0.48827817, requires_grad=True), tensor(-0.49207729, requires_grad=True), tensor(-0.49590677, requires_grad=True), tensor(-0.49976803, requires_grad=True), tensor(-0.5036626, requires_grad=True), tensor(-0.50759216, requires_grad=True), tensor(-0.51155857, requires_grad=True), tensor(-0.51556388, requires_grad=True), tensor(-0.51961035, requires_grad=True), tensor(-0.5237005, requires_grad=True), tensor(-0.52783717, requires_grad=True), tensor(-0.53202352, requires_grad=True), tensor(-0.53626317, requires_grad=True), tensor(-0.5405602, requires_grad=True), tensor(-0.54491934, requires_grad=True), tensor(-0.54934603, requires_grad=True), tensor(-0.55384665, requires_grad=True), tensor(-0.5584287, requires_grad=True), tensor(-0.56310119, requires_grad=True), tensor(-0.56787498, requires_grad=True), tensor(-0.57276352, requires_grad=True), tensor(-0.57778363, requires_grad=True), tensor(-0.58295697, requires_grad=True), tensor(-0.5883122, requires_grad=True), tensor(-0.59388863, requires_grad=True), tensor(-0.59974275, requires_grad=True), tensor(-0.60596119, requires_grad=True), tensor(-0.61268958, requires_grad=True), tensor(-0.6202115, requires_grad=True), tensor(-0.62925806, requires_grad=True), tensor(-0.64751049, requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "import pennylane as qml\n",
    "import numpy as np\n",
    "# dont touch ------------------------------------------------------------\n",
    "\n",
    "num_qubits = 6\n",
    "dev = qml.device(\"default.qubit\", wires=num_qubits)\n",
    "@qml.qnode(dev)\n",
    "def variational_circuit(params, num_layers, variable_values):\n",
    "\n",
    "    # feature maps\n",
    "    for i, value in enumerate(variable_values):\n",
    "        qml.RY(2 * np.arccos(np.clip(value, -1, 1)), wires=i)\n",
    "\n",
    "    # paramterized variational circuits\n",
    "    for layer in range(num_layers):\n",
    "        for i in range(len(variable_values)):\n",
    "            qml.RZ(params[layer, i, 0], wires=i)\n",
    "            qml.RX(params[layer, i, 1], wires=i)\n",
    "        for i in range(len(variable_values) - 1):\n",
    "            qml.CNOT(wires=[i, i + 1])\n",
    "    \n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(len(variable_values))]\n",
    "            \n",
    "# Function to calculate the cost fucntion\n",
    "def cost_fn(params, num_layers, variable_values):\n",
    "    ans =[]\n",
    "    total_cost = 0\n",
    "    num_iterations = variable_values.shape[1] if len(variable_values.shape) > 1 else variable_values.shape[0]\n",
    "    for i in range(num_iterations):\n",
    "        selected_values = variable_values[:, i] if len(variable_values.shape) > 1 else variable_values\n",
    "        outputs = variational_circuit(params, num_layers, selected_values)\n",
    "        for i in outputs:\n",
    "            ans.append(i)\n",
    "        # print(outputs)\n",
    "        # cost = np.sum(outputs)\n",
    "        # total_cost += cost\n",
    "    return ans\n",
    "\n",
    "num_layers = 4\n",
    "# Parameters for the variational circuit\n",
    "params = np.random.uniform(-np.pi / 2, np.pi / 2, size=(num_layers, num_qubits, 2))\n",
    "\n",
    "# To choose variables to encode\n",
    "chosen_variables = input(f\"Choose the variables to encode from the list {variable_names} (comma-separated): \")\n",
    "chosen_variables = [v.strip() for v in chosen_variables.split(',')]\n",
    "selected_values = np.concatenate([variable_values[v] for v in chosen_variables], axis=0)\n",
    "\n",
    "# To reshape\n",
    "selected_values = selected_values.reshape(1, -1)\n",
    "total_cost = cost_fn(params, num_layers, selected_values)\n",
    "print(f\"Total cost = {total_cost}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'total_cost' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mtotal_cost\u001b[49m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'total_cost' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(total_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid variable names chosen. Please choose from the provided list.\n"
     ]
    }
   ],
   "source": [
    "import pennylane as qml\n",
    "import numpy as np\n",
    " \n",
    "# trail 1 -------------------------------------------------------------------------------------------\n",
    "\n",
    "num_qubits = 12\n",
    "dev = qml.device(\"default.qubit\", wires=num_qubits)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def variational_circuit(params, num_layers, variable_values):\n",
    "  # Feature maps (unchanged)\n",
    "  for i, values in enumerate(variable_values):\n",
    "    for j, value in enumerate(values):\n",
    "      qml.RY(2 * np.arccos(np.clip(value, -1, 1)), wires=j + i * len(values))\n",
    "\n",
    "  # Parameterized variational circuits\n",
    "  for layer in range(num_layers):  # Increased layers to 4\n",
    "    for i, values in enumerate(variable_values):\n",
    "      for j, value in enumerate(values):\n",
    "        qml.RZ(params[layer, i, j, 0], wires=j + i * len(values))\n",
    "        qml.RX(params[layer, i, j, 1], wires=j + i * len(values))\n",
    "        qml.Hadamard(wires=j + i * len(values))  # Replaced RX with Hadamard\n",
    "\n",
    "  # Entangling gates (unchanged)\n",
    "  for i, values in enumerate(variable_values):\n",
    "    for j in range(len(values) - 1):\n",
    "      qml.CNOT(wires=[j + i * len(values), j + 1 + i * len(values)])\n",
    "\n",
    "  # Output measurement (unchanged)\n",
    "  return [qml.expval(qml.PauliZ(i)) for i in range(sum(len(values) for values in variable_values))]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def cost_fn(params, num_layers, variable_values):\n",
    "    ans = []\n",
    "    total_cost = 0\n",
    "    num_iterations = variable_values[0].shape[0] if len(variable_values[0].shape) > 1 else variable_values[0].shape[0]\n",
    "    for i in range(num_iterations):\n",
    "        selected_values = [values[i] for values in variable_values]\n",
    "        outputs = variational_circuit(params, num_layers, selected_values)\n",
    "        for i in outputs:\n",
    "            ans.append(i)\n",
    "    return ans\n",
    "\n",
    "\n",
    "\n",
    "# Define the number of layers in the variational circuit\n",
    "num_layers = 4\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Ask the user which variables to encode\n",
    "chosen_variables = input(f\"Choose the variables to encode from the list {variable_names} (comma-separated): \")\n",
    "chosen_variables = [v.strip() for v in chosen_variables.split(',')]\n",
    "\n",
    "# Check if the chosen variables are valid\n",
    "valid_chosen_variables = [v for v in chosen_variables if v in variable_names]\n",
    "valid_chosen_indices = [variable_names.index(v) for v in valid_chosen_variables]\n",
    "\n",
    "if len(valid_chosen_variables) != len(chosen_variables):\n",
    "    print(\"Invalid variable names chosen. Please choose from the provided list.\")\n",
    "else:\n",
    "    # Create the selected_values list based on the chosen variables\n",
    "    if len(valid_chosen_indices) > 0:\n",
    "        selected_values = [variable_values[i] for i in range(len(valid_chosen_indices))]\n",
    "    else:\n",
    "        print(\"No variables chosen. Please choose at least one variable.\")\n",
    "    # Generate random parameters for the variational circuit\n",
    "    params = np.random.uniform(-np.pi / 2, np.pi / 2, size=(num_layers, len(selected_values), 6, 2))\n",
    "\n",
    "    # Calculate the total cost\n",
    "    total_cost = cost_fn(params, num_layers, selected_values)\n",
    "    print(f\"Total cost = {total_cost}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cost = 132.51610175803373\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "num_qubits = 6\n",
    "dev = qml.device(\"default.qubit\", wires=num_qubits)\n",
    "@qml.qnode(dev)\n",
    "def variational_circuit(params, num_layers, variable_values):\n",
    "\n",
    "    # feature maps\n",
    "    for i, value in enumerate(variable_values):\n",
    "        qml.RY(2 * np.arccos(np.clip(value, -1, 1)), wires=i)\n",
    "\n",
    "    # paramterized variational circuits\n",
    "    for layer in range(num_layers):\n",
    "        for i in range(len(variable_values)):\n",
    "            qml.RZ(params[layer, i, 0], wires=i)\n",
    "            qml.RX(params[layer, i, 0], wires=i)\n",
    "            qml.RZ(params[layer, i, 0], wires=i)\n",
    "        for i in range(len(variable_values) - 1):\n",
    "            qml.CNOT(wires=[i, i + 1])\n",
    "    \n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(len(variable_values))]\n",
    "            \n",
    "# Function to calculate the cost fucntion\n",
    "def cost_fn(params, num_layers, variable_values):\n",
    "    total_cost = 0\n",
    "    num_iterations = variable_values.shape[1] if len(variable_values.shape) > 1 else variable_values.shape[0]\n",
    "    for i in range(num_iterations):\n",
    "        selected_values = variable_values[:, i] if len(variable_values.shape) > 1 else variable_values\n",
    "        outputs = variational_circuit(params, num_layers, selected_values)\n",
    "        cost = np.sum(outputs)\n",
    "        total_cost += cost\n",
    "    return total_cost\n",
    "\n",
    "num_layers = 4\n",
    "# Parameters for the variational circuit\n",
    "params = np.random.uniform(-np.pi / 2, np.pi / 2, size=(num_layers, num_qubits, 2))\n",
    "\n",
    "# To choose variables to encode\n",
    "chosen_variables = input(f\"Choose the variables to encode from the list {variable_names} (comma-separated): \")\n",
    "chosen_variables = [v.strip() for v in chosen_variables.split(',')]\n",
    "selected_values = np.concatenate([variable_values[v] for v in chosen_variables], axis=0)\n",
    "\n",
    "# To reshape\n",
    "selected_values = selected_values.reshape(1, -1)\n",
    "total_cost = cost_fn(params, num_layers, selected_values)\n",
    "print(f\"Total cost = {total_cost}\")\n",
    "# print(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# derivative circuit\n",
    "def compute_derivatives_for_variables(cost_fn, variable_names, variable_values, shift, num_layers, params):\n",
    "    derivatives = []\n",
    "    # To select the variables to differentiate\n",
    "    for variable_to_differentiate in variable_names:\n",
    "        num_orders = int(input(f\"Enter the number of orders for {variable_to_differentiate}: \"))\n",
    "        if num_orders <= 0:\n",
    "            print(\"Number of orders must be positive.\")\n",
    "            continue\n",
    "\n",
    "        for j in range(1, num_orders + 1):\n",
    "            variable_values_plus = variable_values.copy()\n",
    "            variable_values_minus = variable_values.copy()\n",
    "\n",
    "            # To apply the shift n times for the n-th order derivative\n",
    "            for _ in range(j):\n",
    "                variable_values_plus[variable_to_differentiate] = [(a + shift) for a in variable_values_plus[variable_to_differentiate]]\n",
    "                variable_values_minus[variable_to_differentiate] = [(a - shift) for a in variable_values_minus[variable_to_differentiate]]\n",
    "\n",
    "            # To reshape the variable values to (1, -1)\n",
    "            variable_values_plus_reshaped = np.array([variable_values_plus[variable_to_differentiate]]).reshape(1, -1)\n",
    "            variable_values_minus_reshaped = np.array([variable_values_minus[variable_to_differentiate]]).reshape(1, -1)\n",
    "\n",
    "            # Passing the shifted values to the circuit to get the output (fucntion values) for those set of inputs\n",
    "            output_plus = cost_fn(params, num_layers, variable_values_plus_reshaped)\n",
    "            output_minus = cost_fn(params, num_layers, variable_values_minus_reshaped)\n",
    "\n",
    "            derivative = (output_plus - output_minus) / (2 * shift ** j)\n",
    "            derivatives.append((variable_to_differentiate, j, derivative))\n",
    "\n",
    "    return derivatives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'list' and 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m shift \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3.14\u001b[39m\n\u001b[1;32m----> 2\u001b[0m derivatives \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_derivatives_for_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcost_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariable_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariable_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshift\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(derivatives)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# The first value is the variable, then the order of differentiation, and final value is the derivative\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[12], line 28\u001b[0m, in \u001b[0;36mcompute_derivatives_for_variables\u001b[1;34m(cost_fn, variable_names, variable_values, shift, num_layers, params)\u001b[0m\n\u001b[0;32m     25\u001b[0m         output_plus \u001b[38;5;241m=\u001b[39m cost_fn(params, num_layers, variable_values_plus_reshaped)\n\u001b[0;32m     26\u001b[0m         output_minus \u001b[38;5;241m=\u001b[39m cost_fn(params, num_layers, variable_values_minus_reshaped)\n\u001b[1;32m---> 28\u001b[0m         derivative \u001b[38;5;241m=\u001b[39m (\u001b[43moutput_plus\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moutput_minus\u001b[49m) \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m shift \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m j)\n\u001b[0;32m     29\u001b[0m         derivatives\u001b[38;5;241m.\u001b[39mappend((variable_to_differentiate, j, derivative))\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m derivatives\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'list' and 'list'"
     ]
    }
   ],
   "source": [
    "shift = 3.14\n",
    "derivatives = compute_derivatives_for_variables(cost_fn, variable_names, variable_values, shift, num_layers, params)\n",
    "print(derivatives)\n",
    "# The first value is the variable, then the order of differentiation, and final value is the derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Derivatives:\n",
      "Variable: t, Order: 1, Value: -9.051499818600002e-15\n",
      "Variable: x, Order: 1, Value: -9.051499818600002e-15\n",
      "Variable: x, Order: 2, Value: -2.882643254331211e-15\n",
      "Variable: y, Order: 1, Value: -9.051499818600002e-15\n",
      "Variable: y, Order: 2, Value: -2.882643254331211e-15\n",
      "PDE value: -5.20845321516217e-12\n"
     ]
    }
   ],
   "source": [
    "# To calculate the PDE value from the fucntion and the derivative values \n",
    "\n",
    "def calculate_PDE_from_derivatives(derivatives, variable_names, total_cost):\n",
    "    print(\"Derivatives:\")\n",
    "    for derivative in derivatives:\n",
    "        print(f\"Variable: {derivative[0]}, Order: {derivative[1]}, Value: {derivative[2]}\")\n",
    "    \n",
    "    # To get the number of derivative and non-derivative terms in the PDE expression\n",
    "    num_derivative_terms = int(input(\"Enter the number of derivative terms in the PDE: \"))\n",
    "    num_non_derivative_terms = int(input(\"Enter the number of non-derivative terms in the PDE: \"))\n",
    "    \n",
    "    PDE_value = 0\n",
    "    # To get the details of the derivative terms\n",
    "    for _ in range(num_derivative_terms):\n",
    "        variable = input(f\"Enter variable for the derivative term from the list {variable_names}: \")\n",
    "        order = int(input(f\"Enter the order of the derivative for {variable}: \"))\n",
    "        coefficient_input = input(f\"Enter the coefficient for the derivative term with {variable} of order {order} (can be a variable, 'total_cost', or numerical value): \")\n",
    "        \n",
    "        # To check if the coefficient of the derivative is the mutliplied by fucntion value(as in non linear PDE) or just a numerical value\n",
    "        if coefficient_input in variable_names:\n",
    "            coefficient = float(input(f\"Enter value for the variable {coefficient_input}: \"))\n",
    "            \n",
    "        elif coefficient_input == 'total_cost':\n",
    "            coefficient = total_cost\n",
    "        else:\n",
    "            coefficient = float(coefficient_input)\n",
    "        selected_derivative = None\n",
    "        for derivative in derivatives:\n",
    "            if derivative[0] == variable and derivative[1] == order:\n",
    "                selected_derivative = derivative[2]\n",
    "                break\n",
    "        if selected_derivative is not None:\n",
    "            PDE_value += coefficient * selected_derivative\n",
    "        else:\n",
    "            return f\"Derivative value not found for variable {variable} with order {order}.\"\n",
    "    \n",
    "    # To get the non derivative terms in the PDE \n",
    "\n",
    "    for _ in range(num_non_derivative_terms):\n",
    "        coefficient_input = input(\"Enter the coefficient for the non-derivative term : \") # this can also be a numerical coefficient or the fucntion value itslef\n",
    "        \n",
    "        if coefficient_input in variable_names:\n",
    "            coefficient = float(input(f\"Enter value for the variable {coefficient_input}: \"))\n",
    "        elif coefficient_input == 'total_cost':\n",
    "            coefficient = total_cost\n",
    "        else:\n",
    "            coefficient = float(coefficient_input)\n",
    "        \n",
    "        non_derivative_expr = input(\"Enter the expression for the non-derivative term : \")\n",
    "        variable_used = input(\"Which variable is used in the expression? Enter the variable name or 'total_cost': \")\n",
    "        \n",
    "        variable_values = {var: 0 for var in variable_names}\n",
    "        if variable_used in variable_names:\n",
    "            variable_values[variable_used] = float(input(f\"Enter value for the variable {variable_used}: \"))\n",
    "        elif variable_used == 'total_cost':\n",
    "            variable_values['total_cost'] = total_cost\n",
    "        \n",
    "        non_derivative_value = eval(non_derivative_expr, {\"__builtins__\": None}, variable_values)\n",
    "        PDE_value += coefficient * non_derivative_value\n",
    "    \n",
    "    return PDE_value\n",
    "\n",
    "# Final PDE value\n",
    "PDE_value = calculate_PDE_from_derivatives(derivatives, variable_names, total_cost)\n",
    "print(f\"PDE value: {PDE_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of variables: ['t', 'x', 'y']\n",
      "Initial Condition Expression: np.sin(x)*np.sin(y)\n",
      "Initial Condition Values: [0.00000000e+00 3.99999467e-06 1.59999147e-05 ... 8.29838530e-01\n",
      " 8.28332797e-01 8.26821810e-01]\n",
      "Boundary Condition Values: 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "global initial_condition_values, boundary_condition_values\n",
    "initial_condition_values = None\n",
    "boundary_condition_values = None\n",
    "\n",
    "# To get the initial condition\n",
    "def handle_initial_condition():\n",
    "    global initial_condition_values\n",
    "    print(\"List of variables:\", variable_names)\n",
    "    variables_in_condition = input(\"Enter the variables involved in the initial condition separated by commas: \").split(',')\n",
    "    \n",
    "    valid_variables = [var.strip() for var in variables_in_condition if var.strip() in variable_names]\n",
    "    \n",
    "    if len(valid_variables) == len(variables_in_condition):\n",
    "        initial_condition_expr = input(\"Enter the initial condition expression at t=0: \")\n",
    "        \n",
    "        variable_values_combinations = [variable_values[var] for var in valid_variables]\n",
    "        \n",
    "        try:\n",
    "            print(\"Initial Condition Expression:\", initial_condition_expr)\n",
    "            \n",
    "            initial_condition_values = []\n",
    "            for values in zip(*variable_values_combinations):\n",
    "                eval_context = {var: val for var, val in zip(valid_variables, values)}\n",
    "                eval_context.update({'np': np, 'math': math})\n",
    "                initial_condition = eval(initial_condition_expr, eval_context)\n",
    "                initial_condition_values.append(initial_condition)\n",
    "            \n",
    "            initial_condition_values = np.array(initial_condition_values)\n",
    "            return initial_condition_values\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(\"Invalid expression. Please enter a valid mathematical expression.\")\n",
    "            print(e)\n",
    "            return None\n",
    "    else:\n",
    "        print(\"Invalid variable selection. Please choose variables from the provided list.\")\n",
    "        return None\n",
    "\n",
    "# To get the boundary condition\n",
    "def handle_boundary_conditions():\n",
    "    global boundary_condition_values\n",
    "    boundary_condition_values = {}\n",
    "    \n",
    "    num_boundary_variables = int(input(\"Enter the number of variables involved in the boundary condition: \"))\n",
    "    \n",
    "    if num_boundary_variables == 0:\n",
    "        boundary_condition_expr = input(\"Enter the boundary condition value: \")\n",
    "        boundary_condition_values = float(boundary_condition_expr)\n",
    "        return boundary_condition_values\n",
    "    \n",
    "    variables_in_condition = []\n",
    "    \n",
    "    for _ in range(num_boundary_variables):\n",
    "        variable_name = input(f\"Enter the variable name for the boundary condition (from the list {variable_names}): \")\n",
    "        if variable_name in variable_values:\n",
    "            variables_in_condition.append(variable_name)\n",
    "        else:\n",
    "            print(\"Invalid variable selection. Please select a variable from the list of variables.\")\n",
    "            return None\n",
    "    \n",
    "    boundary_condition_expr = input(\"Enter the boundary condition expression: \")\n",
    "    \n",
    "    for variable_name in variables_in_condition:\n",
    "        boundary_values = variable_values[variable_name]\n",
    "        lowest_value = boundary_values[0]\n",
    "        highest_value = boundary_values[-1]\n",
    "        \n",
    "        print(f\"Values for variable {variable_name}: \")\n",
    "        for value in boundary_values:\n",
    "            print(value)\n",
    "        \n",
    "        boundary_type = input(f\"Enter the boundary type for {variable_name} (point/range): \")\n",
    "        \n",
    "        if boundary_type == 'point':\n",
    "            boundary_value = lowest_value\n",
    "        elif boundary_type == 'range':\n",
    "            lower_boundary_start = float(input(f\"Enter the starting value for the lower boundary condition (between {lowest_value} and {highest_value}): \"))\n",
    "            lower_boundary_end = float(input(f\"Enter the ending value for the lower boundary condition (between {lowest_value} and {highest_value}): \"))\n",
    "            upper_boundary_start = float(input(f\"Enter the starting value for the upper boundary condition (between {lowest_value} and {highest_value}): \"))\n",
    "            upper_boundary_end = float(input(f\"Enter the ending value for the upper boundary condition (between {lowest_value} and {highest_value}): \"))\n",
    "        else:\n",
    "            print(\"Invalid boundary type. Please enter 'point' or 'range'.\")\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            print(\"Boundary Condition Expression:\", boundary_condition_expr)\n",
    "            print(f\"Boundary Variable: {variable_name}\")\n",
    "            \n",
    "            if boundary_type == 'point':\n",
    "                print(f\"Boundary Value: {boundary_value}\")\n",
    "                boundary_condition_values[variable_name] = boundary_value\n",
    "            elif boundary_type == 'range':\n",
    "                print(f\"Lower Boundary Range: [{lower_boundary_start}, {lower_boundary_end}]\")\n",
    "                print(f\"Upper Boundary Range: [{upper_boundary_start}, {upper_boundary_end}]\")\n",
    "                \n",
    "                lower_boundary_values = [value for value in boundary_values if lower_boundary_start <= value <= lower_boundary_end]\n",
    "                upper_boundary_values = [value for value in boundary_values if upper_boundary_start <= value <= upper_boundary_end]\n",
    "                \n",
    "                lower_boundary_function_values = [eval(boundary_condition_expr, {variable_name: value, 'np': np, 'math': math}) for value in lower_boundary_values]\n",
    "                upper_boundary_function_values = [eval(boundary_condition_expr, {variable_name: value, 'np': np, 'math': math}) for value in upper_boundary_values]\n",
    "                \n",
    "                boundary_condition_values[variable_name] = {\n",
    "                    'lower_boundary_start': lower_boundary_start,\n",
    "                    'lower_boundary_end': lower_boundary_end,\n",
    "                    'lower_boundary_values': lower_boundary_values,\n",
    "                    'lower_boundary_function_values': lower_boundary_function_values,\n",
    "                    'upper_boundary_start': upper_boundary_start,\n",
    "                    'upper_boundary_end': upper_boundary_end,\n",
    "                    'upper_boundary_values': upper_boundary_values,\n",
    "                    'upper_boundary_function_values': upper_boundary_function_values\n",
    "                }\n",
    "                \n",
    "                print(f\"Lower Boundary Function Values for {variable_name}: {lower_boundary_function_values}\")\n",
    "                print(f\"Upper Boundary Function Values for {variable_name}: {upper_boundary_function_values}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(\"Invalid expression. Please enter a valid mathematical expression.\")\n",
    "            print(e)\n",
    "    \n",
    "    return boundary_condition_values\n",
    "\n",
    "# Function call\n",
    "condition_type = input(\"Enter the problem type (initial/boundary/both): \")\n",
    "\n",
    "if condition_type == 'initial':\n",
    "    handle_initial_condition()\n",
    "    print(\"Initial Condition Values:\", initial_condition_values)\n",
    "elif condition_type == 'boundary':\n",
    "    boundary_condition_values = handle_boundary_conditions()\n",
    "    print(\"Boundary Condition Values:\", boundary_condition_values)\n",
    "elif condition_type == 'both':\n",
    "    handle_initial_condition()\n",
    "    boundary_condition_values = handle_boundary_conditions()\n",
    "    print(\"Initial Condition Values:\", initial_condition_values)\n",
    "    print(\"Boundary Condition Values:\", boundary_condition_values)\n",
    "else:\n",
    "    print(\"Invalid input. Please enter 'initial' for an initial value problem, 'boundary' for a boundary value problem, or 'both' for both initial and boundary conditions.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001\n"
     ]
    }
   ],
   "source": [
    "print(len(initial_condition_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.217342284873293\n"
     ]
    }
   ],
   "source": [
    "def cost_fn_ic(params, num_layers, variable_values):\n",
    "    ic_loss_values = []\n",
    "    for values in variable_values:\n",
    "        selected_values = np.append(values, 0.0)  # t=0 for the initial condition\n",
    "        clipped_values = np.clip(selected_values.astype(float), -1, 1)\n",
    "        outputs = variational_circuit(params, num_layers, clipped_values)\n",
    "        ic_loss_values.append((outputs[0] - initial_condition_values[0]) ** 2)\n",
    "    return ic_loss_values\n",
    "for key in variable_values:\n",
    "    variable_values[key] = [float(value) for value in variable_values[key]]\n",
    "variable_values_list = list(zip(*[variable_values[key] for key in variable_values.keys()]))\n",
    "ic_loss_values = cost_fn_ic(params, num_layers, variable_values_list)\n",
    "print (np.mean(ic_loss_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.217342284873293\n"
     ]
    }
   ],
   "source": [
    "ic_loss = np.mean(ic_loss_values)\n",
    "print(ic_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7127984894533146e-23\n"
     ]
    }
   ],
   "source": [
    "pde_loss = ((PDE_value - 0) ** 2)\n",
    "print(pde_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.217342284873293\n"
     ]
    }
   ],
   "source": [
    "def calculate_loss(PDE_value, ic_loss, bc_loss, ic_weight=1.0, bc_weight=1.0):\n",
    "    pde_loss = np.mean((PDE_value - 0) ** 2)\n",
    "\n",
    "    condition_type = input(\"Enter whether the problem is initial, boundary or both: \").strip().lower()\n",
    "\n",
    "    if condition_type == 'initial':\n",
    "        total_loss = pde_loss + ic_weight * np.mean([np.mean(value) for value in ic_loss.values()])\n",
    "    elif condition_type == 'boundary':\n",
    "        total_loss = pde_loss + bc_weight * bc_loss\n",
    "    else:\n",
    "\n",
    "        total_loss = pde_loss + ic_weight * np.mean(ic_loss) + bc_weight * bc_loss\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "ic_loss = np.mean(ic_loss_values)\n",
    "bc_loss = 0\n",
    "\n",
    "total_loss = calculate_loss(PDE_value, ic_loss, bc_loss, ic_weight=1.0, bc_weight=1.0)\n",
    "print(total_loss)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 2-dimensional, but 3 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[90], line 29\u001b[0m\n\u001b[0;32m     25\u001b[0m params \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39mpi \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, np\u001b[38;5;241m.\u001b[39mpi \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, size\u001b[38;5;241m=\u001b[39m(num_layers, num_parameters))\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Assuming `variable_values` is defined elsewhere and represents qubit states\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Calculate the PDE value and initial condition loss (same as before)\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m PDE_value \u001b[38;5;241m=\u001b[39m \u001b[43mvariational_circuit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariable_values\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m ic_loss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean([np\u001b[38;5;241m.\u001b[39mmean(value) \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m ic_loss_values\u001b[38;5;241m.\u001b[39mvalues()])\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Run the gradient descent algorithm\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pennylane\\qnode.py:976\u001b[0m, in \u001b[0;36mQNode.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    973\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshots\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _get_device_shots(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_device)\n\u001b[0;32m    975\u001b[0m \u001b[38;5;66;03m# construct the tape\u001b[39;00m\n\u001b[1;32m--> 976\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    978\u001b[0m cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute_kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    979\u001b[0m using_custom_cache \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    980\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(cache, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitem__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    981\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(cache, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__setitem__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    982\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(cache, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__delitem__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    983\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pennylane\\qnode.py:862\u001b[0m, in \u001b[0;36mQNode.construct\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterface \u001b[38;5;241m=\u001b[39m qml\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mget_interface(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mvalues()))\n\u001b[0;32m    861\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m qml\u001b[38;5;241m.\u001b[39mqueuing\u001b[38;5;241m.\u001b[39mAnnotatedQueue() \u001b[38;5;28;01mas\u001b[39;00m q:\n\u001b[1;32m--> 862\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qfunc_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tape \u001b[38;5;241m=\u001b[39m QuantumScript\u001b[38;5;241m.\u001b[39mfrom_queue(q, shots)\n\u001b[0;32m    866\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtape\u001b[38;5;241m.\u001b[39mget_parameters(trainable_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[75], line 17\u001b[0m, in \u001b[0;36mvariational_circuit\u001b[1;34m(params, num_layers, variable_values)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_layers):\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(variable_values)):\n\u001b[1;32m---> 17\u001b[0m         qml\u001b[38;5;241m.\u001b[39mRZ(\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m, wires\u001b[38;5;241m=\u001b[39mi)\n\u001b[0;32m     18\u001b[0m         qml\u001b[38;5;241m.\u001b[39mRX(params[layer, i, \u001b[38;5;241m1\u001b[39m], wires\u001b[38;5;241m=\u001b[39mi)\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(variable_values) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m):\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 2-dimensional, but 3 were indexed"
     ]
    }
   ],
   "source": [
    "\n",
    "def gradient_descent(loss_fn, PDE_value, ic_loss, params, learning_rate, num_iterations):\n",
    "    losses = []\n",
    "    for i in range(num_iterations):\n",
    "        # Reshape the params array to have the desired shape for the circuit\n",
    "        params_2d = params.reshape((num_layers, num_parameters))  # 2D for layers and parameters\n",
    "\n",
    "        PDE_value = variational_circuit(params_2d, num_layers, variable_values.values())\n",
    "        ic_loss = np.mean([np.mean(value) for value in ic_loss_values.values()])\n",
    "        bc_loss = 0\n",
    "        loss = loss_fn(PDE_value, ic_loss, bc_loss)\n",
    "        gradients = np.zeros_like(params)\n",
    "        for j in range(len(params)):\n",
    "            gradients[j] = 2 * (PDE_value - 0) * np.mean([np.mean(value) for value in ic_loss_values.values()])\n",
    "\n",
    "        params -= learning_rate * gradients\n",
    "        losses.append(loss)\n",
    "\n",
    "    return params, losses\n",
    "\n",
    "\n",
    "num_iterations = 100\n",
    "learning_rate = 0.01\n",
    "num_parameters = 2  # Assuming two parameters per layer (e.g., RZ, RX)\n",
    "\n",
    "params = np.random.uniform(-np.pi / 2, np.pi / 2, size=(num_layers, num_parameters))\n",
    "\n",
    "# Assuming `variable_values` is defined elsewhere and represents qubit states\n",
    "# Calculate the PDE value and initial condition loss (same as before)\n",
    "PDE_value = variational_circuit(params, num_layers, variable_values.values())\n",
    "ic_loss = np.mean([np.mean(value) for value in ic_loss_values.values()])\n",
    "\n",
    "# Run the gradient descent algorithm\n",
    "params, losses = gradient_descent(calculate_loss, PDE_value, ic_loss, params, learning_rate, num_iterations)\n",
    "\n",
    "print(f\"Final Loss: {losses[-1]}\")\n",
    "print(f\"Updated Parameters: {params}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
