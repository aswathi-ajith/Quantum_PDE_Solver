{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1267a34",
   "metadata": {},
   "source": [
    "Code done by;        Aswathi Ajith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31630c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pennylane as qml\n",
    "\n",
    "import math\n",
    "from pennylane.optimize import AdamOptimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f17d280",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8887e268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new testing\n"
     ]
    }
   ],
   "source": [
    "print(\"new testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7793cf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Variables for the PDE\n",
    "num_variables = int(input(\"Enter the number of variables for the PDE: \"))\n",
    "all_variable_orders = []\n",
    "all_variable_coefficients = []\n",
    "variable_names = []\n",
    "variable_indices = []\n",
    "variable_values = {}\n",
    "\n",
    "# vraible names, their order of differentiation, and coefficients of those variables's derivatives\n",
    "for i in range(num_variables):\n",
    "    variable_name = input(f\"Enter the name for variable {i + 1}: \")\n",
    "    variable_names.append(variable_name)\n",
    "    variable_indices.append(i)\n",
    "    num_orders = int(input(f\"Enter the number of derivatives for variable {variable_name}: \"))\n",
    "    orders = []\n",
    "    coefficients = []\n",
    "\n",
    "    print(f\"Variable: {variable_name}\")\n",
    "    for j in range(num_orders):\n",
    "        order = int(input(f\"Enter the order for derivative {j + 1} with respect to {variable_name}: \"))\n",
    "        coefficient = input(f\"Enter the coefficient for derivative {j + 1} with respect to {variable_name} (as a function of {variable_name}): \")\n",
    "        orders.append(order)\n",
    "        coefficients.append(coefficient)\n",
    "\n",
    "    # To get the range values of variables\n",
    "    low_value = float(input(f\"Enter the low value for variable {variable_name}: \"))\n",
    "    high_value = float(input(f\"Enter the high value for variable {variable_name}: \"))\n",
    "    # Discretizing the range with certain step size value\n",
    "    step_size = float(input(f\"Enter the step size for generating random numbers for variable {variable_name}: \"))\n",
    "\n",
    "    random_values = np.linspace(low_value, high_value, int((high_value - low_value) / step_size) + 1)\n",
    "    print(f\"Values for {variable_name}:\")\n",
    "    for value in random_values:\n",
    "        print(value)\n",
    "\n",
    "    all_variable_orders.append(orders)\n",
    "    all_variable_coefficients.append(coefficients)\n",
    "    variable_values[variable_name] = random_values.tolist()  \n",
    "\n",
    "# Collect terms that are not derivatives in the PDE(e.g., u**2, sin(u), u, etc....)\n",
    "non_derivative_terms = []\n",
    "add_non_derivative_terms = input(\"Are there any non-derivative terms? type (yes/no): \").strip().lower()\n",
    "\n",
    "while add_non_derivative_terms == \"yes\":\n",
    "    term = input(\"Enter the non-derivative term : \")\n",
    "    non_derivative_terms.append(term)\n",
    "    add_non_derivative_terms = input(\"Is there any more non-derivative terms? (yes/no): \").strip().lower()\n",
    "\n",
    "# To print all info;\n",
    "print(\"Variable Names:\", variable_names)\n",
    "print(\"Variable Values:\", variable_values)\n",
    "print(\"Variable Orders:\", all_variable_orders)\n",
    "print(\"Variable Coefficients:\", all_variable_coefficients)\n",
    "print(\"Non-Derivative Terms:\", non_derivative_terms)\n",
    "\n",
    "# To construct the PDE expression\n",
    "def construct_pde_expression(variable_names, all_variable_orders, all_variable_coefficients, non_derivative_terms):\n",
    "    pde_expression = \"\"\n",
    "    \n",
    "    for i, (variable_name, orders, coefficients) in enumerate(zip(variable_names, all_variable_orders, all_variable_coefficients)):\n",
    "        for order, coeff in zip(orders, coefficients):\n",
    "            if \"lambda\" in coeff:  \n",
    "                term = f\"{coeff}*d^{order}u/d{variable_name}^{order}\"\n",
    "            else:\n",
    "                term = f\"{coeff}*d^{order}u/d{variable_name}^{order}\"\n",
    "            pde_expression += term + \" + \"\n",
    "\n",
    "    \n",
    "    for term in non_derivative_terms:\n",
    "        pde_expression += term + \" + \"\n",
    "    pde_expression = pde_expression[:-3] \n",
    "    return pde_expression\n",
    "\n",
    "\n",
    "pde_expression = construct_pde_expression(variable_names, all_variable_orders, all_variable_coefficients, non_derivative_terms)\n",
    "print(\"Constructed PDE:\", pde_expression)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecd7cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check\n",
    "variable_data = [(key, values) for key, values in variable_values.items()]\n",
    "for variable, values in variable_data:\n",
    "    print(f\"{variable} = {values}\",len(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f28ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cost_array =[]\n",
    "\n",
    "chosen_variables = input(\"Enter the names of the variables to encode (comma-separated): \").split(',')\n",
    "chosen_variables = [v.strip() for v in chosen_variables]\n",
    "\n",
    "\n",
    "variable_dict = dict(variable_data)\n",
    "for var in chosen_variables:\n",
    "    if var not in variable_dict:\n",
    "        raise ValueError(f\"Variable '{var}' is not in the list of available variables.\")\n",
    "\n",
    "\n",
    "selected_values = [variable_dict[var] for var in chosen_variables]\n",
    "selected_values = np.array(selected_values)\n",
    "print(f\"Selected values:\\n{selected_values}\")\n",
    "\n",
    "\n",
    "num_qubits = len(chosen_variables)\n",
    "\n",
    "\n",
    "dev = qml.device(\"default.qubit\", wires=num_qubits)\n",
    "\n",
    "# variational circuit\n",
    "@qml.qnode(dev)\n",
    "def variational_circuit(params, num_layers, variable_values):\n",
    "    # Feature maps\n",
    "    for i, value in enumerate(variable_values):\n",
    "        qml.RY(2 * np.arccos(np.clip(value, -1, 1)), wires=i)\n",
    "\n",
    "    # Parametrized variational circuits\n",
    "    for layer in range(num_layers):\n",
    "        for i in range(len(variable_values)):\n",
    "            qml.RZ(params[layer, i, 0], wires=i)\n",
    "            qml.RX(params[layer, i, 1], wires=i)\n",
    "            # ansatz reduced --------------------\n",
    "            \n",
    "        for i in range(len(variable_values) - 1):\n",
    "            qml.CNOT(wires=[i, i + 1])\n",
    "\n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(len(variable_values))]\n",
    "\n",
    "#  cost function\n",
    "def cost_fn(params, num_layers, variable_data, chosen_variables):\n",
    "    total_cost = 0\n",
    "    num_iterations = len(variable_data[0][1])\n",
    "  \n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        selected_values = [variable_data[var_idx][1][i] for var_idx, var in enumerate(variable_data) if var[0] in chosen_variables]\n",
    "        outputs = variational_circuit(params, num_layers, selected_values)\n",
    "        \n",
    "        cost = np.sum(outputs) #sigma(j)\n",
    "        total_cost += cost #sigma(cost)\n",
    "        print(f\"Iteration {i+1}:\")\n",
    "        print(f\"Variable Names: {chosen_variables}\")\n",
    "        print(f\"Variable Values: {selected_values}\")\n",
    "        print(f\"Cost: {cost}\")\n",
    "        print(\"outputs are\",outputs)\n",
    "        cost_array.append(cost)\n",
    "    \n",
    "    return total_cost,cost_array\n",
    "\n",
    "# number of layers\n",
    "num_layers = 6\n",
    "\n",
    "# Initialize the parameters\n",
    "np.random.seed(42)\n",
    "\n",
    "params = np.random.uniform(-2*np.pi, 2*np.pi, size=(num_layers, num_qubits, 3))\n",
    "\n",
    "\n",
    "# Calculate the cost\n",
    "total_cost, cost_array = cost_fn(params, num_layers, variable_data, chosen_variables)\n",
    "\n",
    "\n",
    "print(f\"Total cost = {total_cost}\")\n",
    "print(f\"The cost array is = {cost_array}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f78395c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def compute_derivatives_for_variables(cost_fn, variable_names, variable_data, chosen_variables, shift, num_layers, params):\n",
    "    derivatives = []\n",
    "    variable_dict = dict(variable_data)\n",
    "    \n",
    "    for variable_to_differentiate in variable_names:\n",
    "        num_orders = int(input(f\"Enter the number of orders for {variable_to_differentiate}: \"))\n",
    "        if num_orders <= 0:\n",
    "            print(\"Number of orders must be positive.\")\n",
    "            continue\n",
    "\n",
    "        for j in range(1, num_orders + 1):\n",
    "            variable_values_plus = {var: variable_dict[var][:] for var in variable_dict}\n",
    "            variable_values_minus = {var: variable_dict[var][:] for var in variable_dict}\n",
    "\n",
    "         \n",
    "            for _ in range(j):\n",
    "                variable_values_plus[variable_to_differentiate] = [a + shift for a in variable_values_plus[variable_to_differentiate]]\n",
    "                variable_values_minus[variable_to_differentiate] = [a - shift for a in variable_values_minus[variable_to_differentiate]]\n",
    "\n",
    "          \n",
    "            variable_data_plus = [(var, variable_values_plus[var]) for var in variable_dict]\n",
    "            variable_data_minus = [(var, variable_values_minus[var]) for var in variable_dict]\n",
    "            \n",
    "\n",
    "          \n",
    "            output_plus, _ = cost_fn(params, num_layers, variable_data_plus, chosen_variables)\n",
    "            output_minus, _ = cost_fn(params, num_layers, variable_data_minus, chosen_variables)\n",
    "            # print(output_minus)\n",
    "            # print(output_plus)\n",
    "\n",
    "     \n",
    "            derivative = (output_plus - output_minus) / (2)\n",
    "            derivatives.append((variable_to_differentiate, j, derivative))\n",
    "\n",
    "    return derivatives\n",
    "\n",
    "\n",
    "shift = 0.01  \n",
    "derivatives = compute_derivatives_for_variables(cost_fn, chosen_variables, variable_data, chosen_variables, shift, num_layers, params)\n",
    "print(derivatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a4539dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Derivatives:\n",
      "Variable: t, Order: 1, Value: 0.0\n",
      "Variable: t, Order: 2, Value: 0.0\n",
      "Variable: x, Order: 1, Value: -40.64954000193177\n",
      "Variable: x, Order: 2, Value: 0.0\n",
      "Variable: y, Order: 1, Value: -40.64954000193177\n",
      "Variable: y, Order: 2, Value: 0.0\n",
      "Variable: z, Order: 1, Value: -40.64954000193177\n",
      "Variable: z, Order: 2, Value: 0.0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 64\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m PDE_value\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# Final PDE value\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m PDE_value \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_PDE_from_derivatives\u001b[49m\u001b[43m(\u001b[49m\u001b[43mderivatives\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariable_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_cost\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPDE value: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPDE_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[14], line 9\u001b[0m, in \u001b[0;36mcalculate_PDE_from_derivatives\u001b[1;34m(derivatives, variable_names, total_cost)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVariable: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mderivative[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Order: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mderivative[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Value: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mderivative[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# To get the number of derivative and non-derivative terms in the PDE expression\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m num_derivative_terms \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEnter the number of derivative terms in the PDE: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m num_non_derivative_terms \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter the number of non-derivative terms in the PDE: \u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     12\u001b[0m PDE_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "# To calculate the PDE value from the fucntion and the derivative values \n",
    "\n",
    "def calculate_PDE_from_derivatives(derivatives, variable_names, total_cost):\n",
    "    print(\"Derivatives:\")\n",
    "    for derivative in derivatives:\n",
    "        print(f\"Variable: {derivative[0]}, Order: {derivative[1]}, Value: {derivative[2]}\")\n",
    "    \n",
    "    # To get the number of derivative and non-derivative terms in the PDE expression\n",
    "    num_derivative_terms = int(input(\"Enter the number of derivative terms in the PDE: \"))\n",
    "    num_non_derivative_terms = int(input(\"Enter the number of non-derivative terms in the PDE: \"))\n",
    "    \n",
    "    PDE_value = 0\n",
    "    # To get the details of the derivative terms\n",
    "    for _ in range(num_derivative_terms):\n",
    "        variable = input(f\"Enter variable for the derivative term from the list {variable_names}: \")\n",
    "        order = int(input(f\"Enter the order of the derivative for {variable}: \"))\n",
    "        coefficient_input = input(f\"Enter the coefficient for the derivative term with {variable} of order {order} (can be a variable, 'total_cost', or numerical value): \")\n",
    "        \n",
    "        # To check if the coefficient of the derivative is the mutliplied by fucntion value(as in non linear PDE) or just a numerical value\n",
    "        if coefficient_input in variable_names:\n",
    "            coefficient = float(input(f\"Enter value for the variable {coefficient_input}: \"))\n",
    "            \n",
    "        elif coefficient_input == 'total_cost':\n",
    "            coefficient = total_cost\n",
    "        else:\n",
    "            coefficient = float(coefficient_input)\n",
    "        selected_derivative = None\n",
    "        for derivative in derivatives:\n",
    "            if derivative[0] == variable and derivative[1] == order:\n",
    "                selected_derivative = derivative[2]\n",
    "                break\n",
    "        if selected_derivative is not None:\n",
    "            PDE_value += coefficient * selected_derivative\n",
    "        else:\n",
    "            return f\"Derivative value not found for variable {variable} with order {order}.\"\n",
    "    \n",
    "    # To get the non derivative terms in the PDE \n",
    "\n",
    "    for _ in range(num_non_derivative_terms):\n",
    "        coefficient_input = input(\"Enter the coefficient for the non-derivative term : \") # this can also be a numerical coefficient or the fucntion value itslef\n",
    "        \n",
    "        if coefficient_input in variable_names:\n",
    "            coefficient = float(input(f\"Enter value for the variable {coefficient_input}: \"))\n",
    "        elif coefficient_input == 'total_cost':\n",
    "            coefficient = total_cost\n",
    "        else:\n",
    "            coefficient = float(coefficient_input)\n",
    "        \n",
    "        non_derivative_expr = input(\"Enter the expression for the non-derivative term : \")\n",
    "        variable_used = input(\"Which variable is used in the expression? Enter the variable name or 'total_cost': \")\n",
    "        \n",
    "        variable_values = {var: 0 for var in variable_names}\n",
    "        if variable_used in variable_names:\n",
    "            variable_values[variable_used] = float(input(f\"Enter value for the variable {variable_used}: \"))\n",
    "        elif variable_used == 'total_cost':\n",
    "            variable_values['total_cost'] = total_cost\n",
    "        \n",
    "        non_derivative_value = eval(non_derivative_expr, {\"__builtins__\": None}, variable_values)\n",
    "        PDE_value += coefficient * non_derivative_value\n",
    "    \n",
    "    return PDE_value\n",
    "\n",
    "# Final PDE value\n",
    "PDE_value = calculate_PDE_from_derivatives(derivatives, variable_names, total_cost)\n",
    "print(f\"PDE value: {PDE_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18625f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of variables: ['t', 'x']\n",
      "Initial Condition Expression: -np.sin(3.14*x)\n",
      "Initial Condition Values: [ 0.00159265  0.00787257  0.01415218 ... -0.01415218 -0.00787257\n",
      " -0.00159265]\n",
      "Boundary Condition Values: 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "global initial_condition_values, boundary_condition_values\n",
    "initial_condition_values = None\n",
    "boundary_condition_values = None\n",
    "\n",
    "# To get the initial condition\n",
    "def handle_initial_condition():\n",
    "    global initial_condition_values\n",
    "    print(\"List of variables:\", variable_names)\n",
    "    variables_in_condition = input(\"Enter the variables involved in the initial condition separated by commas: \").split(',')\n",
    "    \n",
    "    valid_variables = [var.strip() for var in variables_in_condition if var.strip() in variable_names]\n",
    "    \n",
    "    if len(valid_variables) == len(variables_in_condition):\n",
    "        initial_condition_expr = input(\"Enter the initial condition expression at t=0: \")\n",
    "        \n",
    "        variable_values_combinations = [variable_values[var] for var in valid_variables]\n",
    "        \n",
    "        try:\n",
    "            print(\"Initial Condition Expression:\", initial_condition_expr)\n",
    "            \n",
    "            initial_condition_values = []\n",
    "            for values in zip(*variable_values_combinations):\n",
    "                eval_context = {var: val for var, val in zip(valid_variables, values)}\n",
    "                eval_context.update({'np': np, 'math': math})\n",
    "                initial_condition = eval(initial_condition_expr, eval_context)\n",
    "                initial_condition_values.append(initial_condition)\n",
    "            \n",
    "            initial_condition_values = np.array(initial_condition_values)\n",
    "            return initial_condition_values\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(\"Invalid expression. Please enter a valid mathematical expression.\")\n",
    "            print(e)\n",
    "            return None\n",
    "    else:\n",
    "        print(\"Invalid variable selection. Please choose variables from the provided list.\")\n",
    "        return None\n",
    "\n",
    "# To get the boundary condition\n",
    "def handle_boundary_conditions():\n",
    "    global boundary_condition_values\n",
    "    boundary_condition_values = {}\n",
    "    \n",
    "    num_boundary_variables = int(input(\"Enter the number of variables involved in the boundary condition: \"))\n",
    "    \n",
    "    if num_boundary_variables == 0:\n",
    "        boundary_condition_expr = input(\"Enter the boundary condition value: \")\n",
    "        boundary_condition_values = float(boundary_condition_expr)\n",
    "        return boundary_condition_values\n",
    "    \n",
    "    variables_in_condition = []\n",
    "    \n",
    "    for _ in range(num_boundary_variables):\n",
    "        variable_name = input(f\"Enter the variable name for the boundary condition (from the list {variable_names}): \")\n",
    "        if variable_name in variable_values:\n",
    "            variables_in_condition.append(variable_name)\n",
    "        else:\n",
    "            print(\"Invalid variable selection. Please select a variable from the list of variables.\")\n",
    "            return None\n",
    "    \n",
    "    boundary_condition_expr = input(\"Enter the boundary condition expression: \")\n",
    "    \n",
    "    for variable_name in variables_in_condition:\n",
    "        boundary_values = variable_values[variable_name]\n",
    "        lowest_value = boundary_values[0]\n",
    "        highest_value = boundary_values[-1]\n",
    "        \n",
    "        print(f\"Values for variable {variable_name}: \")\n",
    "        for value in boundary_values:\n",
    "            print(value)\n",
    "        \n",
    "        boundary_type = input(f\"Enter the boundary type for {variable_name} (point/range): \")\n",
    "        \n",
    "        if boundary_type == 'point':\n",
    "            boundary_value = lowest_value\n",
    "        elif boundary_type == 'range':\n",
    "            lower_boundary_start = float(input(f\"Enter the starting value for the lower boundary condition (between {lowest_value} and {highest_value}): \"))\n",
    "            lower_boundary_end = float(input(f\"Enter the ending value for the lower boundary condition (between {lowest_value} and {highest_value}): \"))\n",
    "            upper_boundary_start = float(input(f\"Enter the starting value for the upper boundary condition (between {lowest_value} and {highest_value}): \"))\n",
    "            upper_boundary_end = float(input(f\"Enter the ending value for the upper boundary condition (between {lowest_value} and {highest_value}): \"))\n",
    "        else:\n",
    "            print(\"Invalid boundary type. Please enter 'point' or 'range'.\")\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            print(\"Boundary Condition Expression:\", boundary_condition_expr)\n",
    "            print(f\"Boundary Variable: {variable_name}\")\n",
    "            \n",
    "            if boundary_type == 'point':\n",
    "                print(f\"Boundary Value: {boundary_value}\")\n",
    "                boundary_condition_values[variable_name] = boundary_value\n",
    "            elif boundary_type == 'range':\n",
    "                print(f\"Lower Boundary Range: [{lower_boundary_start}, {lower_boundary_end}]\")\n",
    "                print(f\"Upper Boundary Range: [{upper_boundary_start}, {upper_boundary_end}]\")\n",
    "                \n",
    "                lower_boundary_values = [value for value in boundary_values if lower_boundary_start <= value <= lower_boundary_end]\n",
    "                upper_boundary_values = [value for value in boundary_values if upper_boundary_start <= value <= upper_boundary_end]\n",
    "                \n",
    "                lower_boundary_function_values = [eval(boundary_condition_expr, {variable_name: value, 'np': np, 'math': math}) for value in lower_boundary_values]\n",
    "                upper_boundary_function_values = [eval(boundary_condition_expr, {variable_name: value, 'np': np, 'math': math}) for value in upper_boundary_values]\n",
    "                \n",
    "                boundary_condition_values[variable_name] = {\n",
    "                    'lower_boundary_start': lower_boundary_start,\n",
    "                    'lower_boundary_end': lower_boundary_end,\n",
    "                    'lower_boundary_values': lower_boundary_values,\n",
    "                    'lower_boundary_function_values': lower_boundary_function_values,\n",
    "                    'upper_boundary_start': upper_boundary_start,\n",
    "                    'upper_boundary_end': upper_boundary_end,\n",
    "                    'upper_boundary_values': upper_boundary_values,\n",
    "                    'upper_boundary_function_values': upper_boundary_function_values\n",
    "                }\n",
    "                \n",
    "                print(f\"Lower Boundary Function Values for {variable_name}: {lower_boundary_function_values}\")\n",
    "                print(f\"Upper Boundary Function Values for {variable_name}: {upper_boundary_function_values}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(\"Invalid expression. Please enter a valid mathematical expression.\")\n",
    "            print(e)\n",
    "    \n",
    "    return boundary_condition_values\n",
    "\n",
    "# Function call\n",
    "condition_type = input(\"Enter the problem type (initial/boundary/both): \")\n",
    "\n",
    "if condition_type == 'initial':\n",
    "    handle_initial_condition()\n",
    "    print(\"Initial Condition Values:\", initial_condition_values)\n",
    "elif condition_type == 'boundary':\n",
    "    boundary_condition_values = handle_boundary_conditions()\n",
    "    print(\"Boundary Condition Values:\", boundary_condition_values)\n",
    "elif condition_type == 'both':\n",
    "    handle_initial_condition()\n",
    "    boundary_condition_values = handle_boundary_conditions()\n",
    "    print(\"Initial Condition Values:\", initial_condition_values)\n",
    "    print(\"Boundary Condition Values:\", boundary_condition_values)\n",
    "else:\n",
    "    print(\"Invalid input. Please enter 'initial' for an initial value problem, 'boundary' for a boundary value problem, or 'both' for both initial and boundary conditions.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647b5846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boundary_condition_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a69af5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 25\u001b[0m\n\u001b[0;32m     19\u001b[0m         bc_loss_values\u001b[38;5;241m.\u001b[39mappend((max_outputs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m var_max) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bc_loss_values\n\u001b[1;32m---> 25\u001b[0m bc_loss_values \u001b[38;5;241m=\u001b[39m \u001b[43mcost_fn_bc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariable_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariable_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(bc_loss_values)\n",
      "Cell \u001b[1;32mIn[40], line 5\u001b[0m, in \u001b[0;36mcost_fn_bc\u001b[1;34m(params, num_layers, variable_values, variable_names)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m variable_names:\n\u001b[0;32m      4\u001b[0m     var_index \u001b[38;5;241m=\u001b[39m variable_names\u001b[38;5;241m.\u001b[39mindex(var)\n\u001b[1;32m----> 5\u001b[0m     var_min \u001b[38;5;241m=\u001b[39m \u001b[43mvariable_values\u001b[49m\u001b[43m[\u001b[49m\u001b[43mvar_index\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      6\u001b[0m     var_max \u001b[38;5;241m=\u001b[39m variable_values[var_index][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Run the variational circuit for the minimum and maximum values of the variable\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "def cost_fn_bc(params, num_layers, variable_values, variable_names):\n",
    "    bc_loss_values = []\n",
    "    for var in variable_names:\n",
    "        var_index = variable_names.index(var)\n",
    "        var_min = variable_values[var_index][0]\n",
    "        var_max = variable_values[var_index][-1]\n",
    "        \n",
    "        # Run the variational circuit for the minimum and maximum values of the variable\n",
    "        min_values = [0.0] * len(variable_values)\n",
    "        min_values[var_index] = var_min\n",
    "        min_outputs = variational_circuit(params, num_layers, np.array(min_values))\n",
    "        \n",
    "        max_values = [0.0] * len(variable_values)\n",
    "        max_values[var_index] = var_max\n",
    "        max_outputs = variational_circuit(params, num_layers, np.array(max_values))\n",
    "        \n",
    "        # Calculate the loss for the minimum and maximum values of the variable\n",
    "        bc_loss_values.append((min_outputs[0] - var_min) ** 2)\n",
    "        bc_loss_values.append((max_outputs[0] - var_max) ** 2)\n",
    "    \n",
    "    return bc_loss_values\n",
    "\n",
    "\n",
    "\n",
    "bc_loss_values = cost_fn_bc(params, num_layers, variable_values, variable_names)\n",
    "print(bc_loss_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e544187",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2bedab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00159265,  0.00787257,  0.01415218, ..., -0.01415218,\n",
       "       -0.00787257, -0.00159265])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_condition_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b89460f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sin(3.14*x)*np.sin(3.14*y)*np.sin(3.14*z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932d34c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10297242682980556\n"
     ]
    }
   ],
   "source": [
    "def cost_fn_ic(params, num_layers, variable_values):\n",
    "    ic_loss_values = []\n",
    "    for values in variable_values:\n",
    "        selected_values = np.append(values, 0.0)  # t=0 for the initial condition\n",
    "        clipped_values = np.clip(selected_values.astype(float), -1, 1)\n",
    "        outputs = variational_circuit(params, num_layers, clipped_values)\n",
    "        ic_loss_values.append((outputs[0] - initial_condition_values[0]) ** 2)\n",
    "    return ic_loss_values\n",
    "for key in variable_values:\n",
    "    variable_values[key] = [float(value) for value in variable_values[key]]\n",
    "variable_values_list = list(zip(*[variable_values[key] for key in variable_values.keys()]))\n",
    "ic_loss_values = cost_fn_ic(params, num_layers, variable_values_list)\n",
    "print (np.mean(ic_loss_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b8919e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss from initial condition = 0.10297242682980556\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss from initial condition =\", (np.mean(ic_loss_values)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b13fc0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6794169049008608e-14"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PDE_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a0cdd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10297242682980556\n"
     ]
    }
   ],
   "source": [
    "ic_loss = np.mean(ic_loss_values)\n",
    "print(ic_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2af6192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02934235880793538"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7.1792749502685085e-28 + (1.0*0.02934235880793538)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dd32b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss from PDE calculated 7.072778479433872e-22\n"
     ]
    }
   ],
   "source": [
    "pde_loss = ((PDE_value - 0) ** 2)\n",
    "print('Loss from PDE calculated',pde_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceea4f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = [0.0, 0.0001, 0.0002, 0.00030000000000000003, 0.0004, 0.0005, 0.0006000000000000001, 0.0007, 0.0008, 0.0009000000000000001, 0.001, 0.0011, 0.0012000000000000001, 0.0013000000000000002, 0.0014, 0.0015, 0.0016, 0.0017000000000000001, 0.0018000000000000002, 0.0019, 0.002, 0.0021000000000000003, 0.0022, 0.0023, 0.0024000000000000002, 0.0025, 0.0026000000000000003, 0.0027, 0.0028, 0.0029000000000000002, 0.003, 0.0031000000000000003, 0.0032, 0.0033, 0.0034000000000000002, 0.0035, 0.0036000000000000003, 0.0037, 0.0038, 0.0039000000000000003, 0.004, 0.0041, 0.004200000000000001, 0.0043, 0.0044, 0.0045000000000000005, 0.0046, 0.0047, 0.0048000000000000004, 0.0049, 0.005, 0.0051, 0.005200000000000001, 0.0053, 0.0054, 0.0055000000000000005, 0.0056, 0.0057, 0.0058000000000000005, 0.0059, 0.006, 0.0061, 0.006200000000000001, 0.0063, 0.0064, 0.006500000000000001, 0.0066, 0.0067, 0.0068000000000000005, 0.006900000000000001, 0.007, 0.0071, 0.007200000000000001, 0.0073, 0.0074, 0.007500000000000001, 0.0076, 0.0077, 0.0078000000000000005, 0.0079, 0.008, 0.0081, 0.0082, 0.0083, 0.008400000000000001, 0.0085, 0.0086, 0.008700000000000001, 0.0088, 0.0089, 0.009000000000000001, 0.0091, 0.0092, 0.009300000000000001, 0.0094, 0.0095, 0.009600000000000001, 0.0097, 0.0098, 0.0099, 0.01, 0.010100000000000001, 0.0102, 0.0103, 0.010400000000000001, 0.0105, 0.0106, 0.010700000000000001, 0.0108, 0.0109, 0.011000000000000001, 0.0111, 0.0112, 0.011300000000000001, 0.0114, 0.0115, 0.011600000000000001, 0.0117, 0.0118, 0.0119, 0.012, 0.012100000000000001, 0.0122, 0.0123, 0.012400000000000001, 0.0125, 0.0126, 0.012700000000000001, 0.0128, 0.0129, 0.013000000000000001, 0.0131, 0.0132, 0.013300000000000001, 0.0134, 0.0135, 0.013600000000000001, 0.0137, 0.013800000000000002, 0.013900000000000001, 0.014, 0.014100000000000001, 0.0142, 0.0143, 0.014400000000000001, 0.0145, 0.0146, 0.014700000000000001, 0.0148, 0.0149, 0.015000000000000001, 0.0151, 0.0152, 0.015300000000000001, 0.0154, 0.0155, 0.015600000000000001, 0.015700000000000002, 0.0158, 0.0159, 0.016, 0.0161, 0.0162, 0.016300000000000002, 0.0164, 0.0165, 0.0166, 0.0167, 0.016800000000000002, 0.016900000000000002, 0.017, 0.0171, 0.0172, 0.0173, 0.017400000000000002, 0.0175, 0.0176, 0.0177, 0.0178, 0.0179, 0.018000000000000002, 0.0181, 0.0182, 0.0183, 0.0184, 0.018500000000000003, 0.018600000000000002, 0.0187, 0.0188, 0.0189, 0.019, 0.019100000000000002, 0.019200000000000002, 0.0193, 0.0194, 0.0195, 0.0196, 0.019700000000000002, 0.0198, 0.0199, 0.02, 0.0201, 0.020200000000000003, 0.020300000000000002, 0.0204, 0.0205, 0.0206, 0.0207, 0.020800000000000003, 0.020900000000000002, 0.021, 0.0211, 0.0212, 0.0213, 0.021400000000000002, 0.021500000000000002, 0.0216, 0.0217, 0.0218, 0.0219, 0.022000000000000002, 0.0221, 0.0222, 0.0223, 0.0224, 0.022500000000000003, 0.022600000000000002, 0.0227, 0.0228, 0.0229, 0.023, 0.023100000000000002, 0.023200000000000002, 0.0233, 0.0234, 0.0235, 0.0236, 0.023700000000000002, 0.0238, 0.0239, 0.024, 0.0241, 0.024200000000000003, 0.024300000000000002, 0.0244, 0.0245, 0.0246, 0.0247, 0.024800000000000003, 0.024900000000000002, 0.025, 0.0251, 0.0252, 0.0253, 0.025400000000000002, 0.025500000000000002, 0.0256, 0.0257, 0.0258, 0.025900000000000003, 0.026000000000000002, 0.0261, 0.0262, 0.0263, 0.0264, 0.026500000000000003, 0.026600000000000002, 0.0267, 0.0268, 0.0269, 0.027, 0.027100000000000003, 0.027200000000000002, 0.0273, 0.0274, 0.0275, 0.027600000000000003, 0.027700000000000002, 0.027800000000000002, 0.0279, 0.028, 0.0281, 0.028200000000000003, 0.028300000000000002, 0.0284, 0.0285, 0.0286, 0.0287, 0.028800000000000003, 0.028900000000000002, 0.029, 0.0291, 0.0292, 0.029300000000000003, 0.029400000000000003, 0.029500000000000002, 0.0296, 0.0297, 0.0298, 0.029900000000000003, 0.030000000000000002, 0.030100000000000002, 0.0302, 0.0303, 0.0304, 0.030500000000000003, 0.030600000000000002, 0.0307, 0.0308, 0.0309, 0.031, 0.031100000000000003, 0.031200000000000002, 0.0313, 0.031400000000000004, 0.0315, 0.0316, 0.0317, 0.0318, 0.031900000000000005, 0.032, 0.032100000000000004, 0.0322, 0.0323, 0.0324, 0.0325, 0.032600000000000004, 0.0327, 0.0328, 0.0329, 0.033, 0.033100000000000004, 0.0332, 0.0333, 0.0334, 0.0335, 0.033600000000000005, 0.0337, 0.033800000000000004, 0.0339, 0.034, 0.0341, 0.0342, 0.034300000000000004, 0.0344, 0.0345, 0.0346, 0.0347, 0.034800000000000005, 0.0349, 0.035, 0.0351, 0.0352, 0.035300000000000005, 0.0354, 0.035500000000000004, 0.0356, 0.0357, 0.0358, 0.0359, 0.036000000000000004, 0.0361, 0.0362, 0.0363, 0.0364, 0.036500000000000005, 0.0366, 0.0367, 0.0368, 0.0369, 0.037000000000000005, 0.0371, 0.037200000000000004, 0.0373, 0.0374, 0.0375, 0.0376, 0.037700000000000004, 0.0378, 0.0379, 0.038, 0.0381, 0.038200000000000005, 0.0383, 0.038400000000000004, 0.0385, 0.0386, 0.038700000000000005, 0.0388, 0.038900000000000004, 0.039, 0.0391, 0.0392, 0.0393, 0.039400000000000004, 0.0395, 0.0396, 0.0397, 0.0398, 0.039900000000000005, 0.04, 0.040100000000000004, 0.0402, 0.0403, 0.040400000000000005, 0.0405, 0.040600000000000004, 0.0407, 0.0408, 0.0409, 0.041, 0.041100000000000005, 0.0412, 0.0413, 0.0414, 0.0415, 0.041600000000000005, 0.0417, 0.041800000000000004, 0.0419, 0.042, 0.042100000000000005, 0.0422, 0.042300000000000004, 0.0424, 0.0425, 0.0426, 0.0427, 0.042800000000000005, 0.0429, 0.043000000000000003, 0.0431, 0.0432, 0.043300000000000005, 0.0434, 0.043500000000000004, 0.0436, 0.0437, 0.0438, 0.0439, 0.044000000000000004, 0.0441, 0.0442, 0.0443, 0.0444, 0.044500000000000005, 0.0446, 0.044700000000000004, 0.0448, 0.0449, 0.045000000000000005, 0.0451, 0.045200000000000004, 0.0453, 0.0454, 0.0455, 0.0456, 0.045700000000000005, 0.0458, 0.0459, 0.046, 0.0461, 0.046200000000000005, 0.0463, 0.046400000000000004, 0.0465, 0.0466, 0.046700000000000005, 0.0468, 0.046900000000000004, 0.047, 0.0471, 0.0472, 0.0473, 0.047400000000000005, 0.0475, 0.0476, 0.0477, 0.0478, 0.047900000000000005, 0.048, 0.048100000000000004, 0.0482, 0.0483, 0.048400000000000006, 0.0485, 0.048600000000000004, 0.0487, 0.0488, 0.0489, 0.049, 0.049100000000000005, 0.0492, 0.049300000000000004, 0.0494, 0.0495, 0.049600000000000005, 0.0497, 0.049800000000000004, 0.0499, 0.05, 0.050100000000000006, 0.0502, 0.050300000000000004, 0.0504, 0.0505, 0.0506, 0.0507, 0.050800000000000005, 0.0509, 0.051000000000000004, 0.0511, 0.0512, 0.051300000000000005, 0.0514, 0.051500000000000004, 0.0516, 0.0517, 0.051800000000000006, 0.0519, 0.052000000000000005, 0.0521, 0.0522, 0.0523, 0.0524, 0.052500000000000005, 0.0526, 0.052700000000000004, 0.0528, 0.0529, 0.053000000000000005, 0.0531, 0.053200000000000004, 0.0533, 0.0534, 0.053500000000000006, 0.0536, 0.053700000000000005, 0.0538, 0.0539, 0.054, 0.0541, 0.054200000000000005, 0.0543, 0.054400000000000004, 0.0545, 0.0546, 0.054700000000000006, 0.0548, 0.054900000000000004, 0.055, 0.0551, 0.055200000000000006, 0.0553, 0.055400000000000005, 0.0555, 0.055600000000000004, 0.0557, 0.0558, 0.055900000000000005, 0.056, 0.056100000000000004, 0.0562, 0.0563, 0.056400000000000006, 0.0565, 0.056600000000000004, 0.0567, 0.0568, 0.056900000000000006, 0.057, 0.057100000000000005, 0.0572, 0.057300000000000004, 0.0574, 0.0575, 0.057600000000000005, 0.0577, 0.057800000000000004, 0.0579, 0.058, 0.058100000000000006, 0.0582, 0.058300000000000005, 0.0584, 0.0585, 0.058600000000000006, 0.0587, 0.058800000000000005, 0.0589, 0.059000000000000004, 0.0591, 0.0592, 0.059300000000000005, 0.0594, 0.059500000000000004, 0.0596, 0.0597, 0.059800000000000006, 0.0599, 0.060000000000000005, 0.0601, 0.060200000000000004, 0.0603, 0.0604, 0.060500000000000005, 0.0606, 0.060700000000000004, 0.0608, 0.0609, 0.061000000000000006, 0.0611, 0.061200000000000004, 0.0613, 0.0614, 0.061500000000000006, 0.0616, 0.061700000000000005, 0.0618, 0.061900000000000004, 0.062, 0.0621, 0.062200000000000005, 0.0623, 0.062400000000000004, 0.0625, 0.0626, 0.0627, 0.06280000000000001, 0.0629, 0.063, 0.0631, 0.0632, 0.06330000000000001, 0.0634, 0.0635, 0.0636, 0.0637, 0.06380000000000001, 0.0639, 0.064, 0.0641, 0.06420000000000001, 0.06430000000000001, 0.0644, 0.0645, 0.0646, 0.06470000000000001, 0.0648, 0.0649, 0.065, 0.0651, 0.06520000000000001, 0.0653, 0.0654, 0.0655, 0.0656, 0.06570000000000001, 0.0658, 0.0659, 0.066, 0.0661, 0.06620000000000001, 0.0663, 0.0664, 0.0665, 0.0666, 0.06670000000000001, 0.0668, 0.0669, 0.067, 0.0671, 0.06720000000000001, 0.0673, 0.0674, 0.0675, 0.06760000000000001, 0.06770000000000001, 0.0678, 0.0679, 0.068, 0.06810000000000001, 0.0682, 0.0683, 0.0684, 0.0685, 0.06860000000000001, 0.0687, 0.0688, 0.0689, 0.069, 0.06910000000000001, 0.0692, 0.0693, 0.0694, 0.0695, 0.06960000000000001, 0.0697, 0.0698, 0.0699, 0.07, 0.07010000000000001, 0.0702, 0.0703, 0.0704, 0.07050000000000001, 0.07060000000000001, 0.0707, 0.0708, 0.0709, 0.07100000000000001, 0.0711, 0.0712, 0.0713, 0.0714, 0.07150000000000001, 0.0716, 0.0717, 0.0718, 0.0719, 0.07200000000000001, 0.0721, 0.0722, 0.0723, 0.0724, 0.07250000000000001, 0.0726, 0.0727, 0.0728, 0.0729, 0.07300000000000001, 0.0731, 0.0732, 0.0733, 0.0734, 0.07350000000000001, 0.0736, 0.0737, 0.0738, 0.07390000000000001, 0.07400000000000001, 0.0741, 0.0742, 0.0743, 0.07440000000000001, 0.0745, 0.0746, 0.0747, 0.0748, 0.07490000000000001, 0.075, 0.0751, 0.0752, 0.0753, 0.07540000000000001, 0.0755, 0.0756, 0.0757, 0.0758, 0.07590000000000001, 0.076, 0.0761, 0.0762, 0.0763, 0.07640000000000001, 0.0765, 0.0766, 0.0767, 0.07680000000000001, 0.07690000000000001, 0.077, 0.0771, 0.0772, 0.07730000000000001, 0.07740000000000001, 0.0775, 0.0776, 0.0777, 0.07780000000000001, 0.0779, 0.078, 0.0781, 0.0782, 0.07830000000000001, 0.0784, 0.0785, 0.0786, 0.0787, 0.07880000000000001, 0.0789, 0.079, 0.0791, 0.0792, 0.07930000000000001, 0.0794, 0.0795, 0.0796, 0.07970000000000001, 0.07980000000000001, 0.0799, 0.08, 0.0801, 0.08020000000000001, 0.08030000000000001, 0.0804, 0.0805, 0.0806, 0.08070000000000001, 0.08080000000000001, 0.0809, 0.081, 0.0811, 0.08120000000000001, 0.0813, 0.0814, 0.0815, 0.0816, 0.08170000000000001, 0.0818, 0.0819, 0.082, 0.0821, 0.08220000000000001, 0.0823, 0.0824, 0.0825, 0.0826, 0.08270000000000001, 0.0828, 0.0829, 0.083, 0.08310000000000001, 0.08320000000000001, 0.0833, 0.0834, 0.0835, 0.08360000000000001, 0.08370000000000001, 0.0838, 0.0839, 0.084, 0.08410000000000001, 0.08420000000000001, 0.0843, 0.0844, 0.0845, 0.08460000000000001, 0.0847, 0.0848, 0.0849, 0.085, 0.08510000000000001, 0.0852, 0.0853, 0.0854, 0.0855, 0.08560000000000001, 0.0857, 0.0858, 0.0859, 0.08600000000000001, 0.08610000000000001, 0.0862, 0.0863, 0.0864, 0.08650000000000001, 0.08660000000000001, 0.0867, 0.0868, 0.0869, 0.08700000000000001, 0.08710000000000001, 0.0872, 0.0873, 0.0874, 0.08750000000000001, 0.0876, 0.0877, 0.0878, 0.0879, 0.08800000000000001, 0.0881, 0.0882, 0.0883, 0.0884, 0.08850000000000001, 0.0886, 0.0887, 0.0888, 0.0889, 0.08900000000000001, 0.0891, 0.0892, 0.0893, 0.08940000000000001, 0.08950000000000001, 0.0896, 0.0897, 0.0898, 0.08990000000000001, 0.09000000000000001, 0.0901, 0.0902, 0.0903, 0.09040000000000001, 0.09050000000000001, 0.0906, 0.0907, 0.0908, 0.09090000000000001, 0.091, 0.0911, 0.0912, 0.0913, 0.09140000000000001, 0.0915, 0.0916, 0.0917, 0.0918, 0.09190000000000001, 0.092, 0.0921, 0.0922, 0.09230000000000001, 0.09240000000000001, 0.0925, 0.0926, 0.0927, 0.09280000000000001, 0.09290000000000001, 0.093, 0.0931, 0.0932, 0.09330000000000001, 0.09340000000000001, 0.0935, 0.0936, 0.0937, 0.09380000000000001, 0.09390000000000001, 0.094, 0.0941, 0.0942, 0.09430000000000001, 0.0944, 0.0945, 0.0946, 0.0947, 0.09480000000000001, 0.0949, 0.095, 0.0951, 0.0952, 0.09530000000000001, 0.0954, 0.0955, 0.0956, 0.09570000000000001, 0.09580000000000001, 0.0959, 0.096, 0.0961, 0.09620000000000001, 0.09630000000000001, 0.0964, 0.0965, 0.0966, 0.09670000000000001, 0.09680000000000001, 0.0969, 0.097, 0.0971, 0.09720000000000001, 0.09730000000000001, 0.0974, 0.0975, 0.0976, 0.09770000000000001, 0.0978, 0.0979, 0.098, 0.0981, 0.09820000000000001, 0.0983, 0.0984, 0.0985, 0.09860000000000001, 0.09870000000000001, 0.0988, 0.0989, 0.099, 0.09910000000000001, 0.09920000000000001, 0.0993, 0.0994, 0.0995, 0.09960000000000001, 0.09970000000000001, 0.0998, 0.0999, 0.1, 0.10010000000000001, 0.10020000000000001, 0.1003, 0.1004, 0.1005, 0.10060000000000001, 0.10070000000000001, 0.1008, 0.1009, 0.101, 0.10110000000000001, 0.1012, 0.1013, 0.1014, 0.1015, 0.10160000000000001, 0.1017, 0.1018, 0.1019, 0.10200000000000001, 0.10210000000000001, 0.1022, 0.1023, 0.1024, 0.10250000000000001, 0.10260000000000001, 0.1027, 0.1028, 0.1029, 0.10300000000000001, 0.10310000000000001, 0.1032, 0.1033, 0.1034, 0.10350000000000001, 0.10360000000000001, 0.1037, 0.1038, 0.1039, 0.10400000000000001, 0.1041, 0.1042, 0.1043, 0.1044, 0.10450000000000001, 0.1046, 0.1047, 0.1048, 0.10490000000000001, 0.10500000000000001, 0.1051, 0.1052, 0.1053, 0.10540000000000001, 0.10550000000000001, 0.1056, 0.1057, 0.1058, 0.10590000000000001, 0.10600000000000001, 0.1061, 0.1062, 0.1063, 0.10640000000000001, 0.10650000000000001, 0.1066, 0.1067, 0.1068, 0.10690000000000001, 0.10700000000000001, 0.1071, 0.1072, 0.1073, 0.10740000000000001, 0.1075, 0.1076, 0.1077, 0.1078, 0.10790000000000001, 0.108, 0.1081, 0.1082, 0.10830000000000001, 0.10840000000000001, 0.1085, 0.1086, 0.1087, 0.10880000000000001, 0.10890000000000001, 0.109, 0.1091, 0.1092, 0.10930000000000001, 0.10940000000000001, 0.1095, 0.1096, 0.1097, 0.10980000000000001, 0.10990000000000001, 0.11, 0.1101, 0.1102, 0.11030000000000001, 0.11040000000000001, 0.1105, 0.1106, 0.1107, 0.11080000000000001, 0.1109, 0.111, 0.1111, 0.11120000000000001, 0.11130000000000001, 0.1114, 0.1115, 0.1116, 0.11170000000000001, 0.11180000000000001, 0.1119, 0.112, 0.1121, 0.11220000000000001, 0.11230000000000001, 0.1124, 0.1125, 0.1126, 0.11270000000000001, 0.11280000000000001, 0.1129, 0.113, 0.1131, 0.11320000000000001, 0.11330000000000001, 0.1134, 0.1135, 0.1136, 0.11370000000000001, 0.11380000000000001, 0.1139, 0.114, 0.11410000000000001, 0.11420000000000001, 0.1143, 0.1144, 0.1145, 0.11460000000000001, 0.11470000000000001, 0.1148, 0.1149, 0.115, 0.11510000000000001, 0.11520000000000001, 0.1153, 0.1154, 0.1155, 0.11560000000000001, 0.11570000000000001, 0.1158, 0.1159, 0.116, 0.11610000000000001, 0.11620000000000001, 0.1163, 0.1164, 0.1165, 0.11660000000000001, 0.11670000000000001, 0.1168, 0.1169, 0.117, 0.11710000000000001, 0.11720000000000001, 0.1173, 0.1174, 0.11750000000000001, 0.11760000000000001, 0.1177, 0.1178, 0.1179, 0.11800000000000001, 0.11810000000000001, 0.1182, 0.1183, 0.1184, 0.11850000000000001, 0.11860000000000001, 0.1187, 0.1188, 0.1189, 0.11900000000000001, 0.11910000000000001, 0.1192, 0.1193, 0.1194, 0.11950000000000001, 0.11960000000000001, 0.1197, 0.1198, 0.1199, 0.12000000000000001, 0.12010000000000001, 0.1202, 0.1203, 0.12040000000000001, 0.12050000000000001, 0.1206, 0.1207, 0.1208, 0.12090000000000001, 0.12100000000000001, 0.1211, 0.1212, 0.1213, 0.12140000000000001, 0.12150000000000001, 0.1216, 0.1217, 0.1218, 0.12190000000000001, 0.12200000000000001, 0.1221, 0.1222, 0.1223, 0.12240000000000001, 0.12250000000000001, 0.1226, 0.1227, 0.1228, 0.12290000000000001, 0.12300000000000001, 0.1231, 0.1232, 0.1233, 0.12340000000000001, 0.12350000000000001, 0.1236, 0.1237, 0.12380000000000001, 0.12390000000000001, 0.124, 0.1241, 0.1242, 0.12430000000000001, 0.12440000000000001, 0.1245, 0.1246, 0.1247, 0.12480000000000001, 0.12490000000000001, 0.125, 0.12510000000000002, 0.1252, 0.1253, 0.1254, 0.1255, 0.12560000000000002, 0.1257, 0.1258, 0.1259, 0.126, 0.12610000000000002, 0.1262, 0.1263, 0.1264, 0.1265, 0.12660000000000002, 0.1267, 0.1268, 0.1269, 0.127, 0.12710000000000002, 0.1272, 0.1273, 0.1274, 0.1275, 0.12760000000000002, 0.1277, 0.1278, 0.1279, 0.128, 0.12810000000000002, 0.1282, 0.1283, 0.12840000000000001, 0.1285, 0.12860000000000002, 0.1287, 0.1288, 0.12890000000000001, 0.129, 0.1291, 0.1292, 0.1293, 0.12940000000000002, 0.1295, 0.1296, 0.1297, 0.1298, 0.12990000000000002, 0.13, 0.1301, 0.1302, 0.1303, 0.13040000000000002, 0.1305, 0.1306, 0.1307, 0.1308, 0.13090000000000002, 0.131, 0.1311, 0.1312, 0.1313, 0.13140000000000002, 0.1315, 0.1316, 0.1317, 0.1318, 0.13190000000000002, 0.132, 0.1321, 0.1322, 0.1323, 0.13240000000000002, 0.1325, 0.1326, 0.1327, 0.1328, 0.13290000000000002, 0.133, 0.1331, 0.1332, 0.1333, 0.13340000000000002, 0.1335, 0.1336, 0.1337, 0.1338, 0.13390000000000002, 0.134, 0.1341, 0.1342, 0.1343, 0.13440000000000002, 0.1345, 0.1346, 0.13470000000000001, 0.1348, 0.13490000000000002, 0.135, 0.1351, 0.13520000000000001, 0.1353, 0.13540000000000002, 0.1355, 0.1356, 0.13570000000000002, 0.1358, 0.1359, 0.136, 0.1361, 0.13620000000000002, 0.1363, 0.1364, 0.1365, 0.1366, 0.13670000000000002, 0.1368, 0.1369, 0.137, 0.1371, 0.13720000000000002, 0.1373, 0.1374, 0.1375, 0.1376, 0.13770000000000002, 0.1378, 0.1379, 0.138, 0.1381, 0.13820000000000002, 0.1383, 0.1384, 0.1385, 0.1386, 0.13870000000000002, 0.1388, 0.1389, 0.139, 0.1391, 0.13920000000000002, 0.1393, 0.1394, 0.1395, 0.1396, 0.13970000000000002, 0.1398, 0.1399, 0.14, 0.1401, 0.14020000000000002, 0.1403, 0.1404, 0.1405, 0.1406, 0.14070000000000002, 0.1408, 0.1409, 0.14100000000000001, 0.1411, 0.14120000000000002, 0.1413, 0.1414, 0.14150000000000001, 0.1416, 0.14170000000000002, 0.1418, 0.1419, 0.14200000000000002, 0.1421, 0.1422, 0.1423, 0.1424, 0.14250000000000002, 0.1426, 0.1427, 0.1428, 0.1429, 0.14300000000000002, 0.1431, 0.1432, 0.1433, 0.1434, 0.14350000000000002, 0.1436, 0.1437, 0.1438, 0.1439, 0.14400000000000002, 0.1441, 0.1442, 0.1443, 0.1444, 0.14450000000000002, 0.1446, 0.1447, 0.1448, 0.1449, 0.14500000000000002, 0.1451, 0.1452, 0.1453, 0.1454, 0.14550000000000002, 0.1456, 0.1457, 0.1458, 0.1459, 0.14600000000000002, 0.1461, 0.1462, 0.1463, 0.1464, 0.14650000000000002, 0.1466, 0.1467, 0.1468, 0.1469, 0.14700000000000002, 0.1471, 0.1472, 0.14730000000000001, 0.1474, 0.14750000000000002, 0.1476, 0.1477, 0.14780000000000001, 0.1479, 0.14800000000000002, 0.1481, 0.1482, 0.14830000000000002, 0.1484, 0.14850000000000002, 0.1486, 0.1487, 0.14880000000000002, 0.1489, 0.149, 0.1491, 0.1492, 0.14930000000000002, 0.1494, 0.1495, 0.1496, 0.1497, 0.14980000000000002, 0.1499, 0.15, 0.1501, 0.1502, 0.15030000000000002, 0.1504, 0.1505, 0.1506, 0.1507, 0.15080000000000002, 0.1509, 0.151, 0.1511, 0.1512, 0.15130000000000002, 0.1514, 0.1515, 0.1516, 0.1517, 0.15180000000000002, 0.1519, 0.152, 0.1521, 0.1522, 0.15230000000000002, 0.1524, 0.1525, 0.1526, 0.1527, 0.15280000000000002, 0.1529, 0.153, 0.1531, 0.1532, 0.15330000000000002, 0.1534, 0.1535, 0.15360000000000001, 0.1537, 0.15380000000000002, 0.1539, 0.154, 0.15410000000000001, 0.1542, 0.15430000000000002, 0.1544, 0.1545, 0.15460000000000002, 0.1547, 0.15480000000000002, 0.1549, 0.155, 0.15510000000000002, 0.1552, 0.1553, 0.1554, 0.1555, 0.15560000000000002, 0.1557, 0.1558, 0.1559, 0.156, 0.15610000000000002, 0.1562, 0.1563, 0.1564, 0.1565, 0.15660000000000002, 0.1567, 0.1568, 0.1569, 0.157, 0.15710000000000002, 0.1572, 0.1573, 0.1574, 0.1575, 0.15760000000000002, 0.1577, 0.1578, 0.1579, 0.158, 0.15810000000000002, 0.1582, 0.1583, 0.1584, 0.1585, 0.15860000000000002, 0.1587, 0.1588, 0.1589, 0.159, 0.15910000000000002, 0.1592, 0.1593, 0.15940000000000001, 0.1595, 0.15960000000000002, 0.1597, 0.1598, 0.15990000000000001, 0.16, 0.16010000000000002, 0.1602, 0.1603, 0.16040000000000001, 0.1605, 0.16060000000000002, 0.1607, 0.1608, 0.16090000000000002, 0.161, 0.16110000000000002, 0.1612, 0.1613, 0.16140000000000002, 0.1615, 0.16160000000000002, 0.1617, 0.1618, 0.16190000000000002, 0.162, 0.1621, 0.1622, 0.1623, 0.16240000000000002, 0.1625, 0.1626, 0.1627, 0.1628, 0.16290000000000002, 0.163, 0.1631, 0.1632, 0.1633, 0.16340000000000002, 0.1635, 0.1636, 0.1637, 0.1638, 0.16390000000000002, 0.164, 0.1641, 0.1642, 0.1643, 0.16440000000000002, 0.1645, 0.1646, 0.1647, 0.1648, 0.16490000000000002, 0.165, 0.1651, 0.1652, 0.1653, 0.16540000000000002, 0.1655, 0.1656, 0.16570000000000001, 0.1658, 0.16590000000000002, 0.166, 0.1661, 0.16620000000000001, 0.1663, 0.16640000000000002, 0.1665, 0.1666, 0.16670000000000001, 0.1668, 0.16690000000000002, 0.167, 0.1671, 0.16720000000000002, 0.1673, 0.16740000000000002, 0.1675, 0.1676, 0.16770000000000002, 0.1678, 0.16790000000000002, 0.168, 0.1681, 0.16820000000000002, 0.1683, 0.16840000000000002, 0.1685, 0.1686, 0.16870000000000002, 0.1688, 0.1689, 0.169, 0.1691, 0.16920000000000002, 0.1693, 0.1694, 0.1695, 0.1696, 0.16970000000000002, 0.1698, 0.1699, 0.17, 0.1701, 0.17020000000000002, 0.1703, 0.1704, 0.1705, 0.1706, 0.17070000000000002, 0.1708, 0.1709, 0.171, 0.1711, 0.17120000000000002, 0.1713, 0.1714, 0.1715, 0.1716, 0.17170000000000002, 0.1718, 0.1719, 0.17200000000000001, 0.1721, 0.17220000000000002, 0.1723, 0.1724, 0.17250000000000001, 0.1726, 0.17270000000000002, 0.1728, 0.1729, 0.17300000000000001, 0.1731, 0.17320000000000002, 0.1733, 0.1734, 0.17350000000000002, 0.1736, 0.17370000000000002, 0.1738, 0.1739, 0.17400000000000002, 0.1741, 0.17420000000000002, 0.1743, 0.1744, 0.17450000000000002, 0.1746, 0.17470000000000002, 0.1748, 0.1749, 0.17500000000000002, 0.1751, 0.1752, 0.1753, 0.1754, 0.17550000000000002, 0.1756, 0.1757, 0.1758, 0.1759, 0.17600000000000002, 0.1761, 0.1762, 0.1763, 0.1764, 0.17650000000000002, 0.1766, 0.1767, 0.1768, 0.1769, 0.17700000000000002, 0.1771, 0.1772, 0.1773, 0.1774, 0.17750000000000002, 0.1776, 0.1777, 0.1778, 0.1779, 0.17800000000000002, 0.1781, 0.1782, 0.17830000000000001, 0.1784, 0.17850000000000002, 0.1786, 0.1787, 0.17880000000000001, 0.1789, 0.17900000000000002, 0.1791, 0.1792, 0.17930000000000001, 0.1794, 0.17950000000000002, 0.1796, 0.1797, 0.17980000000000002, 0.1799, 0.18000000000000002, 0.1801, 0.1802, 0.18030000000000002, 0.1804, 0.18050000000000002, 0.1806, 0.1807, 0.18080000000000002, 0.1809, 0.18100000000000002, 0.1811, 0.1812, 0.18130000000000002, 0.1814, 0.18150000000000002, 0.1816, 0.1817, 0.18180000000000002, 0.1819, 0.182, 0.1821, 0.1822, 0.18230000000000002, 0.1824, 0.1825, 0.1826, 0.1827, 0.18280000000000002, 0.1829, 0.183, 0.1831, 0.1832, 0.18330000000000002, 0.1834, 0.1835, 0.1836, 0.1837, 0.18380000000000002, 0.1839, 0.184, 0.1841, 0.1842, 0.18430000000000002, 0.1844, 0.1845, 0.18460000000000001, 0.1847, 0.18480000000000002, 0.1849, 0.185, 0.18510000000000001, 0.1852, 0.18530000000000002, 0.1854, 0.1855, 0.18560000000000001, 0.1857, 0.18580000000000002, 0.1859, 0.186, 0.18610000000000002, 0.1862, 0.18630000000000002, 0.1864, 0.1865, 0.18660000000000002, 0.1867, 0.18680000000000002, 0.1869, 0.187, 0.18710000000000002, 0.1872, 0.18730000000000002, 0.1874, 0.1875, 0.18760000000000002, 0.1877, 0.18780000000000002, 0.1879, 0.188, 0.18810000000000002, 0.1882, 0.1883, 0.1884, 0.1885, 0.18860000000000002, 0.1887, 0.1888, 0.1889, 0.189, 0.18910000000000002, 0.1892, 0.1893, 0.1894, 0.1895, 0.18960000000000002, 0.1897, 0.1898, 0.1899, 0.19, 0.19010000000000002, 0.1902, 0.1903, 0.1904, 0.1905, 0.19060000000000002, 0.1907, 0.1908, 0.19090000000000001, 0.191, 0.19110000000000002, 0.1912, 0.1913, 0.19140000000000001, 0.1915, 0.19160000000000002, 0.1917, 0.1918, 0.19190000000000002, 0.192, 0.19210000000000002, 0.1922, 0.1923, 0.19240000000000002, 0.1925, 0.19260000000000002, 0.1927, 0.1928, 0.19290000000000002, 0.193, 0.19310000000000002, 0.1932, 0.1933, 0.19340000000000002, 0.1935, 0.19360000000000002, 0.1937, 0.1938, 0.19390000000000002, 0.194, 0.19410000000000002, 0.1942, 0.1943, 0.19440000000000002, 0.1945, 0.19460000000000002, 0.1947, 0.1948, 0.19490000000000002, 0.195, 0.1951, 0.1952, 0.1953, 0.19540000000000002, 0.1955, 0.1956, 0.1957, 0.1958, 0.19590000000000002, 0.196, 0.1961, 0.1962, 0.1963, 0.19640000000000002, 0.1965, 0.1966, 0.1967, 0.1968, 0.19690000000000002, 0.197, 0.1971, 0.19720000000000001, 0.1973, 0.19740000000000002, 0.1975, 0.1976, 0.19770000000000001, 0.1978, 0.19790000000000002, 0.198, 0.1981, 0.19820000000000002, 0.1983, 0.19840000000000002, 0.1985, 0.1986, 0.19870000000000002, 0.1988, 0.19890000000000002, 0.199, 0.1991, 0.19920000000000002, 0.1993, 0.19940000000000002, 0.1995, 0.1996, 0.19970000000000002, 0.1998, 0.19990000000000002, 0.2, 0.2001, 0.20020000000000002, 0.2003, 0.20040000000000002, 0.2005, 0.2006, 0.20070000000000002, 0.2008, 0.20090000000000002, 0.201, 0.2011, 0.20120000000000002, 0.2013, 0.20140000000000002, 0.2015, 0.2016, 0.20170000000000002, 0.2018, 0.2019, 0.202, 0.2021, 0.20220000000000002, 0.2023, 0.2024, 0.2025, 0.2026, 0.20270000000000002, 0.2028, 0.2029, 0.203, 0.2031, 0.20320000000000002, 0.2033, 0.2034, 0.20350000000000001, 0.2036, 0.20370000000000002, 0.2038, 0.2039, 0.20400000000000001, 0.2041, 0.20420000000000002, 0.2043, 0.2044, 0.20450000000000002, 0.2046, 0.20470000000000002, 0.2048, 0.2049, 0.20500000000000002, 0.2051, 0.20520000000000002, 0.2053, 0.2054, 0.20550000000000002, 0.2056, 0.20570000000000002, 0.2058, 0.2059, 0.20600000000000002, 0.2061, 0.20620000000000002, 0.2063, 0.2064, 0.20650000000000002, 0.2066, 0.20670000000000002, 0.2068, 0.2069, 0.20700000000000002, 0.2071, 0.20720000000000002, 0.2073, 0.2074, 0.20750000000000002, 0.2076, 0.20770000000000002, 0.2078, 0.2079, 0.20800000000000002, 0.2081, 0.2082, 0.2083, 0.2084, 0.20850000000000002, 0.2086, 0.2087, 0.2088, 0.2089, 0.20900000000000002, 0.2091, 0.2092, 0.2093, 0.2094, 0.20950000000000002, 0.2096, 0.2097, 0.20980000000000001, 0.2099, 0.21000000000000002, 0.2101, 0.2102, 0.21030000000000001, 0.2104, 0.21050000000000002, 0.2106, 0.2107, 0.21080000000000002, 0.2109, 0.21100000000000002, 0.2111, 0.2112, 0.21130000000000002, 0.2114, 0.21150000000000002, 0.2116, 0.2117, 0.21180000000000002, 0.2119, 0.21200000000000002, 0.2121, 0.2122, 0.21230000000000002, 0.2124, 0.21250000000000002, 0.2126, 0.2127, 0.21280000000000002, 0.2129, 0.21300000000000002, 0.2131, 0.2132, 0.21330000000000002, 0.2134, 0.21350000000000002, 0.2136, 0.2137, 0.21380000000000002, 0.2139, 0.21400000000000002, 0.2141, 0.2142, 0.21430000000000002, 0.2144, 0.21450000000000002, 0.2146, 0.2147, 0.21480000000000002, 0.2149, 0.215, 0.2151, 0.2152, 0.21530000000000002, 0.2154, 0.2155, 0.2156, 0.2157, 0.21580000000000002, 0.2159, 0.216, 0.21610000000000001, 0.2162, 0.21630000000000002, 0.2164, 0.2165, 0.21660000000000001, 0.2167, 0.21680000000000002, 0.2169, 0.217, 0.21710000000000002, 0.2172, 0.21730000000000002, 0.2174, 0.2175, 0.21760000000000002, 0.2177, 0.21780000000000002, 0.2179, 0.218, 0.21810000000000002, 0.2182, 0.21830000000000002, 0.2184, 0.2185, 0.21860000000000002, 0.2187, 0.21880000000000002, 0.2189, 0.219, 0.21910000000000002, 0.2192, 0.21930000000000002, 0.2194, 0.2195, 0.21960000000000002, 0.2197, 0.21980000000000002, 0.2199, 0.22, 0.22010000000000002, 0.2202, 0.22030000000000002, 0.2204, 0.2205, 0.22060000000000002, 0.2207, 0.22080000000000002, 0.2209, 0.221, 0.22110000000000002, 0.2212, 0.22130000000000002, 0.2214, 0.2215, 0.22160000000000002, 0.2217, 0.2218, 0.22190000000000001, 0.222, 0.22210000000000002, 0.2222, 0.2223, 0.22240000000000001, 0.2225, 0.22260000000000002, 0.2227, 0.2228, 0.22290000000000001, 0.223, 0.22310000000000002, 0.2232, 0.2233, 0.22340000000000002, 0.2235, 0.22360000000000002, 0.2237, 0.2238, 0.22390000000000002, 0.224, 0.22410000000000002, 0.2242, 0.2243, 0.22440000000000002, 0.2245, 0.22460000000000002, 0.2247, 0.2248, 0.22490000000000002, 0.225, 0.22510000000000002, 0.2252, 0.2253, 0.22540000000000002, 0.2255, 0.22560000000000002, 0.2257, 0.2258, 0.22590000000000002, 0.226, 0.22610000000000002, 0.2262, 0.2263, 0.22640000000000002, 0.2265, 0.22660000000000002, 0.2267, 0.2268, 0.22690000000000002, 0.227, 0.22710000000000002, 0.2272, 0.2273, 0.22740000000000002, 0.2275, 0.22760000000000002, 0.2277, 0.2278, 0.22790000000000002, 0.228, 0.2281, 0.22820000000000001, 0.2283, 0.22840000000000002, 0.2285, 0.2286, 0.22870000000000001, 0.2288, 0.22890000000000002, 0.229, 0.2291, 0.22920000000000001, 0.2293, 0.22940000000000002, 0.2295, 0.2296, 0.22970000000000002, 0.2298, 0.22990000000000002, 0.23, 0.2301, 0.23020000000000002, 0.2303, 0.23040000000000002, 0.2305, 0.2306, 0.23070000000000002, 0.2308, 0.23090000000000002, 0.231, 0.2311, 0.23120000000000002, 0.2313, 0.23140000000000002, 0.2315, 0.2316, 0.23170000000000002, 0.2318, 0.23190000000000002, 0.232, 0.2321, 0.23220000000000002, 0.2323, 0.23240000000000002, 0.2325, 0.2326, 0.23270000000000002, 0.2328, 0.23290000000000002, 0.233, 0.2331, 0.23320000000000002, 0.2333, 0.23340000000000002, 0.2335, 0.2336, 0.23370000000000002, 0.2338, 0.23390000000000002, 0.234, 0.2341, 0.23420000000000002, 0.2343, 0.23440000000000003, 0.23450000000000001, 0.2346, 0.23470000000000002, 0.2348, 0.2349, 0.23500000000000001, 0.2351, 0.23520000000000002, 0.2353, 0.2354, 0.23550000000000001, 0.2356, 0.23570000000000002, 0.2358, 0.2359, 0.23600000000000002, 0.2361, 0.23620000000000002, 0.2363, 0.2364, 0.23650000000000002, 0.2366, 0.23670000000000002, 0.2368, 0.2369, 0.23700000000000002, 0.2371, 0.23720000000000002, 0.2373, 0.2374, 0.23750000000000002, 0.2376, 0.23770000000000002, 0.2378, 0.2379, 0.23800000000000002, 0.2381, 0.23820000000000002, 0.2383, 0.2384, 0.23850000000000002, 0.2386, 0.23870000000000002, 0.2388, 0.2389, 0.23900000000000002, 0.2391, 0.23920000000000002, 0.2393, 0.2394, 0.23950000000000002, 0.2396, 0.23970000000000002, 0.2398, 0.2399, 0.24000000000000002, 0.2401, 0.24020000000000002, 0.2403, 0.2404, 0.24050000000000002, 0.2406, 0.24070000000000003, 0.24080000000000001, 0.2409, 0.24100000000000002, 0.2411, 0.2412, 0.24130000000000001, 0.2414, 0.24150000000000002, 0.2416, 0.2417, 0.24180000000000001, 0.2419, 0.24200000000000002, 0.2421, 0.2422, 0.24230000000000002, 0.2424, 0.24250000000000002, 0.2426, 0.2427, 0.24280000000000002, 0.2429, 0.24300000000000002, 0.2431, 0.2432, 0.24330000000000002, 0.2434, 0.24350000000000002, 0.2436, 0.2437, 0.24380000000000002, 0.2439, 0.24400000000000002, 0.2441, 0.2442, 0.24430000000000002, 0.2444, 0.24450000000000002, 0.2446, 0.2447, 0.24480000000000002, 0.2449, 0.24500000000000002, 0.2451, 0.2452, 0.24530000000000002, 0.2454, 0.24550000000000002, 0.2456, 0.2457, 0.24580000000000002, 0.2459, 0.24600000000000002, 0.2461, 0.2462, 0.24630000000000002, 0.2464, 0.24650000000000002, 0.2466, 0.2467, 0.24680000000000002, 0.2469, 0.24700000000000003, 0.24710000000000001, 0.2472, 0.24730000000000002, 0.2474, 0.24750000000000003, 0.24760000000000001, 0.2477, 0.24780000000000002, 0.2479, 0.248, 0.24810000000000001, 0.2482, 0.24830000000000002, 0.2484, 0.2485, 0.24860000000000002, 0.2487, 0.24880000000000002, 0.2489, 0.249, 0.24910000000000002, 0.2492, 0.24930000000000002, 0.2494, 0.2495, 0.24960000000000002, 0.2497, 0.24980000000000002, 0.2499, 0.25, 0.2501, 0.25020000000000003, 0.2503, 0.2504, 0.2505, 0.2506, 0.25070000000000003, 0.2508, 0.2509, 0.251, 0.2511, 0.25120000000000003, 0.2513, 0.2514, 0.2515, 0.2516, 0.25170000000000003, 0.2518, 0.2519, 0.252, 0.2521, 0.25220000000000004, 0.2523, 0.2524, 0.2525, 0.2526, 0.25270000000000004, 0.2528, 0.2529, 0.253, 0.2531, 0.25320000000000004, 0.2533, 0.2534, 0.2535, 0.2536, 0.25370000000000004, 0.2538, 0.2539, 0.254, 0.2541, 0.25420000000000004, 0.2543, 0.2544, 0.2545, 0.2546, 0.25470000000000004, 0.2548, 0.2549, 0.255, 0.2551, 0.25520000000000004, 0.2553, 0.2554, 0.2555, 0.2556, 0.25570000000000004, 0.2558, 0.2559, 0.256, 0.2561, 0.25620000000000004, 0.25630000000000003, 0.2564, 0.2565, 0.2566, 0.25670000000000004, 0.25680000000000003, 0.2569, 0.257, 0.2571, 0.25720000000000004, 0.25730000000000003, 0.2574, 0.2575, 0.2576, 0.2577, 0.25780000000000003, 0.2579, 0.258, 0.2581, 0.2582, 0.25830000000000003, 0.2584, 0.2585, 0.2586, 0.2587, 0.25880000000000003, 0.2589, 0.259, 0.2591, 0.2592, 0.25930000000000003, 0.2594, 0.2595, 0.2596, 0.2597, 0.25980000000000003, 0.2599, 0.26, 0.2601, 0.2602, 0.26030000000000003, 0.2604, 0.2605, 0.2606, 0.2607, 0.26080000000000003, 0.2609, 0.261, 0.2611, 0.2612, 0.26130000000000003, 0.2614, 0.2615, 0.2616, 0.2617, 0.26180000000000003, 0.2619, 0.262, 0.2621, 0.2622, 0.26230000000000003, 0.2624, 0.2625, 0.2626, 0.2627, 0.26280000000000003, 0.2629, 0.263, 0.2631, 0.2632, 0.26330000000000003, 0.2634, 0.2635, 0.2636, 0.2637, 0.26380000000000003, 0.2639, 0.264, 0.2641, 0.2642, 0.26430000000000003, 0.2644, 0.2645, 0.2646, 0.2647, 0.26480000000000004, 0.2649, 0.265, 0.2651, 0.2652, 0.26530000000000004, 0.2654, 0.2655, 0.2656, 0.2657, 0.26580000000000004, 0.2659, 0.266, 0.2661, 0.2662, 0.26630000000000004, 0.2664, 0.2665, 0.2666, 0.2667, 0.26680000000000004, 0.2669, 0.267, 0.2671, 0.2672, 0.26730000000000004, 0.2674, 0.2675, 0.2676, 0.2677, 0.26780000000000004, 0.2679, 0.268, 0.2681, 0.2682, 0.26830000000000004, 0.2684, 0.2685, 0.2686, 0.2687, 0.26880000000000004, 0.26890000000000003, 0.269, 0.2691, 0.2692, 0.26930000000000004, 0.26940000000000003, 0.2695, 0.2696, 0.2697, 0.26980000000000004, 0.26990000000000003, 0.27, 0.2701, 0.2702, 0.27030000000000004, 0.27040000000000003, 0.2705, 0.2706, 0.2707, 0.27080000000000004, 0.27090000000000003, 0.271, 0.2711, 0.2712, 0.2713, 0.27140000000000003, 0.2715, 0.2716, 0.2717, 0.2718, 0.27190000000000003, 0.272, 0.2721, 0.2722, 0.2723, 0.27240000000000003, 0.2725, 0.2726, 0.2727, 0.2728, 0.27290000000000003, 0.273, 0.2731, 0.2732, 0.2733, 0.27340000000000003, 0.2735, 0.2736, 0.2737, 0.2738, 0.27390000000000003, 0.274, 0.2741, 0.2742, 0.2743, 0.27440000000000003, 0.2745, 0.2746, 0.2747, 0.2748, 0.27490000000000003, 0.275, 0.2751, 0.2752, 0.2753, 0.27540000000000003, 0.2755, 0.2756, 0.2757, 0.2758, 0.27590000000000003, 0.276, 0.2761, 0.2762, 0.2763, 0.27640000000000003, 0.2765, 0.2766, 0.2767, 0.2768, 0.27690000000000003, 0.277, 0.2771, 0.2772, 0.2773, 0.27740000000000004, 0.2775, 0.2776, 0.2777, 0.2778, 0.27790000000000004, 0.278, 0.2781, 0.2782, 0.2783, 0.27840000000000004, 0.2785, 0.2786, 0.2787, 0.2788, 0.27890000000000004, 0.279, 0.2791, 0.2792, 0.2793, 0.27940000000000004, 0.2795, 0.2796, 0.2797, 0.2798, 0.27990000000000004, 0.28, 0.2801, 0.2802, 0.2803, 0.28040000000000004, 0.2805, 0.2806, 0.2807, 0.2808, 0.28090000000000004, 0.281, 0.2811, 0.2812, 0.2813, 0.28140000000000004, 0.28150000000000003, 0.2816, 0.2817, 0.2818, 0.28190000000000004, 0.28200000000000003, 0.2821, 0.2822, 0.2823, 0.28240000000000004, 0.28250000000000003, 0.2826, 0.2827, 0.2828, 0.28290000000000004, 0.28300000000000003, 0.2831, 0.2832, 0.2833, 0.28340000000000004, 0.28350000000000003, 0.2836, 0.2837, 0.2838, 0.28390000000000004, 0.28400000000000003, 0.2841, 0.2842, 0.2843, 0.2844, 0.28450000000000003, 0.2846, 0.2847, 0.2848, 0.2849, 0.28500000000000003, 0.2851, 0.2852, 0.2853, 0.2854, 0.28550000000000003, 0.2856, 0.2857, 0.2858, 0.2859, 0.28600000000000003, 0.2861, 0.2862, 0.2863, 0.2864, 0.28650000000000003, 0.2866, 0.2867, 0.2868, 0.2869, 0.28700000000000003, 0.2871, 0.2872, 0.2873, 0.2874, 0.28750000000000003, 0.2876, 0.2877, 0.2878, 0.2879, 0.28800000000000003, 0.2881, 0.2882, 0.2883, 0.2884, 0.28850000000000003, 0.2886, 0.2887, 0.2888, 0.2889, 0.28900000000000003, 0.2891, 0.2892, 0.2893, 0.2894, 0.28950000000000004, 0.2896, 0.2897, 0.2898, 0.2899, 0.29000000000000004, 0.2901, 0.2902, 0.2903, 0.2904, 0.29050000000000004, 0.2906, 0.2907, 0.2908, 0.2909, 0.29100000000000004, 0.2911, 0.2912, 0.2913, 0.2914, 0.29150000000000004, 0.2916, 0.2917, 0.2918, 0.2919, 0.29200000000000004, 0.2921, 0.2922, 0.2923, 0.2924, 0.29250000000000004, 0.2926, 0.2927, 0.2928, 0.2929, 0.29300000000000004, 0.2931, 0.2932, 0.2933, 0.2934, 0.29350000000000004, 0.2936, 0.2937, 0.2938, 0.2939, 0.29400000000000004, 0.29410000000000003, 0.2942, 0.2943, 0.2944, 0.29450000000000004, 0.29460000000000003, 0.2947, 0.2948, 0.2949, 0.29500000000000004, 0.29510000000000003, 0.2952, 0.2953, 0.2954, 0.29550000000000004, 0.29560000000000003, 0.2957, 0.2958, 0.2959, 0.29600000000000004, 0.29610000000000003, 0.2962, 0.2963, 0.2964, 0.29650000000000004, 0.29660000000000003, 0.2967, 0.2968, 0.2969, 0.29700000000000004, 0.29710000000000003, 0.2972, 0.2973, 0.2974, 0.2975, 0.29760000000000003, 0.2977, 0.2978, 0.2979, 0.298, 0.29810000000000003, 0.2982, 0.2983, 0.2984, 0.2985, 0.29860000000000003, 0.2987, 0.2988, 0.2989, 0.299, 0.29910000000000003, 0.2992, 0.2993, 0.2994, 0.2995, 0.29960000000000003, 0.2997, 0.2998, 0.2999, 0.3, 0.30010000000000003, 0.3002, 0.3003, 0.3004, 0.3005, 0.30060000000000003, 0.3007, 0.3008, 0.3009, 0.301, 0.30110000000000003, 0.3012, 0.3013, 0.3014, 0.3015, 0.30160000000000003, 0.3017, 0.3018, 0.3019, 0.302, 0.30210000000000004, 0.3022, 0.3023, 0.3024, 0.3025, 0.30260000000000004, 0.3027, 0.3028, 0.3029, 0.303, 0.30310000000000004, 0.3032, 0.3033, 0.3034, 0.3035, 0.30360000000000004, 0.3037, 0.3038, 0.3039, 0.304, 0.30410000000000004, 0.3042, 0.3043, 0.3044, 0.3045, 0.30460000000000004, 0.3047, 0.3048, 0.3049, 0.305, 0.30510000000000004, 0.3052, 0.3053, 0.3054, 0.3055, 0.30560000000000004, 0.3057, 0.3058, 0.3059, 0.306, 0.30610000000000004, 0.3062, 0.3063, 0.3064, 0.3065, 0.30660000000000004, 0.30670000000000003, 0.3068, 0.3069, 0.307, 0.30710000000000004, 0.30720000000000003, 0.3073, 0.3074, 0.3075, 0.30760000000000004, 0.30770000000000003, 0.3078, 0.3079, 0.308, 0.30810000000000004, 0.30820000000000003, 0.3083, 0.3084, 0.3085, 0.30860000000000004, 0.30870000000000003, 0.3088, 0.3089, 0.309, 0.30910000000000004, 0.30920000000000003, 0.3093, 0.3094, 0.3095, 0.30960000000000004, 0.30970000000000003, 0.3098, 0.3099, 0.31, 0.31010000000000004, 0.31020000000000003, 0.3103, 0.3104, 0.3105, 0.3106, 0.31070000000000003, 0.3108, 0.3109, 0.311, 0.3111, 0.31120000000000003, 0.3113, 0.3114, 0.3115, 0.3116, 0.31170000000000003, 0.3118, 0.3119, 0.312, 0.3121, 0.31220000000000003, 0.3123, 0.3124, 0.3125, 0.3126, 0.31270000000000003, 0.3128, 0.3129, 0.313, 0.3131, 0.31320000000000003, 0.3133, 0.3134, 0.3135, 0.3136, 0.31370000000000003, 0.3138, 0.3139, 0.314, 0.3141, 0.31420000000000003, 0.3143, 0.3144, 0.3145, 0.3146, 0.31470000000000004, 0.3148, 0.3149, 0.315, 0.3151, 0.31520000000000004, 0.3153, 0.3154, 0.3155, 0.3156, 0.31570000000000004, 0.3158, 0.3159, 0.316, 0.3161, 0.31620000000000004, 0.3163, 0.3164, 0.3165, 0.3166, 0.31670000000000004, 0.3168, 0.3169, 0.317, 0.3171, 0.31720000000000004, 0.3173, 0.3174, 0.3175, 0.3176, 0.31770000000000004, 0.3178, 0.3179, 0.318, 0.3181, 0.31820000000000004, 0.3183, 0.3184, 0.3185, 0.3186, 0.31870000000000004, 0.31880000000000003, 0.3189, 0.319, 0.3191, 0.31920000000000004, 0.31930000000000003, 0.3194, 0.3195, 0.3196, 0.31970000000000004, 0.31980000000000003, 0.3199, 0.32, 0.3201, 0.32020000000000004, 0.32030000000000003, 0.3204, 0.3205, 0.3206, 0.32070000000000004, 0.32080000000000003, 0.3209, 0.321, 0.3211, 0.32120000000000004, 0.32130000000000003, 0.3214, 0.3215, 0.3216, 0.32170000000000004, 0.32180000000000003, 0.3219, 0.322, 0.3221, 0.32220000000000004, 0.32230000000000003, 0.3224, 0.3225, 0.3226, 0.32270000000000004, 0.32280000000000003, 0.3229, 0.323, 0.3231, 0.32320000000000004, 0.32330000000000003, 0.3234, 0.3235, 0.3236, 0.32370000000000004, 0.32380000000000003, 0.3239, 0.324, 0.3241, 0.3242, 0.32430000000000003, 0.3244, 0.3245, 0.3246, 0.3247, 0.32480000000000003, 0.3249, 0.325, 0.3251, 0.3252, 0.32530000000000003, 0.3254, 0.3255, 0.3256, 0.3257, 0.32580000000000003, 0.3259, 0.326, 0.3261, 0.3262, 0.32630000000000003, 0.3264, 0.3265, 0.3266, 0.3267, 0.32680000000000003, 0.3269, 0.327, 0.3271, 0.3272, 0.32730000000000004, 0.3274, 0.3275, 0.3276, 0.3277, 0.32780000000000004, 0.3279, 0.328, 0.3281, 0.3282, 0.32830000000000004, 0.3284, 0.3285, 0.3286, 0.3287, 0.32880000000000004, 0.3289, 0.329, 0.3291, 0.3292, 0.32930000000000004, 0.3294, 0.3295, 0.3296, 0.3297, 0.32980000000000004, 0.3299, 0.33, 0.3301, 0.3302, 0.33030000000000004, 0.3304, 0.3305, 0.3306, 0.3307, 0.33080000000000004, 0.3309, 0.331, 0.3311, 0.3312, 0.33130000000000004, 0.33140000000000003, 0.3315, 0.3316, 0.3317, 0.33180000000000004, 0.33190000000000003, 0.332, 0.3321, 0.3322, 0.33230000000000004, 0.33240000000000003, 0.3325, 0.3326, 0.3327, 0.33280000000000004, 0.33290000000000003, 0.333, 0.3331, 0.3332, 0.33330000000000004, 0.33340000000000003, 0.3335, 0.3336, 0.3337, 0.33380000000000004, 0.33390000000000003, 0.334, 0.3341, 0.3342, 0.33430000000000004, 0.33440000000000003, 0.3345, 0.3346, 0.3347, 0.33480000000000004, 0.33490000000000003, 0.335, 0.3351, 0.3352, 0.33530000000000004, 0.33540000000000003, 0.3355, 0.3356, 0.3357, 0.33580000000000004, 0.33590000000000003, 0.336, 0.3361, 0.3362, 0.33630000000000004, 0.33640000000000003, 0.3365, 0.3366, 0.3367, 0.33680000000000004, 0.33690000000000003, 0.337, 0.3371, 0.3372, 0.3373, 0.33740000000000003, 0.3375, 0.3376, 0.3377, 0.3378, 0.33790000000000003, 0.338, 0.3381, 0.3382, 0.3383, 0.33840000000000003, 0.3385, 0.3386, 0.3387, 0.3388, 0.33890000000000003, 0.339, 0.3391, 0.3392, 0.3393, 0.33940000000000003, 0.3395, 0.3396, 0.3397, 0.3398, 0.33990000000000004, 0.34, 0.3401, 0.3402, 0.3403, 0.34040000000000004, 0.3405, 0.3406, 0.3407, 0.3408, 0.34090000000000004, 0.341, 0.3411, 0.3412, 0.3413, 0.34140000000000004, 0.3415, 0.3416, 0.3417, 0.3418, 0.34190000000000004, 0.342, 0.3421, 0.3422, 0.3423, 0.34240000000000004, 0.3425, 0.3426, 0.3427, 0.3428, 0.34290000000000004, 0.343, 0.3431, 0.3432, 0.3433, 0.34340000000000004, 0.3435, 0.3436, 0.3437, 0.3438, 0.34390000000000004, 0.34400000000000003, 0.3441, 0.3442, 0.3443, 0.34440000000000004, 0.34450000000000003, 0.3446, 0.3447, 0.3448, 0.34490000000000004, 0.34500000000000003, 0.3451, 0.3452, 0.3453, 0.34540000000000004, 0.34550000000000003, 0.3456, 0.3457, 0.3458, 0.34590000000000004, 0.34600000000000003, 0.3461, 0.3462, 0.3463, 0.34640000000000004, 0.34650000000000003, 0.3466, 0.3467, 0.3468, 0.34690000000000004, 0.34700000000000003, 0.3471, 0.3472, 0.3473, 0.34740000000000004, 0.34750000000000003, 0.3476, 0.3477, 0.3478, 0.34790000000000004, 0.34800000000000003, 0.3481, 0.3482, 0.3483, 0.34840000000000004, 0.34850000000000003, 0.3486, 0.3487, 0.3488, 0.34890000000000004, 0.34900000000000003, 0.3491, 0.3492, 0.3493, 0.34940000000000004, 0.34950000000000003, 0.3496, 0.3497, 0.3498, 0.34990000000000004, 0.35000000000000003, 0.3501, 0.3502, 0.3503, 0.3504, 0.35050000000000003, 0.3506, 0.3507, 0.3508, 0.3509, 0.35100000000000003, 0.3511, 0.3512, 0.3513, 0.3514, 0.35150000000000003, 0.3516, 0.3517, 0.3518, 0.3519, 0.35200000000000004, 0.3521, 0.3522, 0.3523, 0.3524, 0.35250000000000004, 0.3526, 0.3527, 0.3528, 0.3529, 0.35300000000000004, 0.3531, 0.3532, 0.3533, 0.3534, 0.35350000000000004, 0.3536, 0.3537, 0.3538, 0.3539, 0.35400000000000004, 0.3541, 0.3542, 0.3543, 0.3544, 0.35450000000000004, 0.3546, 0.3547, 0.3548, 0.3549, 0.35500000000000004, 0.3551, 0.3552, 0.3553, 0.3554, 0.35550000000000004, 0.3556, 0.3557, 0.3558, 0.3559, 0.35600000000000004, 0.3561, 0.3562, 0.3563, 0.3564, 0.35650000000000004, 0.35660000000000003, 0.3567, 0.3568, 0.3569, 0.35700000000000004, 0.35710000000000003, 0.3572, 0.3573, 0.3574, 0.35750000000000004, 0.35760000000000003, 0.3577, 0.3578, 0.3579, 0.35800000000000004, 0.35810000000000003, 0.3582, 0.3583, 0.3584, 0.35850000000000004, 0.35860000000000003, 0.3587, 0.3588, 0.3589, 0.35900000000000004, 0.35910000000000003, 0.3592, 0.3593, 0.3594, 0.35950000000000004, 0.35960000000000003, 0.3597, 0.3598, 0.3599, 0.36000000000000004, 0.36010000000000003, 0.3602, 0.3603, 0.3604, 0.36050000000000004, 0.36060000000000003, 0.3607, 0.3608, 0.3609, 0.36100000000000004, 0.36110000000000003, 0.3612, 0.3613, 0.3614, 0.36150000000000004, 0.36160000000000003, 0.3617, 0.3618, 0.3619, 0.36200000000000004, 0.36210000000000003, 0.3622, 0.3623, 0.3624, 0.36250000000000004, 0.36260000000000003, 0.3627, 0.3628, 0.3629, 0.36300000000000004, 0.36310000000000003, 0.3632, 0.3633, 0.3634, 0.3635, 0.36360000000000003, 0.3637, 0.3638, 0.3639, 0.364, 0.36410000000000003, 0.3642, 0.3643, 0.3644, 0.3645, 0.36460000000000004, 0.3647, 0.3648, 0.3649, 0.365, 0.36510000000000004, 0.3652, 0.3653, 0.3654, 0.3655, 0.36560000000000004, 0.3657, 0.3658, 0.3659, 0.366, 0.36610000000000004, 0.3662, 0.3663, 0.3664, 0.3665, 0.36660000000000004, 0.3667, 0.3668, 0.3669, 0.367, 0.36710000000000004, 0.3672, 0.3673, 0.3674, 0.3675, 0.36760000000000004, 0.3677, 0.3678, 0.3679, 0.368, 0.36810000000000004, 0.3682, 0.3683, 0.3684, 0.3685, 0.36860000000000004, 0.3687, 0.3688, 0.3689, 0.369, 0.36910000000000004, 0.36920000000000003, 0.3693, 0.3694, 0.3695, 0.36960000000000004, 0.36970000000000003, 0.3698, 0.3699, 0.37, 0.37010000000000004, 0.37020000000000003, 0.3703, 0.3704, 0.3705, 0.37060000000000004, 0.37070000000000003, 0.3708, 0.3709, 0.371, 0.37110000000000004, 0.37120000000000003, 0.3713, 0.3714, 0.3715, 0.37160000000000004, 0.37170000000000003, 0.3718, 0.3719, 0.372, 0.37210000000000004, 0.37220000000000003, 0.3723, 0.3724, 0.3725, 0.37260000000000004, 0.37270000000000003, 0.3728, 0.3729, 0.373, 0.37310000000000004, 0.37320000000000003, 0.3733, 0.3734, 0.3735, 0.37360000000000004, 0.37370000000000003, 0.3738, 0.3739, 0.374, 0.37410000000000004, 0.37420000000000003, 0.3743, 0.3744, 0.3745, 0.37460000000000004, 0.37470000000000003, 0.3748, 0.3749, 0.375, 0.37510000000000004, 0.37520000000000003, 0.3753, 0.3754, 0.3755, 0.37560000000000004, 0.37570000000000003, 0.3758, 0.3759, 0.376, 0.37610000000000005, 0.37620000000000003, 0.3763, 0.3764, 0.3765, 0.3766, 0.37670000000000003, 0.3768, 0.3769, 0.377, 0.3771, 0.37720000000000004, 0.3773, 0.3774, 0.3775, 0.3776, 0.37770000000000004, 0.3778, 0.3779, 0.378, 0.3781, 0.37820000000000004, 0.3783, 0.3784, 0.3785, 0.3786, 0.37870000000000004, 0.3788, 0.3789, 0.379, 0.3791, 0.37920000000000004, 0.3793, 0.3794, 0.3795, 0.3796, 0.37970000000000004, 0.3798, 0.3799, 0.38, 0.3801, 0.38020000000000004, 0.3803, 0.3804, 0.3805, 0.3806, 0.38070000000000004, 0.3808, 0.3809, 0.381, 0.3811, 0.38120000000000004, 0.38130000000000003, 0.3814, 0.3815, 0.3816, 0.38170000000000004, 0.38180000000000003, 0.3819, 0.382, 0.3821, 0.38220000000000004, 0.38230000000000003, 0.3824, 0.3825, 0.3826, 0.38270000000000004, 0.38280000000000003, 0.3829, 0.383, 0.3831, 0.38320000000000004, 0.38330000000000003, 0.3834, 0.3835, 0.3836, 0.38370000000000004, 0.38380000000000003, 0.3839, 0.384, 0.3841, 0.38420000000000004, 0.38430000000000003, 0.3844, 0.3845, 0.3846, 0.38470000000000004, 0.38480000000000003, 0.3849, 0.385, 0.3851, 0.38520000000000004, 0.38530000000000003, 0.3854, 0.3855, 0.3856, 0.38570000000000004, 0.38580000000000003, 0.3859, 0.386, 0.3861, 0.38620000000000004, 0.38630000000000003, 0.3864, 0.3865, 0.3866, 0.38670000000000004, 0.38680000000000003, 0.3869, 0.387, 0.3871, 0.38720000000000004, 0.38730000000000003, 0.3874, 0.3875, 0.3876, 0.38770000000000004, 0.38780000000000003, 0.3879, 0.388, 0.3881, 0.38820000000000005, 0.38830000000000003, 0.3884, 0.3885, 0.3886, 0.38870000000000005, 0.38880000000000003, 0.3889, 0.389, 0.3891, 0.38920000000000005, 0.38930000000000003, 0.3894, 0.3895, 0.3896, 0.38970000000000005, 0.38980000000000004, 0.3899, 0.39, 0.3901, 0.3902, 0.39030000000000004, 0.3904, 0.3905, 0.3906, 0.3907, 0.39080000000000004, 0.3909, 0.391, 0.3911, 0.3912, 0.39130000000000004, 0.3914, 0.3915, 0.3916, 0.3917, 0.39180000000000004, 0.3919, 0.392, 0.3921, 0.3922, 0.39230000000000004, 0.3924, 0.3925, 0.3926, 0.3927, 0.39280000000000004, 0.3929, 0.393, 0.3931, 0.3932, 0.39330000000000004, 0.3934, 0.3935, 0.3936, 0.3937, 0.39380000000000004, 0.39390000000000003, 0.394, 0.3941, 0.3942, 0.39430000000000004, 0.39440000000000003, 0.3945, 0.3946, 0.3947, 0.39480000000000004, 0.39490000000000003, 0.395, 0.3951, 0.3952, 0.39530000000000004, 0.39540000000000003, 0.3955, 0.3956, 0.3957, 0.39580000000000004, 0.39590000000000003, 0.396, 0.3961, 0.3962, 0.39630000000000004, 0.39640000000000003, 0.3965, 0.3966, 0.3967, 0.39680000000000004, 0.39690000000000003, 0.397, 0.3971, 0.3972, 0.39730000000000004, 0.39740000000000003, 0.3975, 0.3976, 0.3977, 0.39780000000000004, 0.39790000000000003, 0.398, 0.3981, 0.3982, 0.39830000000000004, 0.39840000000000003, 0.3985, 0.3986, 0.3987, 0.39880000000000004, 0.39890000000000003, 0.399, 0.3991, 0.3992, 0.39930000000000004, 0.39940000000000003, 0.3995, 0.3996, 0.3997, 0.39980000000000004, 0.39990000000000003, 0.4, 0.4001, 0.4002, 0.40030000000000004, 0.40040000000000003, 0.4005, 0.4006, 0.4007, 0.40080000000000005, 0.40090000000000003, 0.401, 0.4011, 0.4012, 0.40130000000000005, 0.40140000000000003, 0.4015, 0.4016, 0.4017, 0.40180000000000005, 0.40190000000000003, 0.402, 0.4021, 0.4022, 0.40230000000000005, 0.40240000000000004, 0.4025, 0.4026, 0.4027, 0.40280000000000005, 0.40290000000000004, 0.403, 0.4031, 0.4032, 0.4033, 0.40340000000000004, 0.4035, 0.4036, 0.4037, 0.4038, 0.40390000000000004, 0.404, 0.4041, 0.4042, 0.4043, 0.40440000000000004, 0.4045, 0.4046, 0.4047, 0.4048, 0.40490000000000004, 0.405, 0.4051, 0.4052, 0.4053, 0.40540000000000004, 0.4055, 0.4056, 0.4057, 0.4058, 0.40590000000000004, 0.406, 0.4061, 0.4062, 0.4063, 0.40640000000000004, 0.40650000000000003, 0.4066, 0.4067, 0.4068, 0.40690000000000004, 0.40700000000000003, 0.4071, 0.4072, 0.4073, 0.40740000000000004, 0.40750000000000003, 0.4076, 0.4077, 0.4078, 0.40790000000000004, 0.40800000000000003, 0.4081, 0.4082, 0.4083, 0.40840000000000004, 0.40850000000000003, 0.4086, 0.4087, 0.4088, 0.40890000000000004, 0.40900000000000003, 0.4091, 0.4092, 0.4093, 0.40940000000000004, 0.40950000000000003, 0.4096, 0.4097, 0.4098, 0.40990000000000004, 0.41000000000000003, 0.4101, 0.4102, 0.4103, 0.41040000000000004, 0.41050000000000003, 0.4106, 0.4107, 0.4108, 0.41090000000000004, 0.41100000000000003, 0.4111, 0.4112, 0.4113, 0.41140000000000004, 0.41150000000000003, 0.4116, 0.4117, 0.4118, 0.41190000000000004, 0.41200000000000003, 0.4121, 0.4122, 0.4123, 0.41240000000000004, 0.41250000000000003, 0.4126, 0.4127, 0.4128, 0.41290000000000004, 0.41300000000000003, 0.4131, 0.4132, 0.4133, 0.41340000000000005, 0.41350000000000003, 0.4136, 0.4137, 0.4138, 0.41390000000000005, 0.41400000000000003, 0.4141, 0.4142, 0.4143, 0.41440000000000005, 0.41450000000000004, 0.4146, 0.4147, 0.4148, 0.41490000000000005, 0.41500000000000004, 0.4151, 0.4152, 0.4153, 0.41540000000000005, 0.41550000000000004, 0.4156, 0.4157, 0.4158, 0.41590000000000005, 0.41600000000000004, 0.4161, 0.4162, 0.4163, 0.4164, 0.41650000000000004, 0.4166, 0.4167, 0.4168, 0.4169, 0.41700000000000004, 0.4171, 0.4172, 0.4173, 0.4174, 0.41750000000000004, 0.4176, 0.4177, 0.4178, 0.4179, 0.41800000000000004, 0.4181, 0.4182, 0.4183, 0.4184, 0.41850000000000004, 0.4186, 0.4187, 0.4188, 0.4189, 0.41900000000000004, 0.41910000000000003, 0.4192, 0.4193, 0.4194, 0.41950000000000004, 0.41960000000000003, 0.4197, 0.4198, 0.4199, 0.42000000000000004, 0.42010000000000003, 0.4202, 0.4203, 0.4204, 0.42050000000000004, 0.42060000000000003, 0.4207, 0.4208, 0.4209, 0.42100000000000004, 0.42110000000000003, 0.4212, 0.4213, 0.4214, 0.42150000000000004, 0.42160000000000003, 0.4217, 0.4218, 0.4219, 0.42200000000000004, 0.42210000000000003, 0.4222, 0.4223, 0.4224, 0.42250000000000004, 0.42260000000000003, 0.4227, 0.4228, 0.4229, 0.42300000000000004, 0.42310000000000003, 0.4232, 0.4233, 0.4234, 0.42350000000000004, 0.42360000000000003, 0.4237, 0.4238, 0.4239, 0.42400000000000004, 0.42410000000000003, 0.4242, 0.4243, 0.4244, 0.42450000000000004, 0.42460000000000003, 0.4247, 0.4248, 0.4249, 0.42500000000000004, 0.42510000000000003, 0.4252, 0.4253, 0.4254, 0.42550000000000004, 0.42560000000000003, 0.4257, 0.4258, 0.4259, 0.42600000000000005, 0.42610000000000003, 0.4262, 0.4263, 0.4264, 0.42650000000000005, 0.42660000000000003, 0.4267, 0.4268, 0.4269, 0.42700000000000005, 0.42710000000000004, 0.4272, 0.4273, 0.4274, 0.42750000000000005, 0.42760000000000004, 0.4277, 0.4278, 0.4279, 0.42800000000000005, 0.42810000000000004, 0.4282, 0.4283, 0.4284, 0.42850000000000005, 0.42860000000000004, 0.4287, 0.4288, 0.4289, 0.42900000000000005, 0.42910000000000004, 0.4292, 0.4293, 0.4294, 0.4295, 0.42960000000000004, 0.4297, 0.4298, 0.4299, 0.43, 0.43010000000000004, 0.4302, 0.4303, 0.4304, 0.4305, 0.43060000000000004, 0.4307, 0.4308, 0.4309, 0.431, 0.43110000000000004, 0.4312, 0.4313, 0.4314, 0.4315, 0.43160000000000004, 0.43170000000000003, 0.4318, 0.4319, 0.432, 0.43210000000000004, 0.43220000000000003, 0.4323, 0.4324, 0.4325, 0.43260000000000004, 0.43270000000000003, 0.4328, 0.4329, 0.433, 0.43310000000000004, 0.43320000000000003, 0.4333, 0.4334, 0.4335, 0.43360000000000004, 0.43370000000000003, 0.4338, 0.4339, 0.434, 0.43410000000000004, 0.43420000000000003, 0.4343, 0.4344, 0.4345, 0.43460000000000004, 0.43470000000000003, 0.4348, 0.4349, 0.435, 0.43510000000000004, 0.43520000000000003, 0.4353, 0.4354, 0.4355, 0.43560000000000004, 0.43570000000000003, 0.4358, 0.4359, 0.436, 0.43610000000000004, 0.43620000000000003, 0.4363, 0.4364, 0.4365, 0.43660000000000004, 0.43670000000000003, 0.4368, 0.4369, 0.437, 0.43710000000000004, 0.43720000000000003, 0.4373, 0.4374, 0.4375, 0.43760000000000004, 0.43770000000000003, 0.4378, 0.4379, 0.438, 0.43810000000000004, 0.43820000000000003, 0.4383, 0.4384, 0.4385, 0.43860000000000005, 0.43870000000000003, 0.4388, 0.4389, 0.439, 0.43910000000000005, 0.43920000000000003, 0.4393, 0.4394, 0.4395, 0.43960000000000005, 0.43970000000000004, 0.4398, 0.4399, 0.44, 0.44010000000000005, 0.44020000000000004, 0.4403, 0.4404, 0.4405, 0.44060000000000005, 0.44070000000000004, 0.4408, 0.4409, 0.441, 0.44110000000000005, 0.44120000000000004, 0.4413, 0.4414, 0.4415, 0.44160000000000005, 0.44170000000000004, 0.4418, 0.4419, 0.442, 0.44210000000000005, 0.44220000000000004, 0.4423, 0.4424, 0.4425, 0.44260000000000005, 0.44270000000000004, 0.4428, 0.4429, 0.443, 0.4431, 0.44320000000000004, 0.4433, 0.4434, 0.4435, 0.4436, 0.44370000000000004, 0.44380000000000003, 0.4439, 0.444, 0.4441, 0.44420000000000004, 0.44430000000000003, 0.4444, 0.4445, 0.4446, 0.44470000000000004, 0.44480000000000003, 0.4449, 0.445, 0.4451, 0.44520000000000004, 0.44530000000000003, 0.4454, 0.4455, 0.4456, 0.44570000000000004, 0.44580000000000003, 0.4459, 0.446, 0.4461, 0.44620000000000004, 0.44630000000000003, 0.4464, 0.4465, 0.4466, 0.44670000000000004, 0.44680000000000003, 0.4469, 0.447, 0.4471, 0.44720000000000004, 0.44730000000000003, 0.4474, 0.4475, 0.4476, 0.44770000000000004, 0.44780000000000003, 0.4479, 0.448, 0.4481, 0.44820000000000004, 0.44830000000000003, 0.4484, 0.4485, 0.4486, 0.44870000000000004, 0.44880000000000003, 0.4489, 0.449, 0.4491, 0.44920000000000004, 0.44930000000000003, 0.4494, 0.4495, 0.4496, 0.44970000000000004, 0.44980000000000003, 0.4499, 0.45, 0.4501, 0.45020000000000004, 0.45030000000000003, 0.4504, 0.4505, 0.4506, 0.45070000000000005, 0.45080000000000003, 0.4509, 0.451, 0.4511, 0.45120000000000005, 0.45130000000000003, 0.4514, 0.4515, 0.4516, 0.45170000000000005, 0.45180000000000003, 0.4519, 0.452, 0.4521, 0.45220000000000005, 0.45230000000000004, 0.4524, 0.4525, 0.4526, 0.45270000000000005, 0.45280000000000004, 0.4529, 0.453, 0.4531, 0.45320000000000005, 0.45330000000000004, 0.4534, 0.4535, 0.4536, 0.45370000000000005, 0.45380000000000004, 0.4539, 0.454, 0.4541, 0.45420000000000005, 0.45430000000000004, 0.4544, 0.4545, 0.4546, 0.45470000000000005, 0.45480000000000004, 0.4549, 0.455, 0.4551, 0.45520000000000005, 0.45530000000000004, 0.4554, 0.4555, 0.4556, 0.45570000000000005, 0.45580000000000004, 0.4559, 0.456, 0.4561, 0.4562, 0.45630000000000004, 0.45640000000000003, 0.4565, 0.4566, 0.4567, 0.45680000000000004, 0.45690000000000003, 0.457, 0.4571, 0.4572, 0.45730000000000004, 0.45740000000000003, 0.4575, 0.4576, 0.4577, 0.45780000000000004, 0.45790000000000003, 0.458, 0.4581, 0.4582, 0.45830000000000004, 0.45840000000000003, 0.4585, 0.4586, 0.4587, 0.45880000000000004, 0.45890000000000003, 0.459, 0.4591, 0.4592, 0.45930000000000004, 0.45940000000000003, 0.4595, 0.4596, 0.4597, 0.45980000000000004, 0.45990000000000003, 0.46, 0.4601, 0.4602, 0.46030000000000004, 0.46040000000000003, 0.4605, 0.4606, 0.4607, 0.46080000000000004, 0.46090000000000003, 0.461, 0.4611, 0.4612, 0.46130000000000004, 0.46140000000000003, 0.4615, 0.4616, 0.4617, 0.46180000000000004, 0.46190000000000003, 0.462, 0.4621, 0.4622, 0.46230000000000004, 0.46240000000000003, 0.4625, 0.4626, 0.4627, 0.46280000000000004, 0.46290000000000003, 0.463, 0.4631, 0.4632, 0.46330000000000005, 0.46340000000000003, 0.4635, 0.4636, 0.4637, 0.46380000000000005, 0.46390000000000003, 0.464, 0.4641, 0.4642, 0.46430000000000005, 0.46440000000000003, 0.4645, 0.4646, 0.4647, 0.46480000000000005, 0.46490000000000004, 0.465, 0.4651, 0.4652, 0.46530000000000005, 0.46540000000000004, 0.4655, 0.4656, 0.4657, 0.46580000000000005, 0.46590000000000004, 0.466, 0.4661, 0.4662, 0.46630000000000005, 0.46640000000000004, 0.4665, 0.4666, 0.4667, 0.46680000000000005, 0.46690000000000004, 0.467, 0.4671, 0.4672, 0.46730000000000005, 0.46740000000000004, 0.4675, 0.4676, 0.4677, 0.46780000000000005, 0.46790000000000004, 0.468, 0.4681, 0.4682, 0.46830000000000005, 0.46840000000000004, 0.4685, 0.4686, 0.4687, 0.46880000000000005, 0.46890000000000004, 0.46900000000000003, 0.4691, 0.4692, 0.4693, 0.46940000000000004, 0.46950000000000003, 0.4696, 0.4697, 0.4698, 0.46990000000000004, 0.47000000000000003, 0.4701, 0.4702, 0.4703, 0.47040000000000004, 0.47050000000000003, 0.4706, 0.4707, 0.4708, 0.47090000000000004, 0.47100000000000003, 0.4711, 0.4712, 0.4713, 0.47140000000000004, 0.47150000000000003, 0.4716, 0.4717, 0.4718, 0.47190000000000004, 0.47200000000000003, 0.4721, 0.4722, 0.4723, 0.47240000000000004, 0.47250000000000003, 0.4726, 0.4727, 0.4728, 0.47290000000000004, 0.47300000000000003, 0.4731, 0.4732, 0.4733, 0.47340000000000004, 0.47350000000000003, 0.4736, 0.4737, 0.4738, 0.47390000000000004, 0.47400000000000003, 0.4741, 0.4742, 0.4743, 0.47440000000000004, 0.47450000000000003, 0.4746, 0.4747, 0.4748, 0.47490000000000004, 0.47500000000000003, 0.4751, 0.4752, 0.4753, 0.47540000000000004, 0.47550000000000003, 0.4756, 0.4757, 0.4758, 0.47590000000000005, 0.47600000000000003, 0.4761, 0.4762, 0.4763, 0.47640000000000005, 0.47650000000000003, 0.4766, 0.4767, 0.4768, 0.47690000000000005, 0.47700000000000004, 0.4771, 0.4772, 0.4773, 0.47740000000000005, 0.47750000000000004, 0.4776, 0.4777, 0.4778, 0.47790000000000005, 0.47800000000000004, 0.4781, 0.4782, 0.4783, 0.47840000000000005, 0.47850000000000004, 0.4786, 0.4787, 0.4788, 0.47890000000000005, 0.47900000000000004, 0.4791, 0.4792, 0.4793, 0.47940000000000005, 0.47950000000000004, 0.4796, 0.4797, 0.4798, 0.47990000000000005, 0.48000000000000004, 0.4801, 0.4802, 0.4803, 0.48040000000000005, 0.48050000000000004, 0.4806, 0.4807, 0.4808, 0.48090000000000005, 0.48100000000000004, 0.4811, 0.4812, 0.4813, 0.48140000000000005, 0.48150000000000004, 0.48160000000000003, 0.4817, 0.4818, 0.48190000000000005, 0.48200000000000004, 0.48210000000000003, 0.4822, 0.4823, 0.4824, 0.48250000000000004, 0.48260000000000003, 0.4827, 0.4828, 0.4829, 0.48300000000000004, 0.48310000000000003, 0.4832, 0.4833, 0.4834, 0.48350000000000004, 0.48360000000000003, 0.4837, 0.4838, 0.4839, 0.48400000000000004, 0.48410000000000003, 0.4842, 0.4843, 0.4844, 0.48450000000000004, 0.48460000000000003, 0.4847, 0.4848, 0.4849, 0.48500000000000004, 0.48510000000000003, 0.4852, 0.4853, 0.4854, 0.48550000000000004, 0.48560000000000003, 0.4857, 0.4858, 0.4859, 0.48600000000000004, 0.48610000000000003, 0.4862, 0.4863, 0.4864, 0.48650000000000004, 0.48660000000000003, 0.4867, 0.4868, 0.4869, 0.48700000000000004, 0.48710000000000003, 0.4872, 0.4873, 0.4874, 0.48750000000000004, 0.48760000000000003, 0.4877, 0.4878, 0.4879, 0.48800000000000004, 0.48810000000000003, 0.4882, 0.4883, 0.4884, 0.48850000000000005, 0.48860000000000003, 0.4887, 0.4888, 0.4889, 0.48900000000000005, 0.48910000000000003, 0.4892, 0.4893, 0.4894, 0.48950000000000005, 0.48960000000000004, 0.4897, 0.4898, 0.4899, 0.49000000000000005, 0.49010000000000004, 0.4902, 0.4903, 0.4904, 0.49050000000000005, 0.49060000000000004, 0.4907, 0.4908, 0.4909, 0.49100000000000005, 0.49110000000000004, 0.4912, 0.4913, 0.4914, 0.49150000000000005, 0.49160000000000004, 0.4917, 0.4918, 0.4919, 0.49200000000000005, 0.49210000000000004, 0.4922, 0.4923, 0.4924, 0.49250000000000005, 0.49260000000000004, 0.4927, 0.4928, 0.4929, 0.49300000000000005, 0.49310000000000004, 0.4932, 0.4933, 0.4934, 0.49350000000000005, 0.49360000000000004, 0.4937, 0.4938, 0.4939, 0.49400000000000005, 0.49410000000000004, 0.49420000000000003, 0.4943, 0.4944, 0.49450000000000005, 0.49460000000000004, 0.49470000000000003, 0.4948, 0.4949, 0.49500000000000005, 0.49510000000000004, 0.49520000000000003, 0.4953, 0.4954, 0.4955, 0.49560000000000004, 0.49570000000000003, 0.4958, 0.4959, 0.496, 0.49610000000000004, 0.49620000000000003, 0.4963, 0.4964, 0.4965, 0.49660000000000004, 0.49670000000000003, 0.4968, 0.4969, 0.497, 0.49710000000000004, 0.49720000000000003, 0.4973, 0.4974, 0.4975, 0.49760000000000004, 0.49770000000000003, 0.4978, 0.4979, 0.498, 0.49810000000000004, 0.49820000000000003, 0.4983, 0.4984, 0.4985, 0.49860000000000004, 0.49870000000000003, 0.4988, 0.4989, 0.499, 0.49910000000000004, 0.49920000000000003, 0.4993, 0.4994, 0.4995, 0.49960000000000004, 0.49970000000000003, 0.4998, 0.4999, 0.5]\n",
      "x = [0.0, 0.02040816326530612, 0.04081632653061224, 0.061224489795918366, 0.08163265306122448, 0.1020408163265306, 0.12244897959183673, 0.14285714285714285, 0.16326530612244897, 0.18367346938775508, 0.2040816326530612, 0.22448979591836732, 0.24489795918367346, 0.26530612244897955, 0.2857142857142857, 0.3061224489795918, 0.32653061224489793, 0.3469387755102041, 0.36734693877551017, 0.3877551020408163, 0.4081632653061224, 0.42857142857142855, 0.44897959183673464, 0.4693877551020408, 0.4897959183673469, 0.5102040816326531, 0.5306122448979591, 0.5510204081632653, 0.5714285714285714, 0.5918367346938775, 0.6122448979591836, 0.6326530612244897, 0.6530612244897959, 0.673469387755102, 0.6938775510204082, 0.7142857142857142, 0.7346938775510203, 0.7551020408163265, 0.7755102040816326, 0.7959183673469387, 0.8163265306122448, 0.836734693877551, 0.8571428571428571, 0.8775510204081632, 0.8979591836734693, 0.9183673469387754, 0.9387755102040816, 0.9591836734693877, 0.9795918367346939, 1.0]\n"
     ]
    }
   ],
   "source": [
    "#Check\n",
    "variable_data = [(key, values) for key, values in variable_values.items()]\n",
    "\n",
    "for variable, values in variable_data:\n",
    "    print(f\"{variable} = {values}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bdf8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second Key: x\n",
      "Second Values: [0.0, 0.02040816326530612, 0.04081632653061224, 0.061224489795918366, 0.08163265306122448, 0.1020408163265306, 0.12244897959183673, 0.14285714285714285, 0.16326530612244897, 0.18367346938775508, 0.2040816326530612, 0.22448979591836732, 0.24489795918367346, 0.26530612244897955, 0.2857142857142857, 0.3061224489795918, 0.32653061224489793, 0.3469387755102041, 0.36734693877551017, 0.3877551020408163, 0.4081632653061224, 0.42857142857142855, 0.44897959183673464, 0.4693877551020408, 0.4897959183673469, 0.5102040816326531, 0.5306122448979591, 0.5510204081632653, 0.5714285714285714, 0.5918367346938775, 0.6122448979591836, 0.6326530612244897, 0.6530612244897959, 0.673469387755102, 0.6938775510204082, 0.7142857142857142, 0.7346938775510203, 0.7551020408163265, 0.7755102040816326, 0.7959183673469387, 0.8163265306122448, 0.836734693877551, 0.8571428571428571, 0.8775510204081632, 0.8979591836734693, 0.9183673469387754, 0.9387755102040816, 0.9591836734693877, 0.9795918367346939, 1.0]\n"
     ]
    }
   ],
   "source": [
    "second_key, second_values = variable_data[1]\n",
    "\n",
    "print(f\"Second Key: {second_key}\")\n",
    "print(f\"Second Values: {second_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123a29b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss is 0.10297242682980556\n"
     ]
    }
   ],
   "source": [
    "def calculate_loss(PDE_value, ic_loss, bc_loss, ic_weight=1.0, bc_weight=1.0):\n",
    "    pde_loss = np.mean((PDE_value - 0) ** 2)\n",
    "\n",
    "    condition_type = input(\"Enter whether the problem is initial, boundary or both: \").strip().lower()\n",
    "\n",
    "    if condition_type == 'initial':\n",
    "        total_loss = pde_loss + ic_weight * np.mean([np.mean(value) for value in ic_loss.values()])\n",
    "    elif condition_type == 'boundary':\n",
    "        total_loss = pde_loss + bc_weight * bc_loss\n",
    "    else:\n",
    "\n",
    "        total_loss = pde_loss + ic_weight * np.mean(ic_loss) + bc_weight * bc_loss\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "ic_loss = np.mean(ic_loss_values)\n",
    "bc_loss = 0\n",
    "\n",
    "total_loss = calculate_loss(PDE_value, ic_loss, bc_loss, ic_weight=1.0, bc_weight=1.0)\n",
    "print('Total loss is', total_loss)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36f69d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Derivatives:\n",
      "Variable: t, Order: 1, Value: -4.638893657032501e-14\n",
      "Variable: t, Order: 2, Value: -1.4773546678447454e-14\n",
      "Variable: x, Order: 1, Value: -4.638893657032501e-14\n",
      "Variable: x, Order: 2, Value: -1.4773546678447454e-14\n",
      "Iteration 1, Loss: 0.10297242682980556, Parameter: 0.11782064759981957\n",
      "Derivatives:\n",
      "Variable: t, Order: 1, Value: -4.638893657032501e-14\n",
      "Variable: t, Order: 2, Value: -1.4773546678447454e-14\n",
      "Variable: x, Order: 1, Value: -4.638893657032501e-14\n",
      "Variable: x, Order: 2, Value: -1.4773546678447454e-14\n",
      "Iteration 2, Loss: 0.10283426603087094, Parameter: 0.11679230494004275\n",
      "Derivatives:\n",
      "Variable: t, Order: 1, Value: -4.638893657032501e-14\n",
      "Variable: t, Order: 2, Value: -1.4773546678447454e-14\n",
      "Variable: x, Order: 1, Value: -4.638893657032501e-14\n",
      "Variable: x, Order: 2, Value: -1.4773546678447454e-14\n",
      "Iteration 3, Loss: 0.10269495587555103, Parameter: 0.11576535538181913\n",
      "Derivatives:\n",
      "Variable: t, Order: 1, Value: -4.638893657032501e-14\n",
      "Variable: t, Order: 2, Value: -1.4773546678447454e-14\n",
      "Variable: x, Order: 1, Value: -4.638893657032501e-14\n",
      "Variable: x, Order: 2, Value: -1.4773546678447454e-14\n",
      "Iteration 4, Loss: 0.10255450541135401, Parameter: 0.11473981032823749\n",
      "Derivatives:\n",
      "Variable: t, Order: 1, Value: -4.638893657032501e-14\n",
      "Variable: t, Order: 2, Value: -1.4773546678447454e-14\n",
      "Variable: x, Order: 1, Value: -4.638893657032501e-14\n",
      "Variable: x, Order: 2, Value: -1.4773546678447454e-14\n",
      "Iteration 5, Loss: 0.10241292382083435, Parameter: 0.11371568109056104\n",
      "Derivatives:\n",
      "Variable: t, Order: 1, Value: -4.638893657032501e-14\n",
      "Variable: t, Order: 2, Value: -1.4773546678447454e-14\n",
      "Variable: x, Order: 1, Value: -4.638893657032501e-14\n",
      "Variable: x, Order: 2, Value: -1.4773546678447454e-14\n",
      "Iteration 6, Loss: 0.10227022041899046, Parameter: 0.11269297888690304\n",
      "Derivatives:\n",
      "Variable: t, Order: 1, Value: -4.638893657032501e-14\n",
      "Variable: t, Order: 2, Value: -1.4773546678447454e-14\n",
      "Variable: x, Order: 1, Value: -4.638893657032501e-14\n",
      "Variable: x, Order: 2, Value: -1.4773546678447454e-14\n",
      "Iteration 7, Loss: 0.10212640465062953, Parameter: 0.11167171484092864\n",
      "Derivatives:\n",
      "Variable: t, Order: 1, Value: -4.638893657032501e-14\n",
      "Variable: t, Order: 2, Value: -1.4773546678447454e-14\n",
      "Variable: x, Order: 1, Value: -4.638893657032501e-14\n",
      "Variable: x, Order: 2, Value: -1.4773546678447454e-14\n",
      "Iteration 8, Loss: 0.10198148608770044, Parameter: 0.11065189998058353\n",
      "Derivatives:\n",
      "Variable: t, Order: 1, Value: -4.638893657032501e-14\n",
      "Variable: t, Order: 2, Value: -1.4773546678447454e-14\n",
      "Variable: x, Order: 1, Value: -4.638893657032501e-14\n",
      "Variable: x, Order: 2, Value: -1.4773546678447454e-14\n",
      "Iteration 9, Loss: 0.10183547442659606, Parameter: 0.10963354523684947\n",
      "Derivatives:\n",
      "Variable: t, Order: 1, Value: -4.638893657032501e-14\n",
      "Variable: t, Order: 2, Value: -1.4773546678447454e-14\n",
      "Variable: x, Order: 1, Value: -4.638893657032501e-14\n",
      "Variable: x, Order: 2, Value: -1.4773546678447454e-14\n",
      "Iteration 10, Loss: 0.1016883794854276, Parameter: 0.10861666144252709\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "alpha = 0.01\n",
    "ic_weight = 1\n",
    "bc_weight = 1\n",
    "loss_values = []\n",
    "param_values = [] \n",
    "num_iterations = 10\n",
    "\n",
    "# gradient descent\n",
    "for n in range(num_iterations):\n",
    "    # Calculate the loss\n",
    "    ic_loss_values = cost_fn_ic(params, num_layers, variable_values_list)\n",
    "    ic_loss = np.mean(ic_loss_values)\n",
    "    bc_loss = 0  # Assuming bc_loss is zero \n",
    "    \n",
    "    loss = calculate_loss(PDE_value, ic_loss, bc_loss, ic_weight, bc_weight)\n",
    "\n",
    "    # Calculating  the gradient of the loss with respect to the parameter\n",
    "    gradient = ic_weight * ic_loss - 2 * (PDE_value - 0)  \n",
    "\n",
    "    # Updating the parameters\n",
    "    params = params - alpha * gradient \n",
    "\n",
    "    # Recalculate PDE value\n",
    "    PDE_value = calculate_PDE_from_derivatives(derivatives, variable_names, total_cost)\n",
    "    loss_values.append(loss)\n",
    "    param_values.append(params.flatten()[0])  \n",
    "    print(f\"Iteration {n+1}, Loss: {loss}, Parameter: {params.flatten()[0]}\")\n",
    "\n",
    "# Plot Loss vs Iteration number\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(param_values, loss_values)\n",
    "plt.xlabel('Theta (First parameter in params)')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss vs Theta')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc60061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Provided data\n",
    "data = \"\"\"\n",
    "Iteration 1, Loss: 0.10297242682980556, Parameter: 0.11782064759981957\n",
    "Iteration 2, Loss: 0.10283426603087094, Parameter: 0.11679230494004275\n",
    "Iteration 3, Loss: 0.10269495587555103, Parameter: 0.11576535538181913\n",
    "Iteration 4, Loss: 0.10255450541135401, Parameter: 0.11473981032823749\n",
    "Iteration 5, Loss: 0.10241292382083435, Parameter: 0.11371568109056104\n",
    "Iteration 6, Loss: 0.10227022041899046, Parameter: 0.11269297888690304\n",
    "Iteration 7, Loss: 0.10212640465062953, Parameter: 0.11167171484092864\n",
    "Iteration 8, Loss: 0.10198148608770044, Parameter: 0.11065189998058353\n",
    "Iteration 9, Loss: 0.10183547442659606, Parameter: 0.10963354523684947\n",
    "Iteration 10, Loss: 0.1016883794854276, Parameter: 0.10861666144252709\n",
    "\"\"\"\n",
    "\n",
    "# Parse the data\n",
    "iterations = []\n",
    "loss_values = []\n",
    "\n",
    "for line in data.strip().split(\"\\n\"):\n",
    "    parts = line.split(\", \")\n",
    "    iteration = int(parts[0].split()[1])\n",
    "    loss = float(parts[1].split()[1])\n",
    "    iterations.append(iteration)\n",
    "    loss_values.append(loss)\n",
    "\n",
    "# Plotting the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(iterations, loss_values, marker='o', linestyle='-', color='b')\n",
    "plt.title('Loss vs. Iteration')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d867cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.10861666144252709"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9882431d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(0.90846017, requires_grad=True)]        [-1.]\n",
      "[tensor(0.88689037, requires_grad=True)]        [-0.998]\n",
      "[tensor(0.87376801, requires_grad=True)]        [-0.996]\n",
      "[tensor(0.862062, requires_grad=True)]        [-0.994]\n",
      "[tensor(0.85110175, requires_grad=True)]        [-0.992]\n",
      "[tensor(0.84062678, requires_grad=True)]        [-0.99]\n",
      "[tensor(0.83050316, requires_grad=True)]        [-0.988]\n",
      "[tensor(0.82065114, requires_grad=True)]        [-0.986]\n",
      "[tensor(0.81101859, requires_grad=True)]        [-0.984]\n",
      "[tensor(0.80156924, requires_grad=True)]        [-0.982]\n",
      "[tensor(0.7922766, requires_grad=True)]        [-0.98]\n",
      "[tensor(0.78312062, requires_grad=True)]        [-0.978]\n",
      "[tensor(0.77408568, requires_grad=True)]        [-0.976]\n",
      "[tensor(0.76515935, requires_grad=True)]        [-0.974]\n",
      "[tensor(0.7563315, requires_grad=True)]        [-0.972]\n",
      "[tensor(0.74759377, requires_grad=True)]        [-0.97]\n",
      "[tensor(0.73893916, requires_grad=True)]        [-0.968]\n",
      "[tensor(0.73036173, requires_grad=True)]        [-0.966]\n",
      "[tensor(0.72185638, requires_grad=True)]        [-0.964]\n",
      "[tensor(0.71341871, requires_grad=True)]        [-0.962]\n",
      "[tensor(0.70504488, requires_grad=True)]        [-0.96]\n",
      "[tensor(0.69673152, requires_grad=True)]        [-0.958]\n",
      "[tensor(0.68847563, requires_grad=True)]        [-0.956]\n",
      "[tensor(0.68027458, requires_grad=True)]        [-0.954]\n",
      "[tensor(0.67212597, requires_grad=True)]        [-0.952]\n",
      "[tensor(0.66402767, requires_grad=True)]        [-0.95]\n",
      "[tensor(0.65597775, requires_grad=True)]        [-0.948]\n",
      "[tensor(0.64797447, requires_grad=True)]        [-0.946]\n",
      "[tensor(0.64001622, requires_grad=True)]        [-0.944]\n",
      "[tensor(0.63210156, requires_grad=True)]        [-0.942]\n",
      "[tensor(0.62422914, requires_grad=True)]        [-0.94]\n",
      "[tensor(0.61639774, requires_grad=True)]        [-0.938]\n",
      "[tensor(0.60860622, requires_grad=True)]        [-0.936]\n",
      "[tensor(0.60085354, requires_grad=True)]        [-0.934]\n",
      "[tensor(0.59313873, requires_grad=True)]        [-0.932]\n",
      "[tensor(0.58546088, requires_grad=True)]        [-0.93]\n",
      "[tensor(0.57781916, requires_grad=True)]        [-0.928]\n",
      "[tensor(0.57021277, requires_grad=True)]        [-0.926]\n",
      "[tensor(0.56264098, requires_grad=True)]        [-0.924]\n",
      "[tensor(0.55510312, requires_grad=True)]        [-0.922]\n",
      "[tensor(0.54759852, requires_grad=True)]        [-0.92]\n",
      "[tensor(0.54012659, requires_grad=True)]        [-0.918]\n",
      "[tensor(0.53268674, requires_grad=True)]        [-0.916]\n",
      "[tensor(0.52527846, requires_grad=True)]        [-0.914]\n",
      "[tensor(0.51790121, requires_grad=True)]        [-0.912]\n",
      "[tensor(0.51055452, requires_grad=True)]        [-0.91]\n",
      "[tensor(0.50323794, requires_grad=True)]        [-0.908]\n",
      "[tensor(0.49595103, requires_grad=True)]        [-0.906]\n",
      "[tensor(0.48869338, requires_grad=True)]        [-0.904]\n",
      "[tensor(0.4814646, requires_grad=True)]        [-0.902]\n",
      "[tensor(0.47426431, requires_grad=True)]        [-0.9]\n",
      "[tensor(0.46709217, requires_grad=True)]        [-0.898]\n",
      "[tensor(0.45994783, requires_grad=True)]        [-0.896]\n",
      "[tensor(0.45283098, requires_grad=True)]        [-0.894]\n",
      "[tensor(0.4457413, requires_grad=True)]        [-0.892]\n",
      "[tensor(0.43867849, requires_grad=True)]        [-0.89]\n",
      "[tensor(0.43164229, requires_grad=True)]        [-0.888]\n",
      "[tensor(0.42463241, requires_grad=True)]        [-0.886]\n",
      "[tensor(0.41764859, requires_grad=True)]        [-0.884]\n",
      "[tensor(0.4106906, requires_grad=True)]        [-0.882]\n",
      "[tensor(0.40375818, requires_grad=True)]        [-0.88]\n",
      "[tensor(0.39685111, requires_grad=True)]        [-0.878]\n",
      "[tensor(0.38996917, requires_grad=True)]        [-0.876]\n",
      "[tensor(0.38311214, requires_grad=True)]        [-0.874]\n",
      "[tensor(0.37627983, requires_grad=True)]        [-0.872]\n",
      "[tensor(0.36947203, requires_grad=True)]        [-0.87]\n",
      "[tensor(0.36268855, requires_grad=True)]        [-0.868]\n",
      "[tensor(0.35592921, requires_grad=True)]        [-0.866]\n",
      "[tensor(0.34919383, requires_grad=True)]        [-0.864]\n",
      "[tensor(0.34248225, requires_grad=True)]        [-0.862]\n",
      "[tensor(0.33579429, requires_grad=True)]        [-0.86]\n",
      "[tensor(0.32912979, requires_grad=True)]        [-0.858]\n",
      "[tensor(0.32248861, requires_grad=True)]        [-0.856]\n",
      "[tensor(0.31587059, requires_grad=True)]        [-0.854]\n",
      "[tensor(0.30927558, requires_grad=True)]        [-0.852]\n",
      "[tensor(0.30270345, requires_grad=True)]        [-0.85]\n",
      "[tensor(0.29615406, requires_grad=True)]        [-0.848]\n",
      "[tensor(0.28962727, requires_grad=True)]        [-0.846]\n",
      "[tensor(0.28312297, requires_grad=True)]        [-0.844]\n",
      "[tensor(0.27664102, requires_grad=True)]        [-0.842]\n",
      "[tensor(0.2701813, requires_grad=True)]        [-0.84]\n",
      "[tensor(0.26374369, requires_grad=True)]        [-0.838]\n",
      "[tensor(0.25732809, requires_grad=True)]        [-0.836]\n",
      "[tensor(0.25093438, requires_grad=True)]        [-0.834]\n",
      "[tensor(0.24456245, requires_grad=True)]        [-0.832]\n",
      "[tensor(0.2382122, requires_grad=True)]        [-0.83]\n",
      "[tensor(0.23188353, requires_grad=True)]        [-0.828]\n",
      "[tensor(0.22557633, requires_grad=True)]        [-0.826]\n",
      "[tensor(0.21929051, requires_grad=True)]        [-0.824]\n",
      "[tensor(0.21302598, requires_grad=True)]        [-0.822]\n",
      "[tensor(0.20678264, requires_grad=True)]        [-0.82]\n",
      "[tensor(0.2005604, requires_grad=True)]        [-0.818]\n",
      "[tensor(0.19435917, requires_grad=True)]        [-0.816]\n",
      "[tensor(0.18817888, requires_grad=True)]        [-0.814]\n",
      "[tensor(0.18201943, requires_grad=True)]        [-0.812]\n",
      "[tensor(0.17588075, requires_grad=True)]        [-0.81]\n",
      "[tensor(0.16976275, requires_grad=True)]        [-0.808]\n",
      "[tensor(0.16366536, requires_grad=True)]        [-0.806]\n",
      "[tensor(0.15758851, requires_grad=True)]        [-0.804]\n",
      "[tensor(0.15153211, requires_grad=True)]        [-0.802]\n",
      "[tensor(0.1454961, requires_grad=True)]        [-0.8]\n",
      "[tensor(0.1394804, requires_grad=True)]        [-0.798]\n",
      "[tensor(0.13348495, requires_grad=True)]        [-0.796]\n",
      "[tensor(0.12750968, requires_grad=True)]        [-0.794]\n",
      "[tensor(0.12155452, requires_grad=True)]        [-0.792]\n",
      "[tensor(0.11561941, requires_grad=True)]        [-0.79]\n",
      "[tensor(0.10970428, requires_grad=True)]        [-0.788]\n",
      "[tensor(0.10380907, requires_grad=True)]        [-0.786]\n",
      "[tensor(0.09793372, requires_grad=True)]        [-0.784]\n",
      "[tensor(0.09207818, requires_grad=True)]        [-0.782]\n",
      "[tensor(0.08624237, requires_grad=True)]        [-0.78]\n",
      "[tensor(0.08042625, requires_grad=True)]        [-0.778]\n",
      "[tensor(0.07462976, requires_grad=True)]        [-0.776]\n",
      "[tensor(0.06885284, requires_grad=True)]        [-0.774]\n",
      "[tensor(0.06309544, requires_grad=True)]        [-0.772]\n",
      "[tensor(0.05735751, requires_grad=True)]        [-0.77]\n",
      "[tensor(0.051639, requires_grad=True)]        [-0.768]\n",
      "[tensor(0.04593985, requires_grad=True)]        [-0.766]\n",
      "[tensor(0.04026001, requires_grad=True)]        [-0.764]\n",
      "[tensor(0.03459943, requires_grad=True)]        [-0.762]\n",
      "[tensor(0.02895808, requires_grad=True)]        [-0.76]\n",
      "[tensor(0.02333589, requires_grad=True)]        [-0.758]\n",
      "[tensor(0.01773282, requires_grad=True)]        [-0.756]\n",
      "[tensor(0.01214883, requires_grad=True)]        [-0.754]\n",
      "[tensor(0.00658388, requires_grad=True)]        [-0.752]\n",
      "[tensor(0.00103791, requires_grad=True)]        [-0.75]\n",
      "[tensor(-0.00448912, requires_grad=True)]        [-0.748]\n",
      "[tensor(-0.00999724, requires_grad=True)]        [-0.746]\n",
      "[tensor(-0.01548651, requires_grad=True)]        [-0.744]\n",
      "[tensor(-0.02095695, requires_grad=True)]        [-0.742]\n",
      "[tensor(-0.02640862, requires_grad=True)]        [-0.74]\n",
      "[tensor(-0.03184155, requires_grad=True)]        [-0.738]\n",
      "[tensor(-0.03725578, requires_grad=True)]        [-0.736]\n",
      "[tensor(-0.04265135, requires_grad=True)]        [-0.734]\n",
      "[tensor(-0.04802829, requires_grad=True)]        [-0.732]\n",
      "[tensor(-0.05338666, requires_grad=True)]        [-0.73]\n",
      "[tensor(-0.05872647, requires_grad=True)]        [-0.728]\n",
      "[tensor(-0.06404777, requires_grad=True)]        [-0.726]\n",
      "[tensor(-0.0693506, requires_grad=True)]        [-0.724]\n",
      "[tensor(-0.07463498, requires_grad=True)]        [-0.722]\n",
      "[tensor(-0.07990096, requires_grad=True)]        [-0.72]\n",
      "[tensor(-0.08514857, requires_grad=True)]        [-0.718]\n",
      "[tensor(-0.09037783, requires_grad=True)]        [-0.716]\n",
      "[tensor(-0.09558879, requires_grad=True)]        [-0.714]\n",
      "[tensor(-0.10078148, requires_grad=True)]        [-0.712]\n",
      "[tensor(-0.10595593, requires_grad=True)]        [-0.71]\n",
      "[tensor(-0.11111216, requires_grad=True)]        [-0.708]\n",
      "[tensor(-0.11625022, requires_grad=True)]        [-0.706]\n",
      "[tensor(-0.12137013, requires_grad=True)]        [-0.704]\n",
      "[tensor(-0.12647193, requires_grad=True)]        [-0.702]\n",
      "[tensor(-0.13155563, requires_grad=True)]        [-0.7]\n",
      "[tensor(-0.13662128, requires_grad=True)]        [-0.698]\n",
      "[tensor(-0.1416689, requires_grad=True)]        [-0.696]\n",
      "[tensor(-0.14669852, requires_grad=True)]        [-0.694]\n",
      "[tensor(-0.15171017, requires_grad=True)]        [-0.692]\n",
      "[tensor(-0.15670387, requires_grad=True)]        [-0.69]\n",
      "[tensor(-0.16167966, requires_grad=True)]        [-0.688]\n",
      "[tensor(-0.16663756, requires_grad=True)]        [-0.686]\n",
      "[tensor(-0.1715776, requires_grad=True)]        [-0.684]\n",
      "[tensor(-0.1764998, requires_grad=True)]        [-0.682]\n",
      "[tensor(-0.1814042, requires_grad=True)]        [-0.68]\n",
      "[tensor(-0.18629081, requires_grad=True)]        [-0.678]\n",
      "[tensor(-0.19115966, requires_grad=True)]        [-0.676]\n",
      "[tensor(-0.19601078, requires_grad=True)]        [-0.674]\n",
      "[tensor(-0.20084419, requires_grad=True)]        [-0.672]\n",
      "[tensor(-0.20565992, requires_grad=True)]        [-0.67]\n",
      "[tensor(-0.21045799, requires_grad=True)]        [-0.668]\n",
      "[tensor(-0.21523842, requires_grad=True)]        [-0.666]\n",
      "[tensor(-0.22000125, requires_grad=True)]        [-0.664]\n",
      "[tensor(-0.22474648, requires_grad=True)]        [-0.662]\n",
      "[tensor(-0.22947415, requires_grad=True)]        [-0.66]\n",
      "[tensor(-0.23418428, requires_grad=True)]        [-0.658]\n",
      "[tensor(-0.23887689, requires_grad=True)]        [-0.656]\n",
      "[tensor(-0.24355201, requires_grad=True)]        [-0.654]\n",
      "[tensor(-0.24820964, requires_grad=True)]        [-0.652]\n",
      "[tensor(-0.25284983, requires_grad=True)]        [-0.65]\n",
      "[tensor(-0.25747259, requires_grad=True)]        [-0.648]\n",
      "[tensor(-0.26207793, requires_grad=True)]        [-0.646]\n",
      "[tensor(-0.26666589, requires_grad=True)]        [-0.644]\n",
      "[tensor(-0.27123648, requires_grad=True)]        [-0.642]\n",
      "[tensor(-0.27578972, requires_grad=True)]        [-0.64]\n",
      "[tensor(-0.28032563, requires_grad=True)]        [-0.638]\n",
      "[tensor(-0.28484424, requires_grad=True)]        [-0.636]\n",
      "[tensor(-0.28934556, requires_grad=True)]        [-0.634]\n",
      "[tensor(-0.29382962, requires_grad=True)]        [-0.632]\n",
      "[tensor(-0.29829642, requires_grad=True)]        [-0.63]\n",
      "[tensor(-0.302746, requires_grad=True)]        [-0.628]\n",
      "[tensor(-0.30717838, requires_grad=True)]        [-0.626]\n",
      "[tensor(-0.31159356, requires_grad=True)]        [-0.624]\n",
      "[tensor(-0.31599157, requires_grad=True)]        [-0.622]\n",
      "[tensor(-0.32037243, requires_grad=True)]        [-0.62]\n",
      "[tensor(-0.32473615, requires_grad=True)]        [-0.618]\n",
      "[tensor(-0.32908276, requires_grad=True)]        [-0.616]\n",
      "[tensor(-0.33341227, requires_grad=True)]        [-0.614]\n",
      "[tensor(-0.3377247, requires_grad=True)]        [-0.612]\n",
      "[tensor(-0.34202007, requires_grad=True)]        [-0.61]\n",
      "[tensor(-0.3462984, requires_grad=True)]        [-0.608]\n",
      "[tensor(-0.3505597, requires_grad=True)]        [-0.606]\n",
      "[tensor(-0.35480398, requires_grad=True)]        [-0.604]\n",
      "[tensor(-0.35903128, requires_grad=True)]        [-0.602]\n",
      "[tensor(-0.3632416, requires_grad=True)]        [-0.6]\n",
      "[tensor(-0.36743496, requires_grad=True)]        [-0.598]\n",
      "[tensor(-0.37161137, requires_grad=True)]        [-0.596]\n",
      "[tensor(-0.37577086, requires_grad=True)]        [-0.594]\n",
      "[tensor(-0.37991344, requires_grad=True)]        [-0.592]\n",
      "[tensor(-0.38403913, requires_grad=True)]        [-0.59]\n",
      "[tensor(-0.38814793, requires_grad=True)]        [-0.588]\n",
      "[tensor(-0.39223988, requires_grad=True)]        [-0.586]\n",
      "[tensor(-0.39631497, requires_grad=True)]        [-0.584]\n",
      "[tensor(-0.40037324, requires_grad=True)]        [-0.582]\n",
      "[tensor(-0.40441469, requires_grad=True)]        [-0.58]\n",
      "[tensor(-0.40843934, requires_grad=True)]        [-0.578]\n",
      "[tensor(-0.4124472, requires_grad=True)]        [-0.576]\n",
      "[tensor(-0.4164383, requires_grad=True)]        [-0.574]\n",
      "[tensor(-0.42041263, requires_grad=True)]        [-0.572]\n",
      "[tensor(-0.42437023, requires_grad=True)]        [-0.57]\n",
      "[tensor(-0.4283111, requires_grad=True)]        [-0.568]\n",
      "[tensor(-0.43223525, requires_grad=True)]        [-0.566]\n",
      "[tensor(-0.43614271, requires_grad=True)]        [-0.564]\n",
      "[tensor(-0.44003349, requires_grad=True)]        [-0.562]\n",
      "[tensor(-0.4439076, requires_grad=True)]        [-0.56]\n",
      "[tensor(-0.44776505, requires_grad=True)]        [-0.558]\n",
      "[tensor(-0.45160586, requires_grad=True)]        [-0.556]\n",
      "[tensor(-0.45543004, requires_grad=True)]        [-0.554]\n",
      "[tensor(-0.45923761, requires_grad=True)]        [-0.552]\n",
      "[tensor(-0.46302858, requires_grad=True)]        [-0.55]\n",
      "[tensor(-0.46680296, requires_grad=True)]        [-0.548]\n",
      "[tensor(-0.47056077, requires_grad=True)]        [-0.546]\n",
      "[tensor(-0.47430202, requires_grad=True)]        [-0.544]\n",
      "[tensor(-0.47802672, requires_grad=True)]        [-0.542]\n",
      "[tensor(-0.48173488, requires_grad=True)]        [-0.54]\n",
      "[tensor(-0.48542653, requires_grad=True)]        [-0.538]\n",
      "[tensor(-0.48910166, requires_grad=True)]        [-0.536]\n",
      "[tensor(-0.4927603, requires_grad=True)]        [-0.534]\n",
      "[tensor(-0.49640246, requires_grad=True)]        [-0.532]\n",
      "[tensor(-0.50002815, requires_grad=True)]        [-0.53]\n",
      "[tensor(-0.50363738, requires_grad=True)]        [-0.528]\n",
      "[tensor(-0.50723016, requires_grad=True)]        [-0.526]\n",
      "[tensor(-0.51080651, requires_grad=True)]        [-0.524]\n",
      "[tensor(-0.51436644, requires_grad=True)]        [-0.522]\n",
      "[tensor(-0.51790996, requires_grad=True)]        [-0.52]\n",
      "[tensor(-0.52143708, requires_grad=True)]        [-0.518]\n",
      "[tensor(-0.52494782, requires_grad=True)]        [-0.516]\n",
      "[tensor(-0.52844218, requires_grad=True)]        [-0.514]\n",
      "[tensor(-0.53192019, requires_grad=True)]        [-0.512]\n",
      "[tensor(-0.53538184, requires_grad=True)]        [-0.51]\n",
      "[tensor(-0.53882715, requires_grad=True)]        [-0.508]\n",
      "[tensor(-0.54225614, requires_grad=True)]        [-0.506]\n",
      "[tensor(-0.54566881, requires_grad=True)]        [-0.504]\n",
      "[tensor(-0.54906518, requires_grad=True)]        [-0.502]\n",
      "[tensor(-0.55244526, requires_grad=True)]        [-0.5]\n",
      "[tensor(-0.55580905, requires_grad=True)]        [-0.498]\n",
      "[tensor(-0.55915658, requires_grad=True)]        [-0.496]\n",
      "[tensor(-0.56248784, requires_grad=True)]        [-0.494]\n",
      "[tensor(-0.56580286, requires_grad=True)]        [-0.492]\n",
      "[tensor(-0.56910164, requires_grad=True)]        [-0.49]\n",
      "[tensor(-0.57238419, requires_grad=True)]        [-0.488]\n",
      "[tensor(-0.57565053, requires_grad=True)]        [-0.486]\n",
      "[tensor(-0.57890066, requires_grad=True)]        [-0.484]\n",
      "[tensor(-0.5821346, requires_grad=True)]        [-0.482]\n",
      "[tensor(-0.58535236, requires_grad=True)]        [-0.48]\n",
      "[tensor(-0.58855394, requires_grad=True)]        [-0.478]\n",
      "[tensor(-0.59173936, requires_grad=True)]        [-0.476]\n",
      "[tensor(-0.59490862, requires_grad=True)]        [-0.474]\n",
      "[tensor(-0.59806175, requires_grad=True)]        [-0.472]\n",
      "[tensor(-0.60119874, requires_grad=True)]        [-0.47]\n",
      "[tensor(-0.60431961, requires_grad=True)]        [-0.468]\n",
      "[tensor(-0.60742437, requires_grad=True)]        [-0.466]\n",
      "[tensor(-0.61051303, requires_grad=True)]        [-0.464]\n",
      "[tensor(-0.61358559, requires_grad=True)]        [-0.462]\n",
      "[tensor(-0.61664208, requires_grad=True)]        [-0.46]\n",
      "[tensor(-0.61968249, requires_grad=True)]        [-0.458]\n",
      "[tensor(-0.62270684, requires_grad=True)]        [-0.456]\n",
      "[tensor(-0.62571514, requires_grad=True)]        [-0.454]\n",
      "[tensor(-0.6287074, requires_grad=True)]        [-0.452]\n",
      "[tensor(-0.63168362, requires_grad=True)]        [-0.45]\n",
      "[tensor(-0.63464382, requires_grad=True)]        [-0.448]\n",
      "[tensor(-0.63758801, requires_grad=True)]        [-0.446]\n",
      "[tensor(-0.6405162, requires_grad=True)]        [-0.444]\n",
      "[tensor(-0.64342839, requires_grad=True)]        [-0.442]\n",
      "[tensor(-0.64632459, requires_grad=True)]        [-0.44]\n",
      "[tensor(-0.64920482, requires_grad=True)]        [-0.438]\n",
      "[tensor(-0.65206908, requires_grad=True)]        [-0.436]\n",
      "[tensor(-0.65491739, requires_grad=True)]        [-0.434]\n",
      "[tensor(-0.65774974, requires_grad=True)]        [-0.432]\n",
      "[tensor(-0.66056616, requires_grad=True)]        [-0.43]\n",
      "[tensor(-0.66336665, requires_grad=True)]        [-0.428]\n",
      "[tensor(-0.66615122, requires_grad=True)]        [-0.426]\n",
      "[tensor(-0.66891987, requires_grad=True)]        [-0.424]\n",
      "[tensor(-0.67167263, requires_grad=True)]        [-0.422]\n",
      "[tensor(-0.67440949, requires_grad=True)]        [-0.42]\n",
      "[tensor(-0.67713046, requires_grad=True)]        [-0.418]\n",
      "[tensor(-0.67983556, requires_grad=True)]        [-0.416]\n",
      "[tensor(-0.68252479, requires_grad=True)]        [-0.414]\n",
      "[tensor(-0.68519816, requires_grad=True)]        [-0.412]\n",
      "[tensor(-0.68785569, requires_grad=True)]        [-0.41]\n",
      "[tensor(-0.69049737, requires_grad=True)]        [-0.408]\n",
      "[tensor(-0.69312322, requires_grad=True)]        [-0.406]\n",
      "[tensor(-0.69573324, requires_grad=True)]        [-0.404]\n",
      "[tensor(-0.69832745, requires_grad=True)]        [-0.402]\n",
      "[tensor(-0.70090585, requires_grad=True)]        [-0.4]\n",
      "[tensor(-0.70346846, requires_grad=True)]        [-0.398]\n",
      "[tensor(-0.70601527, requires_grad=True)]        [-0.396]\n",
      "[tensor(-0.7085463, requires_grad=True)]        [-0.394]\n",
      "[tensor(-0.71106156, requires_grad=True)]        [-0.392]\n",
      "[tensor(-0.71356105, requires_grad=True)]        [-0.39]\n",
      "[tensor(-0.71604478, requires_grad=True)]        [-0.388]\n",
      "[tensor(-0.71851277, requires_grad=True)]        [-0.386]\n",
      "[tensor(-0.72096502, requires_grad=True)]        [-0.384]\n",
      "[tensor(-0.72340153, requires_grad=True)]        [-0.382]\n",
      "[tensor(-0.72582232, requires_grad=True)]        [-0.38]\n",
      "[tensor(-0.72822739, requires_grad=True)]        [-0.378]\n",
      "[tensor(-0.73061675, requires_grad=True)]        [-0.376]\n",
      "[tensor(-0.73299042, requires_grad=True)]        [-0.374]\n",
      "[tensor(-0.73534839, requires_grad=True)]        [-0.372]\n",
      "[tensor(-0.73769067, requires_grad=True)]        [-0.37]\n",
      "[tensor(-0.74001728, requires_grad=True)]        [-0.368]\n",
      "[tensor(-0.74232822, requires_grad=True)]        [-0.366]\n",
      "[tensor(-0.7446235, requires_grad=True)]        [-0.364]\n",
      "[tensor(-0.74690313, requires_grad=True)]        [-0.362]\n",
      "[tensor(-0.74916711, requires_grad=True)]        [-0.36]\n",
      "[tensor(-0.75141545, requires_grad=True)]        [-0.358]\n",
      "[tensor(-0.75364816, requires_grad=True)]        [-0.356]\n",
      "[tensor(-0.75586525, requires_grad=True)]        [-0.354]\n",
      "[tensor(-0.75806673, requires_grad=True)]        [-0.352]\n",
      "[tensor(-0.7602526, requires_grad=True)]        [-0.35]\n",
      "[tensor(-0.76242287, requires_grad=True)]        [-0.348]\n",
      "[tensor(-0.76457754, requires_grad=True)]        [-0.346]\n",
      "[tensor(-0.76671664, requires_grad=True)]        [-0.344]\n",
      "[tensor(-0.76884015, requires_grad=True)]        [-0.342]\n",
      "[tensor(-0.7709481, requires_grad=True)]        [-0.34]\n",
      "[tensor(-0.77304048, requires_grad=True)]        [-0.338]\n",
      "[tensor(-0.77511731, requires_grad=True)]        [-0.336]\n",
      "[tensor(-0.77717859, requires_grad=True)]        [-0.334]\n",
      "[tensor(-0.77922433, requires_grad=True)]        [-0.332]\n",
      "[tensor(-0.78125453, requires_grad=True)]        [-0.33]\n",
      "[tensor(-0.78326922, requires_grad=True)]        [-0.328]\n",
      "[tensor(-0.78526838, requires_grad=True)]        [-0.326]\n",
      "[tensor(-0.78725203, requires_grad=True)]        [-0.324]\n",
      "[tensor(-0.78922018, requires_grad=True)]        [-0.322]\n",
      "[tensor(-0.79117283, requires_grad=True)]        [-0.32]\n",
      "[tensor(-0.79310999, requires_grad=True)]        [-0.318]\n",
      "[tensor(-0.79503167, requires_grad=True)]        [-0.316]\n",
      "[tensor(-0.79693788, requires_grad=True)]        [-0.314]\n",
      "[tensor(-0.79882861, requires_grad=True)]        [-0.312]\n",
      "[tensor(-0.80070389, requires_grad=True)]        [-0.31]\n",
      "[tensor(-0.80256371, requires_grad=True)]        [-0.308]\n",
      "[tensor(-0.80440808, requires_grad=True)]        [-0.306]\n",
      "[tensor(-0.80623701, requires_grad=True)]        [-0.304]\n",
      "[tensor(-0.80805051, requires_grad=True)]        [-0.302]\n",
      "[tensor(-0.80984858, requires_grad=True)]        [-0.3]\n",
      "[tensor(-0.81163123, requires_grad=True)]        [-0.298]\n",
      "[tensor(-0.81339847, requires_grad=True)]        [-0.296]\n",
      "[tensor(-0.81515031, requires_grad=True)]        [-0.294]\n",
      "[tensor(-0.81688674, requires_grad=True)]        [-0.292]\n",
      "[tensor(-0.81860779, requires_grad=True)]        [-0.29]\n",
      "[tensor(-0.82031345, requires_grad=True)]        [-0.288]\n",
      "[tensor(-0.82200372, requires_grad=True)]        [-0.286]\n",
      "[tensor(-0.82367863, requires_grad=True)]        [-0.284]\n",
      "[tensor(-0.82533817, requires_grad=True)]        [-0.282]\n",
      "[tensor(-0.82698236, requires_grad=True)]        [-0.28]\n",
      "[tensor(-0.82861119, requires_grad=True)]        [-0.278]\n",
      "[tensor(-0.83022468, requires_grad=True)]        [-0.276]\n",
      "[tensor(-0.83182283, requires_grad=True)]        [-0.274]\n",
      "[tensor(-0.83340564, requires_grad=True)]        [-0.272]\n",
      "[tensor(-0.83497313, requires_grad=True)]        [-0.27]\n",
      "[tensor(-0.83652531, requires_grad=True)]        [-0.268]\n",
      "[tensor(-0.83806217, requires_grad=True)]        [-0.266]\n",
      "[tensor(-0.83958372, requires_grad=True)]        [-0.264]\n",
      "[tensor(-0.84108998, requires_grad=True)]        [-0.262]\n",
      "[tensor(-0.84258094, requires_grad=True)]        [-0.26]\n",
      "[tensor(-0.84405662, requires_grad=True)]        [-0.258]\n",
      "[tensor(-0.84551702, requires_grad=True)]        [-0.256]\n",
      "[tensor(-0.84696215, requires_grad=True)]        [-0.254]\n",
      "[tensor(-0.848392, requires_grad=True)]        [-0.252]\n",
      "[tensor(-0.8498066, requires_grad=True)]        [-0.25]\n",
      "[tensor(-0.85120595, requires_grad=True)]        [-0.248]\n",
      "[tensor(-0.85259005, requires_grad=True)]        [-0.246]\n",
      "[tensor(-0.8539589, requires_grad=True)]        [-0.244]\n",
      "[tensor(-0.85531252, requires_grad=True)]        [-0.242]\n",
      "[tensor(-0.85665092, requires_grad=True)]        [-0.24]\n",
      "[tensor(-0.85797409, requires_grad=True)]        [-0.238]\n",
      "[tensor(-0.85928205, requires_grad=True)]        [-0.236]\n",
      "[tensor(-0.86057479, requires_grad=True)]        [-0.234]\n",
      "[tensor(-0.86185234, requires_grad=True)]        [-0.232]\n",
      "[tensor(-0.86311468, requires_grad=True)]        [-0.23]\n",
      "[tensor(-0.86436184, requires_grad=True)]        [-0.228]\n",
      "[tensor(-0.86559381, requires_grad=True)]        [-0.226]\n",
      "[tensor(-0.8668106, requires_grad=True)]        [-0.224]\n",
      "[tensor(-0.86801223, requires_grad=True)]        [-0.222]\n",
      "[tensor(-0.86919868, requires_grad=True)]        [-0.22]\n",
      "[tensor(-0.87036998, requires_grad=True)]        [-0.218]\n",
      "[tensor(-0.87152612, requires_grad=True)]        [-0.216]\n",
      "[tensor(-0.87266712, requires_grad=True)]        [-0.214]\n",
      "[tensor(-0.87379297, requires_grad=True)]        [-0.212]\n",
      "[tensor(-0.87490369, requires_grad=True)]        [-0.21]\n",
      "[tensor(-0.87599928, requires_grad=True)]        [-0.208]\n",
      "[tensor(-0.87707975, requires_grad=True)]        [-0.206]\n",
      "[tensor(-0.8781451, requires_grad=True)]        [-0.204]\n",
      "[tensor(-0.87919534, requires_grad=True)]        [-0.202]\n",
      "[tensor(-0.88023047, requires_grad=True)]        [-0.2]\n",
      "[tensor(-0.88125051, requires_grad=True)]        [-0.198]\n",
      "[tensor(-0.88225545, requires_grad=True)]        [-0.196]\n",
      "[tensor(-0.88324531, requires_grad=True)]        [-0.194]\n",
      "[tensor(-0.88422009, requires_grad=True)]        [-0.192]\n",
      "[tensor(-0.88517979, requires_grad=True)]        [-0.19]\n",
      "[tensor(-0.88612442, requires_grad=True)]        [-0.188]\n",
      "[tensor(-0.88705399, requires_grad=True)]        [-0.186]\n",
      "[tensor(-0.88796851, requires_grad=True)]        [-0.184]\n",
      "[tensor(-0.88886797, requires_grad=True)]        [-0.182]\n",
      "[tensor(-0.88975239, requires_grad=True)]        [-0.18]\n",
      "[tensor(-0.89062177, requires_grad=True)]        [-0.178]\n",
      "[tensor(-0.89147611, requires_grad=True)]        [-0.176]\n",
      "[tensor(-0.89231543, requires_grad=True)]        [-0.174]\n",
      "[tensor(-0.89313973, requires_grad=True)]        [-0.172]\n",
      "[tensor(-0.89394901, requires_grad=True)]        [-0.17]\n",
      "[tensor(-0.89474328, requires_grad=True)]        [-0.168]\n",
      "[tensor(-0.89552255, requires_grad=True)]        [-0.166]\n",
      "[tensor(-0.89628682, requires_grad=True)]        [-0.164]\n",
      "[tensor(-0.8970361, requires_grad=True)]        [-0.162]\n",
      "[tensor(-0.89777039, requires_grad=True)]        [-0.16]\n",
      "[tensor(-0.89848971, requires_grad=True)]        [-0.158]\n",
      "[tensor(-0.89919404, requires_grad=True)]        [-0.156]\n",
      "[tensor(-0.89988341, requires_grad=True)]        [-0.154]\n",
      "[tensor(-0.90055782, requires_grad=True)]        [-0.152]\n",
      "[tensor(-0.90121727, requires_grad=True)]        [-0.15]\n",
      "[tensor(-0.90186176, requires_grad=True)]        [-0.148]\n",
      "[tensor(-0.90249131, requires_grad=True)]        [-0.146]\n",
      "[tensor(-0.90310593, requires_grad=True)]        [-0.144]\n",
      "[tensor(-0.9037056, requires_grad=True)]        [-0.142]\n",
      "[tensor(-0.90429035, requires_grad=True)]        [-0.14]\n",
      "[tensor(-0.90486018, requires_grad=True)]        [-0.138]\n",
      "[tensor(-0.90541509, requires_grad=True)]        [-0.136]\n",
      "[tensor(-0.90595508, requires_grad=True)]        [-0.134]\n",
      "[tensor(-0.90648018, requires_grad=True)]        [-0.132]\n",
      "[tensor(-0.90699037, requires_grad=True)]        [-0.13]\n",
      "[tensor(-0.90748567, requires_grad=True)]        [-0.128]\n",
      "[tensor(-0.90796607, requires_grad=True)]        [-0.126]\n",
      "[tensor(-0.9084316, requires_grad=True)]        [-0.124]\n",
      "[tensor(-0.90888225, requires_grad=True)]        [-0.122]\n",
      "[tensor(-0.90931803, requires_grad=True)]        [-0.12]\n",
      "[tensor(-0.90973894, requires_grad=True)]        [-0.118]\n",
      "[tensor(-0.91014499, requires_grad=True)]        [-0.116]\n",
      "[tensor(-0.91053618, requires_grad=True)]        [-0.114]\n",
      "[tensor(-0.91091253, requires_grad=True)]        [-0.112]\n",
      "[tensor(-0.91127404, requires_grad=True)]        [-0.11]\n",
      "[tensor(-0.9116207, requires_grad=True)]        [-0.108]\n",
      "[tensor(-0.91195254, requires_grad=True)]        [-0.106]\n",
      "[tensor(-0.91226954, requires_grad=True)]        [-0.104]\n",
      "[tensor(-0.91257173, requires_grad=True)]        [-0.102]\n",
      "[tensor(-0.9128591, requires_grad=True)]        [-0.1]\n",
      "[tensor(-0.91313166, requires_grad=True)]        [-0.098]\n",
      "[tensor(-0.91338942, requires_grad=True)]        [-0.096]\n",
      "[tensor(-0.91363237, requires_grad=True)]        [-0.094]\n",
      "[tensor(-0.91386054, requires_grad=True)]        [-0.092]\n",
      "[tensor(-0.91407392, requires_grad=True)]        [-0.09]\n",
      "[tensor(-0.91427251, requires_grad=True)]        [-0.088]\n",
      "[tensor(-0.91445633, requires_grad=True)]        [-0.086]\n",
      "[tensor(-0.91462538, requires_grad=True)]        [-0.084]\n",
      "[tensor(-0.91477966, requires_grad=True)]        [-0.082]\n",
      "[tensor(-0.91491918, requires_grad=True)]        [-0.08]\n",
      "[tensor(-0.91504395, requires_grad=True)]        [-0.078]\n",
      "[tensor(-0.91515397, requires_grad=True)]        [-0.076]\n",
      "[tensor(-0.91524925, requires_grad=True)]        [-0.074]\n",
      "[tensor(-0.91532979, requires_grad=True)]        [-0.072]\n",
      "[tensor(-0.91539559, requires_grad=True)]        [-0.07]\n",
      "[tensor(-0.91544667, requires_grad=True)]        [-0.068]\n",
      "[tensor(-0.91548303, requires_grad=True)]        [-0.066]\n",
      "[tensor(-0.91550467, requires_grad=True)]        [-0.064]\n",
      "[tensor(-0.91551161, requires_grad=True)]        [-0.062]\n",
      "[tensor(-0.91550384, requires_grad=True)]        [-0.06]\n",
      "[tensor(-0.91548136, requires_grad=True)]        [-0.058]\n",
      "[tensor(-0.9154442, requires_grad=True)]        [-0.056]\n",
      "[tensor(-0.91539235, requires_grad=True)]        [-0.054]\n",
      "[tensor(-0.91532581, requires_grad=True)]        [-0.052]\n",
      "[tensor(-0.9152446, requires_grad=True)]        [-0.05]\n",
      "[tensor(-0.91514871, requires_grad=True)]        [-0.048]\n",
      "[tensor(-0.91503816, requires_grad=True)]        [-0.046]\n",
      "[tensor(-0.91491295, requires_grad=True)]        [-0.044]\n",
      "[tensor(-0.91477309, requires_grad=True)]        [-0.042]\n",
      "[tensor(-0.91461857, requires_grad=True)]        [-0.04]\n",
      "[tensor(-0.91444941, requires_grad=True)]        [-0.038]\n",
      "[tensor(-0.91426561, requires_grad=True)]        [-0.036]\n",
      "[tensor(-0.91406717, requires_grad=True)]        [-0.034]\n",
      "[tensor(-0.91385411, requires_grad=True)]        [-0.032]\n",
      "[tensor(-0.91362643, requires_grad=True)]        [-0.03]\n",
      "[tensor(-0.91338413, requires_grad=True)]        [-0.028]\n",
      "[tensor(-0.91312722, requires_grad=True)]        [-0.026]\n",
      "[tensor(-0.9128557, requires_grad=True)]        [-0.024]\n",
      "[tensor(-0.91256958, requires_grad=True)]        [-0.022]\n",
      "[tensor(-0.91226886, requires_grad=True)]        [-0.02]\n",
      "[tensor(-0.91195356, requires_grad=True)]        [-0.018]\n",
      "[tensor(-0.91162367, requires_grad=True)]        [-0.016]\n",
      "[tensor(-0.9112792, requires_grad=True)]        [-0.014]\n",
      "[tensor(-0.91092016, requires_grad=True)]        [-0.012]\n",
      "[tensor(-0.91054655, requires_grad=True)]        [-0.01]\n",
      "[tensor(-0.91015838, requires_grad=True)]        [-0.008]\n",
      "[tensor(-0.90975565, requires_grad=True)]        [-0.006]\n",
      "[tensor(-0.90933837, requires_grad=True)]        [-0.004]\n",
      "[tensor(-0.90890654, requires_grad=True)]        [-0.002]\n",
      "[tensor(-0.90846017, requires_grad=True)]        [0.]\n",
      "[tensor(-0.90799927, requires_grad=True)]        [0.002]\n",
      "[tensor(-0.90752384, requires_grad=True)]        [0.004]\n",
      "[tensor(-0.90703388, requires_grad=True)]        [0.006]\n",
      "[tensor(-0.9065294, requires_grad=True)]        [0.008]\n",
      "[tensor(-0.90601041, requires_grad=True)]        [0.01]\n",
      "[tensor(-0.90547691, requires_grad=True)]        [0.012]\n",
      "[tensor(-0.90492891, requires_grad=True)]        [0.014]\n",
      "[tensor(-0.90436642, requires_grad=True)]        [0.016]\n",
      "[tensor(-0.90378943, requires_grad=True)]        [0.018]\n",
      "[tensor(-0.90319795, requires_grad=True)]        [0.02]\n",
      "[tensor(-0.90259199, requires_grad=True)]        [0.022]\n",
      "[tensor(-0.90197156, requires_grad=True)]        [0.024]\n",
      "[tensor(-0.90133666, requires_grad=True)]        [0.026]\n",
      "[tensor(-0.90068729, requires_grad=True)]        [0.028]\n",
      "[tensor(-0.90002346, requires_grad=True)]        [0.03]\n",
      "[tensor(-0.89934518, requires_grad=True)]        [0.032]\n",
      "[tensor(-0.89865245, requires_grad=True)]        [0.034]\n",
      "[tensor(-0.89794528, requires_grad=True)]        [0.036]\n",
      "[tensor(-0.89722367, requires_grad=True)]        [0.038]\n",
      "[tensor(-0.89648763, requires_grad=True)]        [0.04]\n",
      "[tensor(-0.89573717, requires_grad=True)]        [0.042]\n",
      "[tensor(-0.89497228, requires_grad=True)]        [0.044]\n",
      "[tensor(-0.89419298, requires_grad=True)]        [0.046]\n",
      "[tensor(-0.89339926, requires_grad=True)]        [0.048]\n",
      "[tensor(-0.89259115, requires_grad=True)]        [0.05]\n",
      "[tensor(-0.89176863, requires_grad=True)]        [0.052]\n",
      "[tensor(-0.89093172, requires_grad=True)]        [0.054]\n",
      "[tensor(-0.89008042, requires_grad=True)]        [0.056]\n",
      "[tensor(-0.88921474, requires_grad=True)]        [0.058]\n",
      "[tensor(-0.88833469, requires_grad=True)]        [0.06]\n",
      "[tensor(-0.88744026, requires_grad=True)]        [0.062]\n",
      "[tensor(-0.88653146, requires_grad=True)]        [0.064]\n",
      "[tensor(-0.88560831, requires_grad=True)]        [0.066]\n",
      "[tensor(-0.8846708, requires_grad=True)]        [0.068]\n",
      "[tensor(-0.88371894, requires_grad=True)]        [0.07]\n",
      "[tensor(-0.88275273, requires_grad=True)]        [0.072]\n",
      "[tensor(-0.88177219, requires_grad=True)]        [0.074]\n",
      "[tensor(-0.88077731, requires_grad=True)]        [0.076]\n",
      "[tensor(-0.87976811, requires_grad=True)]        [0.078]\n",
      "[tensor(-0.87874458, requires_grad=True)]        [0.08]\n",
      "[tensor(-0.87770674, requires_grad=True)]        [0.082]\n",
      "[tensor(-0.87665459, requires_grad=True)]        [0.084]\n",
      "[tensor(-0.87558813, requires_grad=True)]        [0.086]\n",
      "[tensor(-0.87450737, requires_grad=True)]        [0.088]\n",
      "[tensor(-0.87341232, requires_grad=True)]        [0.09]\n",
      "[tensor(-0.87230298, requires_grad=True)]        [0.092]\n",
      "[tensor(-0.87117936, requires_grad=True)]        [0.094]\n",
      "[tensor(-0.87004146, requires_grad=True)]        [0.096]\n",
      "[tensor(-0.86888928, requires_grad=True)]        [0.098]\n",
      "[tensor(-0.86772284, requires_grad=True)]        [0.1]\n",
      "[tensor(-0.86654214, requires_grad=True)]        [0.102]\n",
      "[tensor(-0.86534718, requires_grad=True)]        [0.104]\n",
      "[tensor(-0.86413798, requires_grad=True)]        [0.106]\n",
      "[tensor(-0.86291453, requires_grad=True)]        [0.108]\n",
      "[tensor(-0.86167684, requires_grad=True)]        [0.11]\n",
      "[tensor(-0.86042492, requires_grad=True)]        [0.112]\n",
      "[tensor(-0.85915877, requires_grad=True)]        [0.114]\n",
      "[tensor(-0.8578784, requires_grad=True)]        [0.116]\n",
      "[tensor(-0.85658381, requires_grad=True)]        [0.118]\n",
      "[tensor(-0.85527502, requires_grad=True)]        [0.12]\n",
      "[tensor(-0.85395201, requires_grad=True)]        [0.122]\n",
      "[tensor(-0.85261481, requires_grad=True)]        [0.124]\n",
      "[tensor(-0.85126342, requires_grad=True)]        [0.126]\n",
      "[tensor(-0.84989784, requires_grad=True)]        [0.128]\n",
      "[tensor(-0.84851807, requires_grad=True)]        [0.13]\n",
      "[tensor(-0.84712413, requires_grad=True)]        [0.132]\n",
      "[tensor(-0.84571602, requires_grad=True)]        [0.134]\n",
      "[tensor(-0.84429374, requires_grad=True)]        [0.136]\n",
      "[tensor(-0.84285731, requires_grad=True)]        [0.138]\n",
      "[tensor(-0.84140672, requires_grad=True)]        [0.14]\n",
      "[tensor(-0.83994198, requires_grad=True)]        [0.142]\n",
      "[tensor(-0.8384631, requires_grad=True)]        [0.144]\n",
      "[tensor(-0.83697008, requires_grad=True)]        [0.146]\n",
      "[tensor(-0.83546294, requires_grad=True)]        [0.148]\n",
      "[tensor(-0.83394167, requires_grad=True)]        [0.15]\n",
      "[tensor(-0.83240627, requires_grad=True)]        [0.152]\n",
      "[tensor(-0.83085677, requires_grad=True)]        [0.154]\n",
      "[tensor(-0.82929316, requires_grad=True)]        [0.156]\n",
      "[tensor(-0.82771544, requires_grad=True)]        [0.158]\n",
      "[tensor(-0.82612363, requires_grad=True)]        [0.16]\n",
      "[tensor(-0.82451773, requires_grad=True)]        [0.162]\n",
      "[tensor(-0.82289775, requires_grad=True)]        [0.164]\n",
      "[tensor(-0.82126368, requires_grad=True)]        [0.166]\n",
      "[tensor(-0.81961555, requires_grad=True)]        [0.168]\n",
      "[tensor(-0.81795334, requires_grad=True)]        [0.17]\n",
      "[tensor(-0.81627708, requires_grad=True)]        [0.172]\n",
      "[tensor(-0.81458676, requires_grad=True)]        [0.174]\n",
      "[tensor(-0.81288239, requires_grad=True)]        [0.176]\n",
      "[tensor(-0.81116397, requires_grad=True)]        [0.178]\n",
      "[tensor(-0.80943152, requires_grad=True)]        [0.18]\n",
      "[tensor(-0.80768504, requires_grad=True)]        [0.182]\n",
      "[tensor(-0.80592453, requires_grad=True)]        [0.184]\n",
      "[tensor(-0.80415, requires_grad=True)]        [0.186]\n",
      "[tensor(-0.80236146, requires_grad=True)]        [0.188]\n",
      "[tensor(-0.80055891, requires_grad=True)]        [0.19]\n",
      "[tensor(-0.79874236, requires_grad=True)]        [0.192]\n",
      "[tensor(-0.79691181, requires_grad=True)]        [0.194]\n",
      "[tensor(-0.79506727, requires_grad=True)]        [0.196]\n",
      "[tensor(-0.79320875, requires_grad=True)]        [0.198]\n",
      "[tensor(-0.79133625, requires_grad=True)]        [0.2]\n",
      "[tensor(-0.78944977, requires_grad=True)]        [0.202]\n",
      "[tensor(-0.78754933, requires_grad=True)]        [0.204]\n",
      "[tensor(-0.78563494, requires_grad=True)]        [0.206]\n",
      "[tensor(-0.78370658, requires_grad=True)]        [0.208]\n",
      "[tensor(-0.78176428, requires_grad=True)]        [0.21]\n",
      "[tensor(-0.77980804, requires_grad=True)]        [0.212]\n",
      "[tensor(-0.77783786, requires_grad=True)]        [0.214]\n",
      "[tensor(-0.77585376, requires_grad=True)]        [0.216]\n",
      "[tensor(-0.77385572, requires_grad=True)]        [0.218]\n",
      "[tensor(-0.77184378, requires_grad=True)]        [0.22]\n",
      "[tensor(-0.76981792, requires_grad=True)]        [0.222]\n",
      "[tensor(-0.76777815, requires_grad=True)]        [0.224]\n",
      "[tensor(-0.76572449, requires_grad=True)]        [0.226]\n",
      "[tensor(-0.76365693, requires_grad=True)]        [0.228]\n",
      "[tensor(-0.76157549, requires_grad=True)]        [0.23]\n",
      "[tensor(-0.75948017, requires_grad=True)]        [0.232]\n",
      "[tensor(-0.75737097, requires_grad=True)]        [0.234]\n",
      "[tensor(-0.75524791, requires_grad=True)]        [0.236]\n",
      "[tensor(-0.75311099, requires_grad=True)]        [0.238]\n",
      "[tensor(-0.75096021, requires_grad=True)]        [0.24]\n",
      "[tensor(-0.74879558, requires_grad=True)]        [0.242]\n",
      "[tensor(-0.74661711, requires_grad=True)]        [0.244]\n",
      "[tensor(-0.7444248, requires_grad=True)]        [0.246]\n",
      "[tensor(-0.74221866, requires_grad=True)]        [0.248]\n",
      "[tensor(-0.7399987, requires_grad=True)]        [0.25]\n",
      "[tensor(-0.73776492, requires_grad=True)]        [0.252]\n",
      "[tensor(-0.73551734, requires_grad=True)]        [0.254]\n",
      "[tensor(-0.73325594, requires_grad=True)]        [0.256]\n",
      "[tensor(-0.73098075, requires_grad=True)]        [0.258]\n",
      "[tensor(-0.72869177, requires_grad=True)]        [0.26]\n",
      "[tensor(-0.72638901, requires_grad=True)]        [0.262]\n",
      "[tensor(-0.72407246, requires_grad=True)]        [0.264]\n",
      "[tensor(-0.72174215, requires_grad=True)]        [0.266]\n",
      "[tensor(-0.71939807, requires_grad=True)]        [0.268]\n",
      "[tensor(-0.71704023, requires_grad=True)]        [0.27]\n",
      "[tensor(-0.71466864, requires_grad=True)]        [0.272]\n",
      "[tensor(-0.7122833, requires_grad=True)]        [0.274]\n",
      "[tensor(-0.70988422, requires_grad=True)]        [0.276]\n",
      "[tensor(-0.70747141, requires_grad=True)]        [0.278]\n",
      "[tensor(-0.70504488, requires_grad=True)]        [0.28]\n",
      "[tensor(-0.70260463, requires_grad=True)]        [0.282]\n",
      "[tensor(-0.70015066, requires_grad=True)]        [0.284]\n",
      "[tensor(-0.69768299, requires_grad=True)]        [0.286]\n",
      "[tensor(-0.69520162, requires_grad=True)]        [0.288]\n",
      "[tensor(-0.69270656, requires_grad=True)]        [0.29]\n",
      "[tensor(-0.69019781, requires_grad=True)]        [0.292]\n",
      "[tensor(-0.68767538, requires_grad=True)]        [0.294]\n",
      "[tensor(-0.68513929, requires_grad=True)]        [0.296]\n",
      "[tensor(-0.68258952, requires_grad=True)]        [0.298]\n",
      "[tensor(-0.6800261, requires_grad=True)]        [0.3]\n",
      "[tensor(-0.67744903, requires_grad=True)]        [0.302]\n",
      "[tensor(-0.67485832, requires_grad=True)]        [0.304]\n",
      "[tensor(-0.67225396, requires_grad=True)]        [0.306]\n",
      "[tensor(-0.66963598, requires_grad=True)]        [0.308]\n",
      "[tensor(-0.66700437, requires_grad=True)]        [0.31]\n",
      "[tensor(-0.66435915, requires_grad=True)]        [0.312]\n",
      "[tensor(-0.66170031, requires_grad=True)]        [0.314]\n",
      "[tensor(-0.65902788, requires_grad=True)]        [0.316]\n",
      "[tensor(-0.65634185, requires_grad=True)]        [0.318]\n",
      "[tensor(-0.65364223, requires_grad=True)]        [0.32]\n",
      "[tensor(-0.65092903, requires_grad=True)]        [0.322]\n",
      "[tensor(-0.64820226, requires_grad=True)]        [0.324]\n",
      "[tensor(-0.64546191, requires_grad=True)]        [0.326]\n",
      "[tensor(-0.64270801, requires_grad=True)]        [0.328]\n",
      "[tensor(-0.63994056, requires_grad=True)]        [0.33]\n",
      "[tensor(-0.63715956, requires_grad=True)]        [0.332]\n",
      "[tensor(-0.63436503, requires_grad=True)]        [0.334]\n",
      "[tensor(-0.63155696, requires_grad=True)]        [0.336]\n",
      "[tensor(-0.62873537, requires_grad=True)]        [0.338]\n",
      "[tensor(-0.62590027, requires_grad=True)]        [0.34]\n",
      "[tensor(-0.62305165, requires_grad=True)]        [0.342]\n",
      "[tensor(-0.62018954, requires_grad=True)]        [0.344]\n",
      "[tensor(-0.61731393, requires_grad=True)]        [0.346]\n",
      "[tensor(-0.61442484, requires_grad=True)]        [0.348]\n",
      "[tensor(-0.61152226, requires_grad=True)]        [0.35]\n",
      "[tensor(-0.60860622, requires_grad=True)]        [0.352]\n",
      "[tensor(-0.60567671, requires_grad=True)]        [0.354]\n",
      "[tensor(-0.60273375, requires_grad=True)]        [0.356]\n",
      "[tensor(-0.59977734, requires_grad=True)]        [0.358]\n",
      "[tensor(-0.59680749, requires_grad=True)]        [0.36]\n",
      "[tensor(-0.5938242, requires_grad=True)]        [0.362]\n",
      "[tensor(-0.59082749, requires_grad=True)]        [0.364]\n",
      "[tensor(-0.58781736, requires_grad=True)]        [0.366]\n",
      "[tensor(-0.58479382, requires_grad=True)]        [0.368]\n",
      "[tensor(-0.58175688, requires_grad=True)]        [0.37]\n",
      "[tensor(-0.57870655, requires_grad=True)]        [0.372]\n",
      "[tensor(-0.57564283, requires_grad=True)]        [0.374]\n",
      "[tensor(-0.57256573, requires_grad=True)]        [0.376]\n",
      "[tensor(-0.56947526, requires_grad=True)]        [0.378]\n",
      "[tensor(-0.56637143, requires_grad=True)]        [0.38]\n",
      "[tensor(-0.56325425, requires_grad=True)]        [0.382]\n",
      "[tensor(-0.56012372, requires_grad=True)]        [0.384]\n",
      "[tensor(-0.55697985, requires_grad=True)]        [0.386]\n",
      "[tensor(-0.55382265, requires_grad=True)]        [0.388]\n",
      "[tensor(-0.55065213, requires_grad=True)]        [0.39]\n",
      "[tensor(-0.54746829, requires_grad=True)]        [0.392]\n",
      "[tensor(-0.54427115, requires_grad=True)]        [0.394]\n",
      "[tensor(-0.54106072, requires_grad=True)]        [0.396]\n",
      "[tensor(-0.53783699, requires_grad=True)]        [0.398]\n",
      "[tensor(-0.53459998, requires_grad=True)]        [0.4]\n",
      "[tensor(-0.5313497, requires_grad=True)]        [0.402]\n",
      "[tensor(-0.52808616, requires_grad=True)]        [0.404]\n",
      "[tensor(-0.52480937, requires_grad=True)]        [0.406]\n",
      "[tensor(-0.52151932, requires_grad=True)]        [0.408]\n",
      "[tensor(-0.51821604, requires_grad=True)]        [0.41]\n",
      "[tensor(-0.51489953, requires_grad=True)]        [0.412]\n",
      "[tensor(-0.5115698, requires_grad=True)]        [0.414]\n",
      "[tensor(-0.50822685, requires_grad=True)]        [0.416]\n",
      "[tensor(-0.5048707, requires_grad=True)]        [0.418]\n",
      "[tensor(-0.50150136, requires_grad=True)]        [0.42]\n",
      "[tensor(-0.49811883, requires_grad=True)]        [0.422]\n",
      "[tensor(-0.49472313, requires_grad=True)]        [0.424]\n",
      "[tensor(-0.49131426, requires_grad=True)]        [0.426]\n",
      "[tensor(-0.48789222, requires_grad=True)]        [0.428]\n",
      "[tensor(-0.48445704, requires_grad=True)]        [0.43]\n",
      "[tensor(-0.48100872, requires_grad=True)]        [0.432]\n",
      "[tensor(-0.47754726, requires_grad=True)]        [0.434]\n",
      "[tensor(-0.47407269, requires_grad=True)]        [0.436]\n",
      "[tensor(-0.47058499, requires_grad=True)]        [0.438]\n",
      "[tensor(-0.4670842, requires_grad=True)]        [0.44]\n",
      "[tensor(-0.46357031, requires_grad=True)]        [0.442]\n",
      "[tensor(-0.46004333, requires_grad=True)]        [0.444]\n",
      "[tensor(-0.45650328, requires_grad=True)]        [0.446]\n",
      "[tensor(-0.45295016, requires_grad=True)]        [0.448]\n",
      "[tensor(-0.44938398, requires_grad=True)]        [0.45]\n",
      "[tensor(-0.44580476, requires_grad=True)]        [0.452]\n",
      "[tensor(-0.4422125, requires_grad=True)]        [0.454]\n",
      "[tensor(-0.43860721, requires_grad=True)]        [0.456]\n",
      "[tensor(-0.4349889, requires_grad=True)]        [0.458]\n",
      "[tensor(-0.43135758, requires_grad=True)]        [0.46]\n",
      "[tensor(-0.42771326, requires_grad=True)]        [0.462]\n",
      "[tensor(-0.42405596, requires_grad=True)]        [0.464]\n",
      "[tensor(-0.42038567, requires_grad=True)]        [0.466]\n",
      "[tensor(-0.41670241, requires_grad=True)]        [0.468]\n",
      "[tensor(-0.4130062, requires_grad=True)]        [0.47]\n",
      "[tensor(-0.40929704, requires_grad=True)]        [0.472]\n",
      "[tensor(-0.40557493, requires_grad=True)]        [0.474]\n",
      "[tensor(-0.4018399, requires_grad=True)]        [0.476]\n",
      "[tensor(-0.39809195, requires_grad=True)]        [0.478]\n",
      "[tensor(-0.39433109, requires_grad=True)]        [0.48]\n",
      "[tensor(-0.39055734, requires_grad=True)]        [0.482]\n",
      "[tensor(-0.3867707, requires_grad=True)]        [0.484]\n",
      "[tensor(-0.38297118, requires_grad=True)]        [0.486]\n",
      "[tensor(-0.3791588, requires_grad=True)]        [0.488]\n",
      "[tensor(-0.37533356, requires_grad=True)]        [0.49]\n",
      "[tensor(-0.37149547, requires_grad=True)]        [0.492]\n",
      "[tensor(-0.36764456, requires_grad=True)]        [0.494]\n",
      "[tensor(-0.36378082, requires_grad=True)]        [0.496]\n",
      "[tensor(-0.35990427, requires_grad=True)]        [0.498]\n",
      "[tensor(-0.35601491, requires_grad=True)]        [0.5]\n",
      "[tensor(-0.35211277, requires_grad=True)]        [0.502]\n",
      "[tensor(-0.34819785, requires_grad=True)]        [0.504]\n",
      "[tensor(-0.34427017, requires_grad=True)]        [0.506]\n",
      "[tensor(-0.34032973, requires_grad=True)]        [0.508]\n",
      "[tensor(-0.33637654, requires_grad=True)]        [0.51]\n",
      "[tensor(-0.33241063, requires_grad=True)]        [0.512]\n",
      "[tensor(-0.32843199, requires_grad=True)]        [0.514]\n",
      "[tensor(-0.32444064, requires_grad=True)]        [0.516]\n",
      "[tensor(-0.3204366, requires_grad=True)]        [0.518]\n",
      "[tensor(-0.31641986, requires_grad=True)]        [0.52]\n",
      "[tensor(-0.31239046, requires_grad=True)]        [0.522]\n",
      "[tensor(-0.30834839, requires_grad=True)]        [0.524]\n",
      "[tensor(-0.30429368, requires_grad=True)]        [0.526]\n",
      "[tensor(-0.30022633, requires_grad=True)]        [0.528]\n",
      "[tensor(-0.29614635, requires_grad=True)]        [0.53]\n",
      "[tensor(-0.29205376, requires_grad=True)]        [0.532]\n",
      "[tensor(-0.28794857, requires_grad=True)]        [0.534]\n",
      "[tensor(-0.28383079, requires_grad=True)]        [0.536]\n",
      "[tensor(-0.27970043, requires_grad=True)]        [0.538]\n",
      "[tensor(-0.27555752, requires_grad=True)]        [0.54]\n",
      "[tensor(-0.27140205, requires_grad=True)]        [0.542]\n",
      "[tensor(-0.26723405, requires_grad=True)]        [0.544]\n",
      "[tensor(-0.26305353, requires_grad=True)]        [0.546]\n",
      "[tensor(-0.25886049, requires_grad=True)]        [0.548]\n",
      "[tensor(-0.25465496, requires_grad=True)]        [0.55]\n",
      "[tensor(-0.25043694, requires_grad=True)]        [0.552]\n",
      "[tensor(-0.24620645, requires_grad=True)]        [0.554]\n",
      "[tensor(-0.24196351, requires_grad=True)]        [0.556]\n",
      "[tensor(-0.23770812, requires_grad=True)]        [0.558]\n",
      "[tensor(-0.23344031, requires_grad=True)]        [0.56]\n",
      "[tensor(-0.22916008, requires_grad=True)]        [0.562]\n",
      "[tensor(-0.22486744, requires_grad=True)]        [0.564]\n",
      "[tensor(-0.22056242, requires_grad=True)]        [0.566]\n",
      "[tensor(-0.21624503, requires_grad=True)]        [0.568]\n",
      "[tensor(-0.21191528, requires_grad=True)]        [0.57]\n",
      "[tensor(-0.20757318, requires_grad=True)]        [0.572]\n",
      "[tensor(-0.20321876, requires_grad=True)]        [0.574]\n",
      "[tensor(-0.19885201, requires_grad=True)]        [0.576]\n",
      "[tensor(-0.19447297, requires_grad=True)]        [0.578]\n",
      "[tensor(-0.19008165, requires_grad=True)]        [0.58]\n",
      "[tensor(-0.18567805, requires_grad=True)]        [0.582]\n",
      "[tensor(-0.1812622, requires_grad=True)]        [0.584]\n",
      "[tensor(-0.17683411, requires_grad=True)]        [0.586]\n",
      "[tensor(-0.1723938, requires_grad=True)]        [0.588]\n",
      "[tensor(-0.16794128, requires_grad=True)]        [0.59]\n",
      "[tensor(-0.16347656, requires_grad=True)]        [0.592]\n",
      "[tensor(-0.15899967, requires_grad=True)]        [0.594]\n",
      "[tensor(-0.15451062, requires_grad=True)]        [0.596]\n",
      "[tensor(-0.15000942, requires_grad=True)]        [0.598]\n",
      "[tensor(-0.1454961, requires_grad=True)]        [0.6]\n",
      "[tensor(-0.14097067, requires_grad=True)]        [0.602]\n",
      "[tensor(-0.13643314, requires_grad=True)]        [0.604]\n",
      "[tensor(-0.13188353, requires_grad=True)]        [0.606]\n",
      "[tensor(-0.12732186, requires_grad=True)]        [0.608]\n",
      "[tensor(-0.12274815, requires_grad=True)]        [0.61]\n",
      "[tensor(-0.11816242, requires_grad=True)]        [0.612]\n",
      "[tensor(-0.11356467, requires_grad=True)]        [0.614]\n",
      "[tensor(-0.10895493, requires_grad=True)]        [0.616]\n",
      "[tensor(-0.10433322, requires_grad=True)]        [0.618]\n",
      "[tensor(-0.09969956, requires_grad=True)]        [0.62]\n",
      "[tensor(-0.09505396, requires_grad=True)]        [0.622]\n",
      "[tensor(-0.09039644, requires_grad=True)]        [0.624]\n",
      "[tensor(-0.08572702, requires_grad=True)]        [0.626]\n",
      "[tensor(-0.08104572, requires_grad=True)]        [0.628]\n",
      "[tensor(-0.07635255, requires_grad=True)]        [0.63]\n",
      "[tensor(-0.07164755, requires_grad=True)]        [0.632]\n",
      "[tensor(-0.06693072, requires_grad=True)]        [0.634]\n",
      "[tensor(-0.06220208, requires_grad=True)]        [0.636]\n",
      "[tensor(-0.05746166, requires_grad=True)]        [0.638]\n",
      "[tensor(-0.05270948, requires_grad=True)]        [0.64]\n",
      "[tensor(-0.04794556, requires_grad=True)]        [0.642]\n",
      "[tensor(-0.04316991, requires_grad=True)]        [0.644]\n",
      "[tensor(-0.03838255, requires_grad=True)]        [0.646]\n",
      "[tensor(-0.03358352, requires_grad=True)]        [0.648]\n",
      "[tensor(-0.02877282, requires_grad=True)]        [0.65]\n",
      "[tensor(-0.02395049, requires_grad=True)]        [0.652]\n",
      "[tensor(-0.01911654, requires_grad=True)]        [0.654]\n",
      "[tensor(-0.01427099, requires_grad=True)]        [0.656]\n",
      "[tensor(-0.00941386, requires_grad=True)]        [0.658]\n",
      "[tensor(-0.00454519, requires_grad=True)]        [0.66]\n",
      "[tensor(0.00033502, requires_grad=True)]        [0.662]\n",
      "[tensor(0.00522673, requires_grad=True)]        [0.664]\n",
      "[tensor(0.01012992, requires_grad=True)]        [0.666]\n",
      "[tensor(0.01504457, requires_grad=True)]        [0.668]\n",
      "[tensor(0.01997066, requires_grad=True)]        [0.67]\n",
      "[tensor(0.02490816, requires_grad=True)]        [0.672]\n",
      "[tensor(0.02985705, requires_grad=True)]        [0.674]\n",
      "[tensor(0.0348173, requires_grad=True)]        [0.676]\n",
      "[tensor(0.03978889, requires_grad=True)]        [0.678]\n",
      "[tensor(0.04477179, requires_grad=True)]        [0.68]\n",
      "[tensor(0.04976598, requires_grad=True)]        [0.682]\n",
      "[tensor(0.05477143, requires_grad=True)]        [0.684]\n",
      "[tensor(0.05978811, requires_grad=True)]        [0.686]\n",
      "[tensor(0.06481601, requires_grad=True)]        [0.688]\n",
      "[tensor(0.06985508, requires_grad=True)]        [0.69]\n",
      "[tensor(0.07490531, requires_grad=True)]        [0.692]\n",
      "[tensor(0.07996667, requires_grad=True)]        [0.694]\n",
      "[tensor(0.08503913, requires_grad=True)]        [0.696]\n",
      "[tensor(0.09012266, requires_grad=True)]        [0.698]\n",
      "[tensor(0.09521723, requires_grad=True)]        [0.7]\n",
      "[tensor(0.10032281, requires_grad=True)]        [0.702]\n",
      "[tensor(0.10543937, requires_grad=True)]        [0.704]\n",
      "[tensor(0.11056689, requires_grad=True)]        [0.706]\n",
      "[tensor(0.11570534, requires_grad=True)]        [0.708]\n",
      "[tensor(0.12085467, requires_grad=True)]        [0.71]\n",
      "[tensor(0.12601487, requires_grad=True)]        [0.712]\n",
      "[tensor(0.1311859, requires_grad=True)]        [0.714]\n",
      "[tensor(0.13636772, requires_grad=True)]        [0.716]\n",
      "[tensor(0.14156031, requires_grad=True)]        [0.718]\n",
      "[tensor(0.14676363, requires_grad=True)]        [0.72]\n",
      "[tensor(0.15197765, requires_grad=True)]        [0.722]\n",
      "[tensor(0.15720233, requires_grad=True)]        [0.724]\n",
      "[tensor(0.16243764, requires_grad=True)]        [0.726]\n",
      "[tensor(0.16768355, requires_grad=True)]        [0.728]\n",
      "[tensor(0.17294002, requires_grad=True)]        [0.73]\n",
      "[tensor(0.178207, requires_grad=True)]        [0.732]\n",
      "[tensor(0.18348448, requires_grad=True)]        [0.734]\n",
      "[tensor(0.1887724, requires_grad=True)]        [0.736]\n",
      "[tensor(0.19407073, requires_grad=True)]        [0.738]\n",
      "[tensor(0.19937944, requires_grad=True)]        [0.74]\n",
      "[tensor(0.20469847, requires_grad=True)]        [0.742]\n",
      "[tensor(0.2100278, requires_grad=True)]        [0.744]\n",
      "[tensor(0.21536738, requires_grad=True)]        [0.746]\n",
      "[tensor(0.22071718, requires_grad=True)]        [0.748]\n",
      "[tensor(0.22607714, requires_grad=True)]        [0.75]\n",
      "[tensor(0.23144723, requires_grad=True)]        [0.752]\n",
      "[tensor(0.2368274, requires_grad=True)]        [0.754]\n",
      "[tensor(0.24221761, requires_grad=True)]        [0.756]\n",
      "[tensor(0.24761781, requires_grad=True)]        [0.758]\n",
      "[tensor(0.25302796, requires_grad=True)]        [0.76]\n",
      "[tensor(0.25844802, requires_grad=True)]        [0.762]\n",
      "[tensor(0.26387792, requires_grad=True)]        [0.764]\n",
      "[tensor(0.26931764, requires_grad=True)]        [0.766]\n",
      "[tensor(0.27476711, requires_grad=True)]        [0.768]\n",
      "[tensor(0.28022629, requires_grad=True)]        [0.77]\n",
      "[tensor(0.28569512, requires_grad=True)]        [0.772]\n",
      "[tensor(0.29117356, requires_grad=True)]        [0.774]\n",
      "[tensor(0.29666155, requires_grad=True)]        [0.776]\n",
      "[tensor(0.30215903, requires_grad=True)]        [0.778]\n",
      "[tensor(0.30766596, requires_grad=True)]        [0.78]\n",
      "[tensor(0.31318227, requires_grad=True)]        [0.782]\n",
      "[tensor(0.31870792, requires_grad=True)]        [0.784]\n",
      "[tensor(0.32424283, requires_grad=True)]        [0.786]\n",
      "[tensor(0.32978695, requires_grad=True)]        [0.788]\n",
      "[tensor(0.33534022, requires_grad=True)]        [0.79]\n",
      "[tensor(0.34090258, requires_grad=True)]        [0.792]\n",
      "[tensor(0.34647396, requires_grad=True)]        [0.794]\n",
      "[tensor(0.3520543, requires_grad=True)]        [0.796]\n",
      "[tensor(0.35764354, requires_grad=True)]        [0.798]\n",
      "[tensor(0.3632416, requires_grad=True)]        [0.8]\n",
      "[tensor(0.36884841, requires_grad=True)]        [0.802]\n",
      "[tensor(0.37446391, requires_grad=True)]        [0.804]\n",
      "[tensor(0.38008802, requires_grad=True)]        [0.806]\n",
      "[tensor(0.38572067, requires_grad=True)]        [0.808]\n",
      "[tensor(0.39136178, requires_grad=True)]        [0.81]\n",
      "[tensor(0.39701128, requires_grad=True)]        [0.812]\n",
      "[tensor(0.40266908, requires_grad=True)]        [0.814]\n",
      "[tensor(0.40833511, requires_grad=True)]        [0.816]\n",
      "[tensor(0.41400928, requires_grad=True)]        [0.818]\n",
      "[tensor(0.4196915, requires_grad=True)]        [0.82]\n",
      "[tensor(0.42538169, requires_grad=True)]        [0.822]\n",
      "[tensor(0.43107976, requires_grad=True)]        [0.824]\n",
      "[tensor(0.43678561, requires_grad=True)]        [0.826]\n",
      "[tensor(0.44249916, requires_grad=True)]        [0.828]\n",
      "[tensor(0.4482203, requires_grad=True)]        [0.83]\n",
      "[tensor(0.45394894, requires_grad=True)]        [0.832]\n",
      "[tensor(0.45968497, requires_grad=True)]        [0.834]\n",
      "[tensor(0.46542829, requires_grad=True)]        [0.836]\n",
      "[tensor(0.47117878, requires_grad=True)]        [0.838]\n",
      "[tensor(0.47693635, requires_grad=True)]        [0.84]\n",
      "[tensor(0.48270087, requires_grad=True)]        [0.842]\n",
      "[tensor(0.48847223, requires_grad=True)]        [0.844]\n",
      "[tensor(0.49425031, requires_grad=True)]        [0.846]\n",
      "[tensor(0.50003497, requires_grad=True)]        [0.848]\n",
      "[tensor(0.5058261, requires_grad=True)]        [0.85]\n",
      "[tensor(0.51162357, requires_grad=True)]        [0.852]\n",
      "[tensor(0.51742723, requires_grad=True)]        [0.854]\n",
      "[tensor(0.52323694, requires_grad=True)]        [0.856]\n",
      "[tensor(0.52905256, requires_grad=True)]        [0.858]\n",
      "[tensor(0.53487394, requires_grad=True)]        [0.86]\n",
      "[tensor(0.54070093, requires_grad=True)]        [0.862]\n",
      "[tensor(0.54653336, requires_grad=True)]        [0.864]\n",
      "[tensor(0.55237108, requires_grad=True)]        [0.866]\n",
      "[tensor(0.5582139, requires_grad=True)]        [0.868]\n",
      "[tensor(0.56406165, requires_grad=True)]        [0.87]\n",
      "[tensor(0.56991415, requires_grad=True)]        [0.872]\n",
      "[tensor(0.57577121, requires_grad=True)]        [0.874]\n",
      "[tensor(0.58163262, requires_grad=True)]        [0.876]\n",
      "[tensor(0.58749819, requires_grad=True)]        [0.878]\n",
      "[tensor(0.59336771, requires_grad=True)]        [0.88]\n",
      "[tensor(0.59924095, requires_grad=True)]        [0.882]\n",
      "[tensor(0.60511767, requires_grad=True)]        [0.884]\n",
      "[tensor(0.61099766, requires_grad=True)]        [0.886]\n",
      "[tensor(0.61688064, requires_grad=True)]        [0.888]\n",
      "[tensor(0.62276637, requires_grad=True)]        [0.89]\n",
      "[tensor(0.62865458, requires_grad=True)]        [0.892]\n",
      "[tensor(0.63454498, requires_grad=True)]        [0.894]\n",
      "[tensor(0.64043727, requires_grad=True)]        [0.896]\n",
      "[tensor(0.64633115, requires_grad=True)]        [0.898]\n",
      "[tensor(0.6522263, requires_grad=True)]        [0.9]\n",
      "[tensor(0.65812238, requires_grad=True)]        [0.902]\n",
      "[tensor(0.66401903, requires_grad=True)]        [0.904]\n",
      "[tensor(0.66991588, requires_grad=True)]        [0.906]\n",
      "[tensor(0.67581255, requires_grad=True)]        [0.908]\n",
      "[tensor(0.68170861, requires_grad=True)]        [0.91]\n",
      "[tensor(0.68760364, requires_grad=True)]        [0.912]\n",
      "[tensor(0.69349718, requires_grad=True)]        [0.914]\n",
      "[tensor(0.69938875, requires_grad=True)]        [0.916]\n",
      "[tensor(0.70527783, requires_grad=True)]        [0.918]\n",
      "[tensor(0.7111639, requires_grad=True)]        [0.92]\n",
      "[tensor(0.71704637, requires_grad=True)]        [0.922]\n",
      "[tensor(0.72292464, requires_grad=True)]        [0.924]\n",
      "[tensor(0.72879807, requires_grad=True)]        [0.926]\n",
      "[tensor(0.73466596, requires_grad=True)]        [0.928]\n",
      "[tensor(0.74052759, requires_grad=True)]        [0.93]\n",
      "[tensor(0.74638216, requires_grad=True)]        [0.932]\n",
      "[tensor(0.75222884, requires_grad=True)]        [0.934]\n",
      "[tensor(0.75806673, requires_grad=True)]        [0.936]\n",
      "[tensor(0.76389485, requires_grad=True)]        [0.938]\n",
      "[tensor(0.76971215, requires_grad=True)]        [0.94]\n",
      "[tensor(0.77551751, requires_grad=True)]        [0.942]\n",
      "[tensor(0.78130969, requires_grad=True)]        [0.944]\n",
      "[tensor(0.78708736, requires_grad=True)]        [0.946]\n",
      "[tensor(0.79284907, requires_grad=True)]        [0.948]\n",
      "[tensor(0.79859321, requires_grad=True)]        [0.95]\n",
      "[tensor(0.80431804, requires_grad=True)]        [0.952]\n",
      "[tensor(0.81002163, requires_grad=True)]        [0.954]\n",
      "[tensor(0.81570185, requires_grad=True)]        [0.956]\n",
      "[tensor(0.82135631, requires_grad=True)]        [0.958]\n",
      "[tensor(0.82698236, requires_grad=True)]        [0.96]\n",
      "[tensor(0.83257701, requires_grad=True)]        [0.962]\n",
      "[tensor(0.8381369, requires_grad=True)]        [0.964]\n",
      "[tensor(0.84365817, requires_grad=True)]        [0.966]\n",
      "[tensor(0.84913643, requires_grad=True)]        [0.968]\n",
      "[tensor(0.85456659, requires_grad=True)]        [0.97]\n",
      "[tensor(0.8599427, requires_grad=True)]        [0.972]\n",
      "[tensor(0.86525776, requires_grad=True)]        [0.974]\n",
      "[tensor(0.8705034, requires_grad=True)]        [0.976]\n",
      "[tensor(0.87566952, requires_grad=True)]        [0.978]\n",
      "[tensor(0.88074366, requires_grad=True)]        [0.98]\n",
      "[tensor(0.88571021, requires_grad=True)]        [0.982]\n",
      "[tensor(0.89054912, requires_grad=True)]        [0.984]\n",
      "[tensor(0.8952339, requires_grad=True)]        [0.986]\n",
      "[tensor(0.89972828, requires_grad=True)]        [0.988]\n",
      "[tensor(0.90398014, requires_grad=True)]        [0.99]\n",
      "[tensor(0.90790972, requires_grad=True)]        [0.992]\n",
      "[tensor(0.91138308, requires_grad=True)]        [0.994]\n",
      "[tensor(0.91413976, requires_grad=True)]        [0.996]\n",
      "[tensor(0.91550915, requires_grad=True)]        [0.998]\n",
      "[tensor(0.90846017, requires_grad=True)]        [1.]\n",
      "[tensor(-0.90846017, requires_grad=True)]        [0.]\n",
      "[tensor(-0.90823154, requires_grad=True)]        [0.001]\n",
      "[tensor(-0.90799927, requires_grad=True)]        [0.002]\n",
      "[tensor(-0.90776337, requires_grad=True)]        [0.003]\n",
      "[tensor(-0.90752384, requires_grad=True)]        [0.004]\n",
      "[tensor(-0.90728067, requires_grad=True)]        [0.005]\n",
      "[tensor(-0.90703388, requires_grad=True)]        [0.006]\n",
      "[tensor(-0.90678346, requires_grad=True)]        [0.007]\n",
      "[tensor(-0.9065294, requires_grad=True)]        [0.008]\n",
      "[tensor(-0.90627172, requires_grad=True)]        [0.009]\n",
      "[tensor(-0.90601041, requires_grad=True)]        [0.01]\n",
      "[tensor(-0.90574548, requires_grad=True)]        [0.011]\n",
      "[tensor(-0.90547691, requires_grad=True)]        [0.012]\n",
      "[tensor(-0.90520473, requires_grad=True)]        [0.013]\n",
      "[tensor(-0.90492891, requires_grad=True)]        [0.014]\n",
      "[tensor(-0.90464948, requires_grad=True)]        [0.015]\n",
      "[tensor(-0.90436642, requires_grad=True)]        [0.016]\n",
      "[tensor(-0.90407973, requires_grad=True)]        [0.017]\n",
      "[tensor(-0.90378943, requires_grad=True)]        [0.018]\n",
      "[tensor(-0.9034955, requires_grad=True)]        [0.019]\n",
      "[tensor(-0.90319795, requires_grad=True)]        [0.02]\n",
      "[tensor(-0.90289678, requires_grad=True)]        [0.021]\n",
      "[tensor(-0.90259199, requires_grad=True)]        [0.022]\n",
      "[tensor(-0.90228358, requires_grad=True)]        [0.023]\n",
      "[tensor(-0.90197156, requires_grad=True)]        [0.024]\n",
      "[tensor(-0.90165592, requires_grad=True)]        [0.025]\n",
      "[tensor(-0.90133666, requires_grad=True)]        [0.026]\n",
      "[tensor(-0.90101378, requires_grad=True)]        [0.027]\n",
      "[tensor(-0.90068729, requires_grad=True)]        [0.028]\n",
      "[tensor(-0.90035718, requires_grad=True)]        [0.029]\n",
      "[tensor(-0.90002346, requires_grad=True)]        [0.03]\n",
      "[tensor(-0.89968613, requires_grad=True)]        [0.031]\n",
      "[tensor(-0.89934518, requires_grad=True)]        [0.032]\n",
      "[tensor(-0.89900062, requires_grad=True)]        [0.033]\n",
      "[tensor(-0.89865245, requires_grad=True)]        [0.034]\n",
      "[tensor(-0.89830067, requires_grad=True)]        [0.035]\n",
      "[tensor(-0.89794528, requires_grad=True)]        [0.036]\n",
      "[tensor(-0.89758628, requires_grad=True)]        [0.037]\n",
      "[tensor(-0.89722367, requires_grad=True)]        [0.038]\n",
      "[tensor(-0.89685746, requires_grad=True)]        [0.039]\n",
      "[tensor(-0.89648763, requires_grad=True)]        [0.04]\n",
      "[tensor(-0.8961142, requires_grad=True)]        [0.041]\n",
      "[tensor(-0.89573717, requires_grad=True)]        [0.042]\n",
      "[tensor(-0.89535653, requires_grad=True)]        [0.043]\n",
      "[tensor(-0.89497228, requires_grad=True)]        [0.044]\n",
      "[tensor(-0.89458443, requires_grad=True)]        [0.045]\n",
      "[tensor(-0.89419298, requires_grad=True)]        [0.046]\n",
      "[tensor(-0.89379792, requires_grad=True)]        [0.047]\n",
      "[tensor(-0.89339926, requires_grad=True)]        [0.048]\n",
      "[tensor(-0.89299701, requires_grad=True)]        [0.049]\n",
      "[tensor(-0.89259115, requires_grad=True)]        [0.05]\n",
      "[tensor(-0.89218169, requires_grad=True)]        [0.051]\n",
      "[tensor(-0.89176863, requires_grad=True)]        [0.052]\n",
      "[tensor(-0.89135197, requires_grad=True)]        [0.053]\n",
      "[tensor(-0.89093172, requires_grad=True)]        [0.054]\n",
      "[tensor(-0.89050787, requires_grad=True)]        [0.055]\n",
      "[tensor(-0.89008042, requires_grad=True)]        [0.056]\n",
      "[tensor(-0.88964938, requires_grad=True)]        [0.057]\n",
      "[tensor(-0.88921474, requires_grad=True)]        [0.058]\n",
      "[tensor(-0.88877651, requires_grad=True)]        [0.059]\n",
      "[tensor(-0.88833469, requires_grad=True)]        [0.06]\n",
      "[tensor(-0.88788927, requires_grad=True)]        [0.061]\n",
      "[tensor(-0.88744026, requires_grad=True)]        [0.062]\n",
      "[tensor(-0.88698765, requires_grad=True)]        [0.063]\n",
      "[tensor(-0.88653146, requires_grad=True)]        [0.064]\n",
      "[tensor(-0.88607168, requires_grad=True)]        [0.065]\n",
      "[tensor(-0.88560831, requires_grad=True)]        [0.066]\n",
      "[tensor(-0.88514134, requires_grad=True)]        [0.067]\n",
      "[tensor(-0.8846708, requires_grad=True)]        [0.068]\n",
      "[tensor(-0.88419666, requires_grad=True)]        [0.069]\n",
      "[tensor(-0.88371894, requires_grad=True)]        [0.07]\n",
      "[tensor(-0.88323763, requires_grad=True)]        [0.071]\n",
      "[tensor(-0.88275273, requires_grad=True)]        [0.072]\n",
      "[tensor(-0.88226425, requires_grad=True)]        [0.073]\n",
      "[tensor(-0.88177219, requires_grad=True)]        [0.074]\n",
      "[tensor(-0.88127654, requires_grad=True)]        [0.075]\n",
      "[tensor(-0.88077731, requires_grad=True)]        [0.076]\n",
      "[tensor(-0.8802745, requires_grad=True)]        [0.077]\n",
      "[tensor(-0.87976811, requires_grad=True)]        [0.078]\n",
      "[tensor(-0.87925814, requires_grad=True)]        [0.079]\n",
      "[tensor(-0.87874458, requires_grad=True)]        [0.08]\n",
      "[tensor(-0.87822745, requires_grad=True)]        [0.081]\n",
      "[tensor(-0.87770674, requires_grad=True)]        [0.082]\n",
      "[tensor(-0.87718245, requires_grad=True)]        [0.083]\n",
      "[tensor(-0.87665459, requires_grad=True)]        [0.084]\n",
      "[tensor(-0.87612315, requires_grad=True)]        [0.085]\n",
      "[tensor(-0.87558813, requires_grad=True)]        [0.086]\n",
      "[tensor(-0.87504954, requires_grad=True)]        [0.087]\n",
      "[tensor(-0.87450737, requires_grad=True)]        [0.088]\n",
      "[tensor(-0.87396163, requires_grad=True)]        [0.089]\n",
      "[tensor(-0.87341232, requires_grad=True)]        [0.09]\n",
      "[tensor(-0.87285944, requires_grad=True)]        [0.091]\n",
      "[tensor(-0.87230298, requires_grad=True)]        [0.092]\n",
      "[tensor(-0.87174295, requires_grad=True)]        [0.093]\n",
      "[tensor(-0.87117936, requires_grad=True)]        [0.094]\n",
      "[tensor(-0.87061219, requires_grad=True)]        [0.095]\n",
      "[tensor(-0.87004146, requires_grad=True)]        [0.096]\n",
      "[tensor(-0.86946715, requires_grad=True)]        [0.097]\n",
      "[tensor(-0.86888928, requires_grad=True)]        [0.098]\n",
      "[tensor(-0.86830784, requires_grad=True)]        [0.099]\n",
      "[tensor(-0.86772284, requires_grad=True)]        [0.1]\n",
      "[tensor(-0.86713427, requires_grad=True)]        [0.101]\n",
      "[tensor(-0.86654214, requires_grad=True)]        [0.102]\n",
      "[tensor(-0.86594644, requires_grad=True)]        [0.103]\n",
      "[tensor(-0.86534718, requires_grad=True)]        [0.104]\n",
      "[tensor(-0.86474436, requires_grad=True)]        [0.105]\n",
      "[tensor(-0.86413798, requires_grad=True)]        [0.106]\n",
      "[tensor(-0.86352803, requires_grad=True)]        [0.107]\n",
      "[tensor(-0.86291453, requires_grad=True)]        [0.108]\n",
      "[tensor(-0.86229746, requires_grad=True)]        [0.109]\n",
      "[tensor(-0.86167684, requires_grad=True)]        [0.11]\n",
      "[tensor(-0.86105266, requires_grad=True)]        [0.111]\n",
      "[tensor(-0.86042492, requires_grad=True)]        [0.112]\n",
      "[tensor(-0.85979362, requires_grad=True)]        [0.113]\n",
      "[tensor(-0.85915877, requires_grad=True)]        [0.114]\n",
      "[tensor(-0.85852036, requires_grad=True)]        [0.115]\n",
      "[tensor(-0.8578784, requires_grad=True)]        [0.116]\n",
      "[tensor(-0.85723288, requires_grad=True)]        [0.117]\n",
      "[tensor(-0.85658381, requires_grad=True)]        [0.118]\n",
      "[tensor(-0.85593119, requires_grad=True)]        [0.119]\n",
      "[tensor(-0.85527502, requires_grad=True)]        [0.12]\n",
      "[tensor(-0.85461529, requires_grad=True)]        [0.121]\n",
      "[tensor(-0.85395201, requires_grad=True)]        [0.122]\n",
      "[tensor(-0.85328519, requires_grad=True)]        [0.123]\n",
      "[tensor(-0.85261481, requires_grad=True)]        [0.124]\n",
      "[tensor(-0.85194089, requires_grad=True)]        [0.125]\n",
      "[tensor(-0.85126342, requires_grad=True)]        [0.126]\n",
      "[tensor(-0.8505824, requires_grad=True)]        [0.127]\n",
      "[tensor(-0.84989784, requires_grad=True)]        [0.128]\n",
      "[tensor(-0.84920973, requires_grad=True)]        [0.129]\n",
      "[tensor(-0.84851807, requires_grad=True)]        [0.13]\n",
      "[tensor(-0.84782287, requires_grad=True)]        [0.131]\n",
      "[tensor(-0.84712413, requires_grad=True)]        [0.132]\n",
      "[tensor(-0.84642185, requires_grad=True)]        [0.133]\n",
      "[tensor(-0.84571602, requires_grad=True)]        [0.134]\n",
      "[tensor(-0.84500665, requires_grad=True)]        [0.135]\n",
      "[tensor(-0.84429374, requires_grad=True)]        [0.136]\n",
      "[tensor(-0.8435773, requires_grad=True)]        [0.137]\n",
      "[tensor(-0.84285731, requires_grad=True)]        [0.138]\n",
      "[tensor(-0.84213378, requires_grad=True)]        [0.139]\n",
      "[tensor(-0.84140672, requires_grad=True)]        [0.14]\n",
      "[tensor(-0.84067612, requires_grad=True)]        [0.141]\n",
      "[tensor(-0.83994198, requires_grad=True)]        [0.142]\n",
      "[tensor(-0.83920431, requires_grad=True)]        [0.143]\n",
      "[tensor(-0.8384631, requires_grad=True)]        [0.144]\n",
      "[tensor(-0.83771836, requires_grad=True)]        [0.145]\n",
      "[tensor(-0.83697008, requires_grad=True)]        [0.146]\n",
      "[tensor(-0.83621828, requires_grad=True)]        [0.147]\n",
      "[tensor(-0.83546294, requires_grad=True)]        [0.148]\n",
      "[tensor(-0.83470407, requires_grad=True)]        [0.149]\n",
      "[tensor(-0.83394167, requires_grad=True)]        [0.15]\n",
      "[tensor(-0.83317573, requires_grad=True)]        [0.151]\n",
      "[tensor(-0.83240627, requires_grad=True)]        [0.152]\n",
      "[tensor(-0.83163329, requires_grad=True)]        [0.153]\n",
      "[tensor(-0.83085677, requires_grad=True)]        [0.154]\n",
      "[tensor(-0.83007673, requires_grad=True)]        [0.155]\n",
      "[tensor(-0.82929316, requires_grad=True)]        [0.156]\n",
      "[tensor(-0.82850606, requires_grad=True)]        [0.157]\n",
      "[tensor(-0.82771544, requires_grad=True)]        [0.158]\n",
      "[tensor(-0.8269213, requires_grad=True)]        [0.159]\n",
      "[tensor(-0.82612363, requires_grad=True)]        [0.16]\n",
      "[tensor(-0.82532244, requires_grad=True)]        [0.161]\n",
      "[tensor(-0.82451773, requires_grad=True)]        [0.162]\n",
      "[tensor(-0.8237095, requires_grad=True)]        [0.163]\n",
      "[tensor(-0.82289775, requires_grad=True)]        [0.164]\n",
      "[tensor(-0.82208247, requires_grad=True)]        [0.165]\n",
      "[tensor(-0.82126368, requires_grad=True)]        [0.166]\n",
      "[tensor(-0.82044137, requires_grad=True)]        [0.167]\n",
      "[tensor(-0.81961555, requires_grad=True)]        [0.168]\n",
      "[tensor(-0.8187862, requires_grad=True)]        [0.169]\n",
      "[tensor(-0.81795334, requires_grad=True)]        [0.17]\n",
      "[tensor(-0.81711697, requires_grad=True)]        [0.171]\n",
      "[tensor(-0.81627708, requires_grad=True)]        [0.172]\n",
      "[tensor(-0.81543367, requires_grad=True)]        [0.173]\n",
      "[tensor(-0.81458676, requires_grad=True)]        [0.174]\n",
      "[tensor(-0.81373633, requires_grad=True)]        [0.175]\n",
      "[tensor(-0.81288239, requires_grad=True)]        [0.176]\n",
      "[tensor(-0.81202493, requires_grad=True)]        [0.177]\n",
      "[tensor(-0.81116397, requires_grad=True)]        [0.178]\n",
      "[tensor(-0.8102995, requires_grad=True)]        [0.179]\n",
      "[tensor(-0.80943152, requires_grad=True)]        [0.18]\n",
      "[tensor(-0.80856003, requires_grad=True)]        [0.181]\n",
      "[tensor(-0.80768504, requires_grad=True)]        [0.182]\n",
      "[tensor(-0.80680654, requires_grad=True)]        [0.183]\n",
      "[tensor(-0.80592453, requires_grad=True)]        [0.184]\n",
      "[tensor(-0.80503902, requires_grad=True)]        [0.185]\n",
      "[tensor(-0.80415, requires_grad=True)]        [0.186]\n",
      "[tensor(-0.80325748, requires_grad=True)]        [0.187]\n",
      "[tensor(-0.80236146, requires_grad=True)]        [0.188]\n",
      "[tensor(-0.80146194, requires_grad=True)]        [0.189]\n",
      "[tensor(-0.80055891, requires_grad=True)]        [0.19]\n",
      "[tensor(-0.79965238, requires_grad=True)]        [0.191]\n",
      "[tensor(-0.79874236, requires_grad=True)]        [0.192]\n",
      "[tensor(-0.79782883, requires_grad=True)]        [0.193]\n",
      "[tensor(-0.79691181, requires_grad=True)]        [0.194]\n",
      "[tensor(-0.79599129, requires_grad=True)]        [0.195]\n",
      "[tensor(-0.79506727, requires_grad=True)]        [0.196]\n",
      "[tensor(-0.79413976, requires_grad=True)]        [0.197]\n",
      "[tensor(-0.79320875, requires_grad=True)]        [0.198]\n",
      "[tensor(-0.79227424, requires_grad=True)]        [0.199]\n",
      "[tensor(-0.79133625, requires_grad=True)]        [0.2]\n",
      "[tensor(-0.79039476, requires_grad=True)]        [0.201]\n",
      "[tensor(-0.78944977, requires_grad=True)]        [0.202]\n",
      "[tensor(-0.7885013, requires_grad=True)]        [0.203]\n",
      "[tensor(-0.78754933, requires_grad=True)]        [0.204]\n",
      "[tensor(-0.78659388, requires_grad=True)]        [0.205]\n",
      "[tensor(-0.78563494, requires_grad=True)]        [0.206]\n",
      "[tensor(-0.7846725, requires_grad=True)]        [0.207]\n",
      "[tensor(-0.78370658, requires_grad=True)]        [0.208]\n",
      "[tensor(-0.78273718, requires_grad=True)]        [0.209]\n",
      "[tensor(-0.78176428, requires_grad=True)]        [0.21]\n",
      "[tensor(-0.7807879, requires_grad=True)]        [0.211]\n",
      "[tensor(-0.77980804, requires_grad=True)]        [0.212]\n",
      "[tensor(-0.77882469, requires_grad=True)]        [0.213]\n",
      "[tensor(-0.77783786, requires_grad=True)]        [0.214]\n",
      "[tensor(-0.77684755, requires_grad=True)]        [0.215]\n",
      "[tensor(-0.77585376, requires_grad=True)]        [0.216]\n",
      "[tensor(-0.77485648, requires_grad=True)]        [0.217]\n",
      "[tensor(-0.77385572, requires_grad=True)]        [0.218]\n",
      "[tensor(-0.77285149, requires_grad=True)]        [0.219]\n",
      "[tensor(-0.77184378, requires_grad=True)]        [0.22]\n",
      "[tensor(-0.77083258, requires_grad=True)]        [0.221]\n",
      "[tensor(-0.76981792, requires_grad=True)]        [0.222]\n",
      "[tensor(-0.76879977, requires_grad=True)]        [0.223]\n",
      "[tensor(-0.76777815, requires_grad=True)]        [0.224]\n",
      "[tensor(-0.76675306, requires_grad=True)]        [0.225]\n",
      "[tensor(-0.76572449, requires_grad=True)]        [0.226]\n",
      "[tensor(-0.76469245, requires_grad=True)]        [0.227]\n",
      "[tensor(-0.76365693, requires_grad=True)]        [0.228]\n",
      "[tensor(-0.76261795, requires_grad=True)]        [0.229]\n",
      "[tensor(-0.76157549, requires_grad=True)]        [0.23]\n",
      "[tensor(-0.76052957, requires_grad=True)]        [0.231]\n",
      "[tensor(-0.75948017, requires_grad=True)]        [0.232]\n",
      "[tensor(-0.75842731, requires_grad=True)]        [0.233]\n",
      "[tensor(-0.75737097, requires_grad=True)]        [0.234]\n",
      "[tensor(-0.75631118, requires_grad=True)]        [0.235]\n",
      "[tensor(-0.75524791, requires_grad=True)]        [0.236]\n",
      "[tensor(-0.75418118, requires_grad=True)]        [0.237]\n",
      "[tensor(-0.75311099, requires_grad=True)]        [0.238]\n",
      "[tensor(-0.75203733, requires_grad=True)]        [0.239]\n",
      "[tensor(-0.75096021, requires_grad=True)]        [0.24]\n",
      "[tensor(-0.74987962, requires_grad=True)]        [0.241]\n",
      "[tensor(-0.74879558, requires_grad=True)]        [0.242]\n",
      "[tensor(-0.74770807, requires_grad=True)]        [0.243]\n",
      "[tensor(-0.74661711, requires_grad=True)]        [0.244]\n",
      "[tensor(-0.74552268, requires_grad=True)]        [0.245]\n",
      "[tensor(-0.7444248, requires_grad=True)]        [0.246]\n",
      "[tensor(-0.74332346, requires_grad=True)]        [0.247]\n",
      "[tensor(-0.74221866, requires_grad=True)]        [0.248]\n",
      "[tensor(-0.74111041, requires_grad=True)]        [0.249]\n",
      "[tensor(-0.7399987, requires_grad=True)]        [0.25]\n",
      "[tensor(-0.73888354, requires_grad=True)]        [0.251]\n",
      "[tensor(-0.73776492, requires_grad=True)]        [0.252]\n",
      "[tensor(-0.73664286, requires_grad=True)]        [0.253]\n",
      "[tensor(-0.73551734, requires_grad=True)]        [0.254]\n",
      "[tensor(-0.73438837, requires_grad=True)]        [0.255]\n",
      "[tensor(-0.73325594, requires_grad=True)]        [0.256]\n",
      "[tensor(-0.73212007, requires_grad=True)]        [0.257]\n",
      "[tensor(-0.73098075, requires_grad=True)]        [0.258]\n",
      "[tensor(-0.72983799, requires_grad=True)]        [0.259]\n",
      "[tensor(-0.72869177, requires_grad=True)]        [0.26]\n",
      "[tensor(-0.72754211, requires_grad=True)]        [0.261]\n",
      "[tensor(-0.72638901, requires_grad=True)]        [0.262]\n",
      "[tensor(-0.72523246, requires_grad=True)]        [0.263]\n",
      "[tensor(-0.72407246, requires_grad=True)]        [0.264]\n",
      "[tensor(-0.72290903, requires_grad=True)]        [0.265]\n",
      "[tensor(-0.72174215, requires_grad=True)]        [0.266]\n",
      "[tensor(-0.72057183, requires_grad=True)]        [0.267]\n",
      "[tensor(-0.71939807, requires_grad=True)]        [0.268]\n",
      "[tensor(-0.71822087, requires_grad=True)]        [0.269]\n",
      "[tensor(-0.71704023, requires_grad=True)]        [0.27]\n",
      "[tensor(-0.71585615, requires_grad=True)]        [0.271]\n",
      "[tensor(-0.71466864, requires_grad=True)]        [0.272]\n",
      "[tensor(-0.71347769, requires_grad=True)]        [0.273]\n",
      "[tensor(-0.7122833, requires_grad=True)]        [0.274]\n",
      "[tensor(-0.71108548, requires_grad=True)]        [0.275]\n",
      "[tensor(-0.70988422, requires_grad=True)]        [0.276]\n",
      "[tensor(-0.70867953, requires_grad=True)]        [0.277]\n",
      "[tensor(-0.70747141, requires_grad=True)]        [0.278]\n",
      "[tensor(-0.70625986, requires_grad=True)]        [0.279]\n",
      "[tensor(-0.70504488, requires_grad=True)]        [0.28]\n",
      "[tensor(-0.70382647, requires_grad=True)]        [0.281]\n",
      "[tensor(-0.70260463, requires_grad=True)]        [0.282]\n",
      "[tensor(-0.70137936, requires_grad=True)]        [0.283]\n",
      "[tensor(-0.70015066, requires_grad=True)]        [0.284]\n",
      "[tensor(-0.69891854, requires_grad=True)]        [0.285]\n",
      "[tensor(-0.69768299, requires_grad=True)]        [0.286]\n",
      "[tensor(-0.69644402, requires_grad=True)]        [0.287]\n",
      "[tensor(-0.69520162, requires_grad=True)]        [0.288]\n",
      "[tensor(-0.6939558, requires_grad=True)]        [0.289]\n",
      "[tensor(-0.69270656, requires_grad=True)]        [0.29]\n",
      "[tensor(-0.69145389, requires_grad=True)]        [0.291]\n",
      "[tensor(-0.69019781, requires_grad=True)]        [0.292]\n",
      "[tensor(-0.68893831, requires_grad=True)]        [0.293]\n",
      "[tensor(-0.68767538, requires_grad=True)]        [0.294]\n",
      "[tensor(-0.68640904, requires_grad=True)]        [0.295]\n",
      "[tensor(-0.68513929, requires_grad=True)]        [0.296]\n",
      "[tensor(-0.68386611, requires_grad=True)]        [0.297]\n",
      "[tensor(-0.68258952, requires_grad=True)]        [0.298]\n",
      "[tensor(-0.68130952, requires_grad=True)]        [0.299]\n",
      "[tensor(-0.6800261, requires_grad=True)]        [0.3]\n",
      "[tensor(-0.67873927, requires_grad=True)]        [0.301]\n",
      "[tensor(-0.67744903, requires_grad=True)]        [0.302]\n",
      "[tensor(-0.67615538, requires_grad=True)]        [0.303]\n",
      "[tensor(-0.67485832, requires_grad=True)]        [0.304]\n",
      "[tensor(-0.67355784, requires_grad=True)]        [0.305]\n",
      "[tensor(-0.67225396, requires_grad=True)]        [0.306]\n",
      "[tensor(-0.67094667, requires_grad=True)]        [0.307]\n",
      "[tensor(-0.66963598, requires_grad=True)]        [0.308]\n",
      "[tensor(-0.66832188, requires_grad=True)]        [0.309]\n",
      "[tensor(-0.66700437, requires_grad=True)]        [0.31]\n",
      "[tensor(-0.66568346, requires_grad=True)]        [0.311]\n",
      "[tensor(-0.66435915, requires_grad=True)]        [0.312]\n",
      "[tensor(-0.66303143, requires_grad=True)]        [0.313]\n",
      "[tensor(-0.66170031, requires_grad=True)]        [0.314]\n",
      "[tensor(-0.6603658, requires_grad=True)]        [0.315]\n",
      "[tensor(-0.65902788, requires_grad=True)]        [0.316]\n",
      "[tensor(-0.65768656, requires_grad=True)]        [0.317]\n",
      "[tensor(-0.65634185, requires_grad=True)]        [0.318]\n",
      "[tensor(-0.65499374, requires_grad=True)]        [0.319]\n",
      "[tensor(-0.65364223, requires_grad=True)]        [0.32]\n",
      "[tensor(-0.65228733, requires_grad=True)]        [0.321]\n",
      "[tensor(-0.65092903, requires_grad=True)]        [0.322]\n",
      "[tensor(-0.64956734, requires_grad=True)]        [0.323]\n",
      "[tensor(-0.64820226, requires_grad=True)]        [0.324]\n",
      "[tensor(-0.64683378, requires_grad=True)]        [0.325]\n",
      "[tensor(-0.64546191, requires_grad=True)]        [0.326]\n",
      "[tensor(-0.64408666, requires_grad=True)]        [0.327]\n",
      "[tensor(-0.64270801, requires_grad=True)]        [0.328]\n",
      "[tensor(-0.64132598, requires_grad=True)]        [0.329]\n",
      "[tensor(-0.63994056, requires_grad=True)]        [0.33]\n",
      "[tensor(-0.63855176, requires_grad=True)]        [0.331]\n",
      "[tensor(-0.63715956, requires_grad=True)]        [0.332]\n",
      "[tensor(-0.63576399, requires_grad=True)]        [0.333]\n",
      "[tensor(-0.63436503, requires_grad=True)]        [0.334]\n",
      "[tensor(-0.63296269, requires_grad=True)]        [0.335]\n",
      "[tensor(-0.63155696, requires_grad=True)]        [0.336]\n",
      "[tensor(-0.63014786, requires_grad=True)]        [0.337]\n",
      "[tensor(-0.62873537, requires_grad=True)]        [0.338]\n",
      "[tensor(-0.62731951, requires_grad=True)]        [0.339]\n",
      "[tensor(-0.62590027, requires_grad=True)]        [0.34]\n",
      "[tensor(-0.62447765, requires_grad=True)]        [0.341]\n",
      "[tensor(-0.62305165, requires_grad=True)]        [0.342]\n",
      "[tensor(-0.62162228, requires_grad=True)]        [0.343]\n",
      "[tensor(-0.62018954, requires_grad=True)]        [0.344]\n",
      "[tensor(-0.61875342, requires_grad=True)]        [0.345]\n",
      "[tensor(-0.61731393, requires_grad=True)]        [0.346]\n",
      "[tensor(-0.61587107, requires_grad=True)]        [0.347]\n",
      "[tensor(-0.61442484, requires_grad=True)]        [0.348]\n",
      "[tensor(-0.61297524, requires_grad=True)]        [0.349]\n",
      "[tensor(-0.61152226, requires_grad=True)]        [0.35]\n",
      "[tensor(-0.61006593, requires_grad=True)]        [0.351]\n",
      "[tensor(-0.60860622, requires_grad=True)]        [0.352]\n",
      "[tensor(-0.60714315, requires_grad=True)]        [0.353]\n",
      "[tensor(-0.60567671, requires_grad=True)]        [0.354]\n",
      "[tensor(-0.60420691, requires_grad=True)]        [0.355]\n",
      "[tensor(-0.60273375, requires_grad=True)]        [0.356]\n",
      "[tensor(-0.60125722, requires_grad=True)]        [0.357]\n",
      "[tensor(-0.59977734, requires_grad=True)]        [0.358]\n",
      "[tensor(-0.59829409, requires_grad=True)]        [0.359]\n",
      "[tensor(-0.59680749, requires_grad=True)]        [0.36]\n",
      "[tensor(-0.59531752, requires_grad=True)]        [0.361]\n",
      "[tensor(-0.5938242, requires_grad=True)]        [0.362]\n",
      "[tensor(-0.59232752, requires_grad=True)]        [0.363]\n",
      "[tensor(-0.59082749, requires_grad=True)]        [0.364]\n",
      "[tensor(-0.5893241, requires_grad=True)]        [0.365]\n",
      "[tensor(-0.58781736, requires_grad=True)]        [0.366]\n",
      "[tensor(-0.58630727, requires_grad=True)]        [0.367]\n",
      "[tensor(-0.58479382, requires_grad=True)]        [0.368]\n",
      "[tensor(-0.58327703, requires_grad=True)]        [0.369]\n",
      "[tensor(-0.58175688, requires_grad=True)]        [0.37]\n",
      "[tensor(-0.58023339, requires_grad=True)]        [0.371]\n",
      "[tensor(-0.57870655, requires_grad=True)]        [0.372]\n",
      "[tensor(-0.57717636, requires_grad=True)]        [0.373]\n",
      "[tensor(-0.57564283, requires_grad=True)]        [0.374]\n",
      "[tensor(-0.57410595, requires_grad=True)]        [0.375]\n",
      "[tensor(-0.57256573, requires_grad=True)]        [0.376]\n",
      "[tensor(-0.57102217, requires_grad=True)]        [0.377]\n",
      "[tensor(-0.56947526, requires_grad=True)]        [0.378]\n",
      "[tensor(-0.56792502, requires_grad=True)]        [0.379]\n",
      "[tensor(-0.56637143, requires_grad=True)]        [0.38]\n",
      "[tensor(-0.56481451, requires_grad=True)]        [0.381]\n",
      "[tensor(-0.56325425, requires_grad=True)]        [0.382]\n",
      "[tensor(-0.56169065, requires_grad=True)]        [0.383]\n",
      "[tensor(-0.56012372, requires_grad=True)]        [0.384]\n",
      "[tensor(-0.55855345, requires_grad=True)]        [0.385]\n",
      "[tensor(-0.55697985, requires_grad=True)]        [0.386]\n",
      "[tensor(-0.55540291, requires_grad=True)]        [0.387]\n",
      "[tensor(-0.55382265, requires_grad=True)]        [0.388]\n",
      "[tensor(-0.55223905, requires_grad=True)]        [0.389]\n",
      "[tensor(-0.55065213, requires_grad=True)]        [0.39]\n",
      "[tensor(-0.54906187, requires_grad=True)]        [0.391]\n",
      "[tensor(-0.54746829, requires_grad=True)]        [0.392]\n",
      "[tensor(-0.54587139, requires_grad=True)]        [0.393]\n",
      "[tensor(-0.54427115, requires_grad=True)]        [0.394]\n",
      "[tensor(-0.5426676, requires_grad=True)]        [0.395]\n",
      "[tensor(-0.54106072, requires_grad=True)]        [0.396]\n",
      "[tensor(-0.53945051, requires_grad=True)]        [0.397]\n",
      "[tensor(-0.53783699, requires_grad=True)]        [0.398]\n",
      "[tensor(-0.53622015, requires_grad=True)]        [0.399]\n",
      "[tensor(-0.53459998, requires_grad=True)]        [0.4]\n",
      "[tensor(-0.5329765, requires_grad=True)]        [0.401]\n",
      "[tensor(-0.5313497, requires_grad=True)]        [0.402]\n",
      "[tensor(-0.52971959, requires_grad=True)]        [0.403]\n",
      "[tensor(-0.52808616, requires_grad=True)]        [0.404]\n",
      "[tensor(-0.52644942, requires_grad=True)]        [0.405]\n",
      "[tensor(-0.52480937, requires_grad=True)]        [0.406]\n",
      "[tensor(-0.523166, requires_grad=True)]        [0.407]\n",
      "[tensor(-0.52151932, requires_grad=True)]        [0.408]\n",
      "[tensor(-0.51986933, requires_grad=True)]        [0.409]\n",
      "[tensor(-0.51821604, requires_grad=True)]        [0.41]\n",
      "[tensor(-0.51655944, requires_grad=True)]        [0.411]\n",
      "[tensor(-0.51489953, requires_grad=True)]        [0.412]\n",
      "[tensor(-0.51323631, requires_grad=True)]        [0.413]\n",
      "[tensor(-0.5115698, requires_grad=True)]        [0.414]\n",
      "[tensor(-0.50989997, requires_grad=True)]        [0.415]\n",
      "[tensor(-0.50822685, requires_grad=True)]        [0.416]\n",
      "[tensor(-0.50655043, requires_grad=True)]        [0.417]\n",
      "[tensor(-0.5048707, requires_grad=True)]        [0.418]\n",
      "[tensor(-0.50318768, requires_grad=True)]        [0.419]\n",
      "[tensor(-0.50150136, requires_grad=True)]        [0.42]\n",
      "[tensor(-0.49981175, requires_grad=True)]        [0.421]\n",
      "[tensor(-0.49811883, requires_grad=True)]        [0.422]\n",
      "[tensor(-0.49642263, requires_grad=True)]        [0.423]\n",
      "[tensor(-0.49472313, requires_grad=True)]        [0.424]\n",
      "[tensor(-0.49302034, requires_grad=True)]        [0.425]\n",
      "[tensor(-0.49131426, requires_grad=True)]        [0.426]\n",
      "[tensor(-0.48960488, requires_grad=True)]        [0.427]\n",
      "[tensor(-0.48789222, requires_grad=True)]        [0.428]\n",
      "[tensor(-0.48617628, requires_grad=True)]        [0.429]\n",
      "[tensor(-0.48445704, requires_grad=True)]        [0.43]\n",
      "[tensor(-0.48273452, requires_grad=True)]        [0.431]\n",
      "[tensor(-0.48100872, requires_grad=True)]        [0.432]\n",
      "[tensor(-0.47927963, requires_grad=True)]        [0.433]\n",
      "[tensor(-0.47754726, requires_grad=True)]        [0.434]\n",
      "[tensor(-0.47581161, requires_grad=True)]        [0.435]\n",
      "[tensor(-0.47407269, requires_grad=True)]        [0.436]\n",
      "[tensor(-0.47233048, requires_grad=True)]        [0.437]\n",
      "[tensor(-0.47058499, requires_grad=True)]        [0.438]\n",
      "[tensor(-0.46883623, requires_grad=True)]        [0.439]\n",
      "[tensor(-0.4670842, requires_grad=True)]        [0.44]\n",
      "[tensor(-0.46532889, requires_grad=True)]        [0.441]\n",
      "[tensor(-0.46357031, requires_grad=True)]        [0.442]\n",
      "[tensor(-0.46180846, requires_grad=True)]        [0.443]\n",
      "[tensor(-0.46004333, requires_grad=True)]        [0.444]\n",
      "[tensor(-0.45827494, requires_grad=True)]        [0.445]\n",
      "[tensor(-0.45650328, requires_grad=True)]        [0.446]\n",
      "[tensor(-0.45472835, requires_grad=True)]        [0.447]\n",
      "[tensor(-0.45295016, requires_grad=True)]        [0.448]\n",
      "[tensor(-0.4511687, requires_grad=True)]        [0.449]\n",
      "[tensor(-0.44938398, requires_grad=True)]        [0.45]\n",
      "[tensor(-0.447596, requires_grad=True)]        [0.451]\n",
      "[tensor(-0.44580476, requires_grad=True)]        [0.452]\n",
      "[tensor(-0.44401026, requires_grad=True)]        [0.453]\n",
      "[tensor(-0.4422125, requires_grad=True)]        [0.454]\n",
      "[tensor(-0.44041148, requires_grad=True)]        [0.455]\n",
      "[tensor(-0.43860721, requires_grad=True)]        [0.456]\n",
      "[tensor(-0.43679968, requires_grad=True)]        [0.457]\n",
      "[tensor(-0.4349889, requires_grad=True)]        [0.458]\n",
      "[tensor(-0.43317486, requires_grad=True)]        [0.459]\n",
      "[tensor(-0.43135758, requires_grad=True)]        [0.46]\n",
      "[tensor(-0.42953705, requires_grad=True)]        [0.461]\n",
      "[tensor(-0.42771326, requires_grad=True)]        [0.462]\n",
      "[tensor(-0.42588623, requires_grad=True)]        [0.463]\n",
      "[tensor(-0.42405596, requires_grad=True)]        [0.464]\n",
      "[tensor(-0.42222243, requires_grad=True)]        [0.465]\n",
      "[tensor(-0.42038567, requires_grad=True)]        [0.466]\n",
      "[tensor(-0.41854566, requires_grad=True)]        [0.467]\n",
      "[tensor(-0.41670241, requires_grad=True)]        [0.468]\n",
      "[tensor(-0.41485593, requires_grad=True)]        [0.469]\n",
      "[tensor(-0.4130062, requires_grad=True)]        [0.47]\n",
      "[tensor(-0.41115324, requires_grad=True)]        [0.471]\n",
      "[tensor(-0.40929704, requires_grad=True)]        [0.472]\n",
      "[tensor(-0.4074376, requires_grad=True)]        [0.473]\n",
      "[tensor(-0.40557493, requires_grad=True)]        [0.474]\n",
      "[tensor(-0.40370903, requires_grad=True)]        [0.475]\n",
      "[tensor(-0.4018399, requires_grad=True)]        [0.476]\n",
      "[tensor(-0.39996754, requires_grad=True)]        [0.477]\n",
      "[tensor(-0.39809195, requires_grad=True)]        [0.478]\n",
      "[tensor(-0.39621314, requires_grad=True)]        [0.479]\n",
      "[tensor(-0.39433109, requires_grad=True)]        [0.48]\n",
      "[tensor(-0.39244583, requires_grad=True)]        [0.481]\n",
      "[tensor(-0.39055734, requires_grad=True)]        [0.482]\n",
      "[tensor(-0.38866563, requires_grad=True)]        [0.483]\n",
      "[tensor(-0.3867707, requires_grad=True)]        [0.484]\n",
      "[tensor(-0.38487255, requires_grad=True)]        [0.485]\n",
      "[tensor(-0.38297118, requires_grad=True)]        [0.486]\n",
      "[tensor(-0.38106659, requires_grad=True)]        [0.487]\n",
      "[tensor(-0.3791588, requires_grad=True)]        [0.488]\n",
      "[tensor(-0.37724778, requires_grad=True)]        [0.489]\n",
      "[tensor(-0.37533356, requires_grad=True)]        [0.49]\n",
      "[tensor(-0.37341612, requires_grad=True)]        [0.491]\n",
      "[tensor(-0.37149547, requires_grad=True)]        [0.492]\n",
      "[tensor(-0.36957162, requires_grad=True)]        [0.493]\n",
      "[tensor(-0.36764456, requires_grad=True)]        [0.494]\n",
      "[tensor(-0.36571429, requires_grad=True)]        [0.495]\n",
      "[tensor(-0.36378082, requires_grad=True)]        [0.496]\n",
      "[tensor(-0.36184414, requires_grad=True)]        [0.497]\n",
      "[tensor(-0.35990427, requires_grad=True)]        [0.498]\n",
      "[tensor(-0.35796119, requires_grad=True)]        [0.499]\n",
      "[tensor(-0.35601491, requires_grad=True)]        [0.5]\n",
      "[tensor(-0.35406544, requires_grad=True)]        [0.501]\n",
      "[tensor(-0.35211277, requires_grad=True)]        [0.502]\n",
      "[tensor(-0.35015691, requires_grad=True)]        [0.503]\n",
      "[tensor(-0.34819785, requires_grad=True)]        [0.504]\n",
      "[tensor(-0.34623561, requires_grad=True)]        [0.505]\n",
      "[tensor(-0.34427017, requires_grad=True)]        [0.506]\n",
      "[tensor(-0.34230154, requires_grad=True)]        [0.507]\n",
      "[tensor(-0.34032973, requires_grad=True)]        [0.508]\n",
      "[tensor(-0.33835473, requires_grad=True)]        [0.509]\n",
      "[tensor(-0.33637654, requires_grad=True)]        [0.51]\n",
      "[tensor(-0.33439518, requires_grad=True)]        [0.511]\n",
      "[tensor(-0.33241063, requires_grad=True)]        [0.512]\n",
      "[tensor(-0.3304229, requires_grad=True)]        [0.513]\n",
      "[tensor(-0.32843199, requires_grad=True)]        [0.514]\n",
      "[tensor(-0.3264379, requires_grad=True)]        [0.515]\n",
      "[tensor(-0.32444064, requires_grad=True)]        [0.516]\n",
      "[tensor(-0.3224402, requires_grad=True)]        [0.517]\n",
      "[tensor(-0.3204366, requires_grad=True)]        [0.518]\n",
      "[tensor(-0.31842981, requires_grad=True)]        [0.519]\n",
      "[tensor(-0.31641986, requires_grad=True)]        [0.52]\n",
      "[tensor(-0.31440675, requires_grad=True)]        [0.521]\n",
      "[tensor(-0.31239046, requires_grad=True)]        [0.522]\n",
      "[tensor(-0.31037101, requires_grad=True)]        [0.523]\n",
      "[tensor(-0.30834839, requires_grad=True)]        [0.524]\n",
      "[tensor(-0.30632262, requires_grad=True)]        [0.525]\n",
      "[tensor(-0.30429368, requires_grad=True)]        [0.526]\n",
      "[tensor(-0.30226158, requires_grad=True)]        [0.527]\n",
      "[tensor(-0.30022633, requires_grad=True)]        [0.528]\n",
      "[tensor(-0.29818791, requires_grad=True)]        [0.529]\n",
      "[tensor(-0.29614635, requires_grad=True)]        [0.53]\n",
      "[tensor(-0.29410163, requires_grad=True)]        [0.531]\n",
      "[tensor(-0.29205376, requires_grad=True)]        [0.532]\n",
      "[tensor(-0.29000274, requires_grad=True)]        [0.533]\n",
      "[tensor(-0.28794857, requires_grad=True)]        [0.534]\n",
      "[tensor(-0.28589125, requires_grad=True)]        [0.535]\n",
      "[tensor(-0.28383079, requires_grad=True)]        [0.536]\n",
      "[tensor(-0.28176718, requires_grad=True)]        [0.537]\n",
      "[tensor(-0.27970043, requires_grad=True)]        [0.538]\n",
      "[tensor(-0.27763055, requires_grad=True)]        [0.539]\n",
      "[tensor(-0.27555752, requires_grad=True)]        [0.54]\n",
      "[tensor(-0.27348135, requires_grad=True)]        [0.541]\n",
      "[tensor(-0.27140205, requires_grad=True)]        [0.542]\n",
      "[tensor(-0.26931962, requires_grad=True)]        [0.543]\n",
      "[tensor(-0.26723405, requires_grad=True)]        [0.544]\n",
      "[tensor(-0.26514535, requires_grad=True)]        [0.545]\n",
      "[tensor(-0.26305353, requires_grad=True)]        [0.546]\n",
      "[tensor(-0.26095857, requires_grad=True)]        [0.547]\n",
      "[tensor(-0.25886049, requires_grad=True)]        [0.548]\n",
      "[tensor(-0.25675929, requires_grad=True)]        [0.549]\n",
      "[tensor(-0.25465496, requires_grad=True)]        [0.55]\n",
      "[tensor(-0.25254751, requires_grad=True)]        [0.551]\n",
      "[tensor(-0.25043694, requires_grad=True)]        [0.552]\n",
      "[tensor(-0.24832326, requires_grad=True)]        [0.553]\n",
      "[tensor(-0.24620645, requires_grad=True)]        [0.554]\n",
      "[tensor(-0.24408654, requires_grad=True)]        [0.555]\n",
      "[tensor(-0.24196351, requires_grad=True)]        [0.556]\n",
      "[tensor(-0.23983737, requires_grad=True)]        [0.557]\n",
      "[tensor(-0.23770812, requires_grad=True)]        [0.558]\n",
      "[tensor(-0.23557577, requires_grad=True)]        [0.559]\n",
      "[tensor(-0.23344031, requires_grad=True)]        [0.56]\n",
      "[tensor(-0.23130174, requires_grad=True)]        [0.561]\n",
      "[tensor(-0.22916008, requires_grad=True)]        [0.562]\n",
      "[tensor(-0.22701531, requires_grad=True)]        [0.563]\n",
      "[tensor(-0.22486744, requires_grad=True)]        [0.564]\n",
      "[tensor(-0.22271648, requires_grad=True)]        [0.565]\n",
      "[tensor(-0.22056242, requires_grad=True)]        [0.566]\n",
      "[tensor(-0.21840527, requires_grad=True)]        [0.567]\n",
      "[tensor(-0.21624503, requires_grad=True)]        [0.568]\n",
      "[tensor(-0.2140817, requires_grad=True)]        [0.569]\n",
      "[tensor(-0.21191528, requires_grad=True)]        [0.57]\n",
      "[tensor(-0.20974577, requires_grad=True)]        [0.571]\n",
      "[tensor(-0.20757318, requires_grad=True)]        [0.572]\n",
      "[tensor(-0.20539751, requires_grad=True)]        [0.573]\n",
      "[tensor(-0.20321876, requires_grad=True)]        [0.574]\n",
      "[tensor(-0.20103692, requires_grad=True)]        [0.575]\n",
      "[tensor(-0.19885201, requires_grad=True)]        [0.576]\n",
      "[tensor(-0.19666403, requires_grad=True)]        [0.577]\n",
      "[tensor(-0.19447297, requires_grad=True)]        [0.578]\n",
      "[tensor(-0.19227885, requires_grad=True)]        [0.579]\n",
      "[tensor(-0.19008165, requires_grad=True)]        [0.58]\n",
      "[tensor(-0.18788138, requires_grad=True)]        [0.581]\n",
      "[tensor(-0.18567805, requires_grad=True)]        [0.582]\n",
      "[tensor(-0.18347166, requires_grad=True)]        [0.583]\n",
      "[tensor(-0.1812622, requires_grad=True)]        [0.584]\n",
      "[tensor(-0.17904969, requires_grad=True)]        [0.585]\n",
      "[tensor(-0.17683411, requires_grad=True)]        [0.586]\n",
      "[tensor(-0.17461548, requires_grad=True)]        [0.587]\n",
      "[tensor(-0.1723938, requires_grad=True)]        [0.588]\n",
      "[tensor(-0.17016906, requires_grad=True)]        [0.589]\n",
      "[tensor(-0.16794128, requires_grad=True)]        [0.59]\n",
      "[tensor(-0.16571044, requires_grad=True)]        [0.591]\n",
      "[tensor(-0.16347656, requires_grad=True)]        [0.592]\n",
      "[tensor(-0.16123964, requires_grad=True)]        [0.593]\n",
      "[tensor(-0.15899967, requires_grad=True)]        [0.594]\n",
      "[tensor(-0.15675666, requires_grad=True)]        [0.595]\n",
      "[tensor(-0.15451062, requires_grad=True)]        [0.596]\n",
      "[tensor(-0.15226154, requires_grad=True)]        [0.597]\n",
      "[tensor(-0.15000942, requires_grad=True)]        [0.598]\n",
      "[tensor(-0.14775428, requires_grad=True)]        [0.599]\n",
      "[tensor(-0.1454961, requires_grad=True)]        [0.6]\n",
      "[tensor(-0.1432349, requires_grad=True)]        [0.601]\n",
      "[tensor(-0.14097067, requires_grad=True)]        [0.602]\n",
      "[tensor(-0.13870341, requires_grad=True)]        [0.603]\n",
      "[tensor(-0.13643314, requires_grad=True)]        [0.604]\n",
      "[tensor(-0.13415984, requires_grad=True)]        [0.605]\n",
      "[tensor(-0.13188353, requires_grad=True)]        [0.606]\n",
      "[tensor(-0.1296042, requires_grad=True)]        [0.607]\n",
      "[tensor(-0.12732186, requires_grad=True)]        [0.608]\n",
      "[tensor(-0.12503651, requires_grad=True)]        [0.609]\n",
      "[tensor(-0.12274815, requires_grad=True)]        [0.61]\n",
      "[tensor(-0.12045679, requires_grad=True)]        [0.611]\n",
      "[tensor(-0.11816242, requires_grad=True)]        [0.612]\n",
      "[tensor(-0.11586504, requires_grad=True)]        [0.613]\n",
      "[tensor(-0.11356467, requires_grad=True)]        [0.614]\n",
      "[tensor(-0.1112613, requires_grad=True)]        [0.615]\n",
      "[tensor(-0.10895493, requires_grad=True)]        [0.616]\n",
      "[tensor(-0.10664557, requires_grad=True)]        [0.617]\n",
      "[tensor(-0.10433322, requires_grad=True)]        [0.618]\n",
      "[tensor(-0.10201788, requires_grad=True)]        [0.619]\n",
      "[tensor(-0.09969956, requires_grad=True)]        [0.62]\n",
      "[tensor(-0.09737825, requires_grad=True)]        [0.621]\n",
      "[tensor(-0.09505396, requires_grad=True)]        [0.622]\n",
      "[tensor(-0.09272669, requires_grad=True)]        [0.623]\n",
      "[tensor(-0.09039644, requires_grad=True)]        [0.624]\n",
      "[tensor(-0.08806321, requires_grad=True)]        [0.625]\n",
      "[tensor(-0.08572702, requires_grad=True)]        [0.626]\n",
      "[tensor(-0.08338785, requires_grad=True)]        [0.627]\n",
      "[tensor(-0.08104572, requires_grad=True)]        [0.628]\n",
      "[tensor(-0.07870062, requires_grad=True)]        [0.629]\n",
      "[tensor(-0.07635255, requires_grad=True)]        [0.63]\n",
      "[tensor(-0.07400153, requires_grad=True)]        [0.631]\n",
      "[tensor(-0.07164755, requires_grad=True)]        [0.632]\n",
      "[tensor(-0.06929061, requires_grad=True)]        [0.633]\n",
      "[tensor(-0.06693072, requires_grad=True)]        [0.634]\n",
      "[tensor(-0.06456787, requires_grad=True)]        [0.635]\n",
      "[tensor(-0.06220208, requires_grad=True)]        [0.636]\n",
      "[tensor(-0.05983334, requires_grad=True)]        [0.637]\n",
      "[tensor(-0.05746166, requires_grad=True)]        [0.638]\n",
      "[tensor(-0.05508704, requires_grad=True)]        [0.639]\n",
      "[tensor(-0.05270948, requires_grad=True)]        [0.64]\n",
      "[tensor(-0.05032899, requires_grad=True)]        [0.641]\n",
      "[tensor(-0.04794556, requires_grad=True)]        [0.642]\n",
      "[tensor(-0.0455592, requires_grad=True)]        [0.643]\n",
      "[tensor(-0.04316991, requires_grad=True)]        [0.644]\n",
      "[tensor(-0.04077769, requires_grad=True)]        [0.645]\n",
      "[tensor(-0.03838255, requires_grad=True)]        [0.646]\n",
      "[tensor(-0.0359845, requires_grad=True)]        [0.647]\n",
      "[tensor(-0.03358352, requires_grad=True)]        [0.648]\n",
      "[tensor(-0.03117963, requires_grad=True)]        [0.649]\n",
      "[tensor(-0.02877282, requires_grad=True)]        [0.65]\n",
      "[tensor(-0.02636311, requires_grad=True)]        [0.651]\n",
      "[tensor(-0.02395049, requires_grad=True)]        [0.652]\n",
      "[tensor(-0.02153496, requires_grad=True)]        [0.653]\n",
      "[tensor(-0.01911654, requires_grad=True)]        [0.654]\n",
      "[tensor(-0.01669521, requires_grad=True)]        [0.655]\n",
      "[tensor(-0.01427099, requires_grad=True)]        [0.656]\n",
      "[tensor(-0.01184387, requires_grad=True)]        [0.657]\n",
      "[tensor(-0.00941386, requires_grad=True)]        [0.658]\n",
      "[tensor(-0.00698097, requires_grad=True)]        [0.659]\n",
      "[tensor(-0.00454519, requires_grad=True)]        [0.66]\n",
      "[tensor(-0.00210653, requires_grad=True)]        [0.661]\n",
      "[tensor(0.00033502, requires_grad=True)]        [0.662]\n",
      "[tensor(0.00277943, requires_grad=True)]        [0.663]\n",
      "[tensor(0.00522673, requires_grad=True)]        [0.664]\n",
      "[tensor(0.00767689, requires_grad=True)]        [0.665]\n",
      "[tensor(0.01012992, requires_grad=True)]        [0.666]\n",
      "[tensor(0.01258581, requires_grad=True)]        [0.667]\n",
      "[tensor(0.01504457, requires_grad=True)]        [0.668]\n",
      "[tensor(0.01750619, requires_grad=True)]        [0.669]\n",
      "[tensor(0.01997066, requires_grad=True)]        [0.67]\n",
      "[tensor(0.02243798, requires_grad=True)]        [0.671]\n",
      "[tensor(0.02490816, requires_grad=True)]        [0.672]\n",
      "[tensor(0.02738118, requires_grad=True)]        [0.673]\n",
      "[tensor(0.02985705, requires_grad=True)]        [0.674]\n",
      "[tensor(0.03233575, requires_grad=True)]        [0.675]\n",
      "[tensor(0.0348173, requires_grad=True)]        [0.676]\n",
      "[tensor(0.03730168, requires_grad=True)]        [0.677]\n",
      "[tensor(0.03978889, requires_grad=True)]        [0.678]\n",
      "[tensor(0.04227892, requires_grad=True)]        [0.679]\n",
      "[tensor(0.04477179, requires_grad=True)]        [0.68]\n",
      "[tensor(0.04726747, requires_grad=True)]        [0.681]\n",
      "[tensor(0.04976598, requires_grad=True)]        [0.682]\n",
      "[tensor(0.05226729, requires_grad=True)]        [0.683]\n",
      "[tensor(0.05477143, requires_grad=True)]        [0.684]\n",
      "[tensor(0.05727837, requires_grad=True)]        [0.685]\n",
      "[tensor(0.05978811, requires_grad=True)]        [0.686]\n",
      "[tensor(0.06230066, requires_grad=True)]        [0.687]\n",
      "[tensor(0.06481601, requires_grad=True)]        [0.688]\n",
      "[tensor(0.06733415, requires_grad=True)]        [0.689]\n",
      "[tensor(0.06985508, requires_grad=True)]        [0.69]\n",
      "[tensor(0.0723788, requires_grad=True)]        [0.691]\n",
      "[tensor(0.07490531, requires_grad=True)]        [0.692]\n",
      "[tensor(0.0774346, requires_grad=True)]        [0.693]\n",
      "[tensor(0.07996667, requires_grad=True)]        [0.694]\n",
      "[tensor(0.08250151, requires_grad=True)]        [0.695]\n",
      "[tensor(0.08503913, requires_grad=True)]        [0.696]\n",
      "[tensor(0.08757951, requires_grad=True)]        [0.697]\n",
      "[tensor(0.09012266, requires_grad=True)]        [0.698]\n",
      "[tensor(0.09266856, requires_grad=True)]        [0.699]\n",
      "[tensor(0.09521723, requires_grad=True)]        [0.7]\n",
      "[tensor(0.09776864, requires_grad=True)]        [0.701]\n",
      "[tensor(0.10032281, requires_grad=True)]        [0.702]\n",
      "[tensor(0.10287972, requires_grad=True)]        [0.703]\n",
      "[tensor(0.10543937, requires_grad=True)]        [0.704]\n",
      "[tensor(0.10800177, requires_grad=True)]        [0.705]\n",
      "[tensor(0.11056689, requires_grad=True)]        [0.706]\n",
      "[tensor(0.11313475, requires_grad=True)]        [0.707]\n",
      "[tensor(0.11570534, requires_grad=True)]        [0.708]\n",
      "[tensor(0.11827865, requires_grad=True)]        [0.709]\n",
      "[tensor(0.12085467, requires_grad=True)]        [0.71]\n",
      "[tensor(0.12343342, requires_grad=True)]        [0.711]\n",
      "[tensor(0.12601487, requires_grad=True)]        [0.712]\n",
      "[tensor(0.12859903, requires_grad=True)]        [0.713]\n",
      "[tensor(0.1311859, requires_grad=True)]        [0.714]\n",
      "[tensor(0.13377546, requires_grad=True)]        [0.715]\n",
      "[tensor(0.13636772, requires_grad=True)]        [0.716]\n",
      "[tensor(0.13896267, requires_grad=True)]        [0.717]\n",
      "[tensor(0.14156031, requires_grad=True)]        [0.718]\n",
      "[tensor(0.14416063, requires_grad=True)]        [0.719]\n",
      "[tensor(0.14676363, requires_grad=True)]        [0.72]\n",
      "[tensor(0.1493693, requires_grad=True)]        [0.721]\n",
      "[tensor(0.15197765, requires_grad=True)]        [0.722]\n",
      "[tensor(0.15458866, requires_grad=True)]        [0.723]\n",
      "[tensor(0.15720233, requires_grad=True)]        [0.724]\n",
      "[tensor(0.15981866, requires_grad=True)]        [0.725]\n",
      "[tensor(0.16243764, requires_grad=True)]        [0.726]\n",
      "[tensor(0.16505927, requires_grad=True)]        [0.727]\n",
      "[tensor(0.16768355, requires_grad=True)]        [0.728]\n",
      "[tensor(0.17031047, requires_grad=True)]        [0.729]\n",
      "[tensor(0.17294002, requires_grad=True)]        [0.73]\n",
      "[tensor(0.1755722, requires_grad=True)]        [0.731]\n",
      "[tensor(0.178207, requires_grad=True)]        [0.732]\n",
      "[tensor(0.18084443, requires_grad=True)]        [0.733]\n",
      "[tensor(0.18348448, requires_grad=True)]        [0.734]\n",
      "[tensor(0.18612713, requires_grad=True)]        [0.735]\n",
      "[tensor(0.1887724, requires_grad=True)]        [0.736]\n",
      "[tensor(0.19142027, requires_grad=True)]        [0.737]\n",
      "[tensor(0.19407073, requires_grad=True)]        [0.738]\n",
      "[tensor(0.19672379, requires_grad=True)]        [0.739]\n",
      "[tensor(0.19937944, requires_grad=True)]        [0.74]\n",
      "[tensor(0.20203767, requires_grad=True)]        [0.741]\n",
      "[tensor(0.20469847, requires_grad=True)]        [0.742]\n",
      "[tensor(0.20736185, requires_grad=True)]        [0.743]\n",
      "[tensor(0.2100278, requires_grad=True)]        [0.744]\n",
      "[tensor(0.21269631, requires_grad=True)]        [0.745]\n",
      "[tensor(0.21536738, requires_grad=True)]        [0.746]\n",
      "[tensor(0.21804101, requires_grad=True)]        [0.747]\n",
      "[tensor(0.22071718, requires_grad=True)]        [0.748]\n",
      "[tensor(0.22339589, requires_grad=True)]        [0.749]\n",
      "[tensor(0.22607714, requires_grad=True)]        [0.75]\n",
      "[tensor(0.22876092, requires_grad=True)]        [0.751]\n",
      "[tensor(0.23144723, requires_grad=True)]        [0.752]\n",
      "[tensor(0.23413605, requires_grad=True)]        [0.753]\n",
      "[tensor(0.2368274, requires_grad=True)]        [0.754]\n",
      "[tensor(0.23952125, requires_grad=True)]        [0.755]\n",
      "[tensor(0.24221761, requires_grad=True)]        [0.756]\n",
      "[tensor(0.24491646, requires_grad=True)]        [0.757]\n",
      "[tensor(0.24761781, requires_grad=True)]        [0.758]\n",
      "[tensor(0.25032164, requires_grad=True)]        [0.759]\n",
      "[tensor(0.25302796, requires_grad=True)]        [0.76]\n",
      "[tensor(0.25573675, requires_grad=True)]        [0.761]\n",
      "[tensor(0.25844802, requires_grad=True)]        [0.762]\n",
      "[tensor(0.26116174, requires_grad=True)]        [0.763]\n",
      "[tensor(0.26387792, requires_grad=True)]        [0.764]\n",
      "[tensor(0.26659656, requires_grad=True)]        [0.765]\n",
      "[tensor(0.26931764, requires_grad=True)]        [0.766]\n",
      "[tensor(0.27204116, requires_grad=True)]        [0.767]\n",
      "[tensor(0.27476711, requires_grad=True)]        [0.768]\n",
      "[tensor(0.27749549, requires_grad=True)]        [0.769]\n",
      "[tensor(0.28022629, requires_grad=True)]        [0.77]\n",
      "[tensor(0.2829595, requires_grad=True)]        [0.771]\n",
      "[tensor(0.28569512, requires_grad=True)]        [0.772]\n",
      "[tensor(0.28843314, requires_grad=True)]        [0.773]\n",
      "[tensor(0.29117356, requires_grad=True)]        [0.774]\n",
      "[tensor(0.29391636, requires_grad=True)]        [0.775]\n",
      "[tensor(0.29666155, requires_grad=True)]        [0.776]\n",
      "[tensor(0.29940911, requires_grad=True)]        [0.777]\n",
      "[tensor(0.30215903, requires_grad=True)]        [0.778]\n",
      "[tensor(0.30491132, requires_grad=True)]        [0.779]\n",
      "[tensor(0.30766596, requires_grad=True)]        [0.78]\n",
      "[tensor(0.31042295, requires_grad=True)]        [0.781]\n",
      "[tensor(0.31318227, requires_grad=True)]        [0.782]\n",
      "[tensor(0.31594393, requires_grad=True)]        [0.783]\n",
      "[tensor(0.31870792, requires_grad=True)]        [0.784]\n",
      "[tensor(0.32147422, requires_grad=True)]        [0.785]\n",
      "[tensor(0.32424283, requires_grad=True)]        [0.786]\n",
      "[tensor(0.32701374, requires_grad=True)]        [0.787]\n",
      "[tensor(0.32978695, requires_grad=True)]        [0.788]\n",
      "[tensor(0.33256245, requires_grad=True)]        [0.789]\n",
      "[tensor(0.33534022, requires_grad=True)]        [0.79]\n",
      "[tensor(0.33812027, requires_grad=True)]        [0.791]\n",
      "[tensor(0.34090258, requires_grad=True)]        [0.792]\n",
      "[tensor(0.34368715, requires_grad=True)]        [0.793]\n",
      "[tensor(0.34647396, requires_grad=True)]        [0.794]\n",
      "[tensor(0.34926302, requires_grad=True)]        [0.795]\n",
      "[tensor(0.3520543, requires_grad=True)]        [0.796]\n",
      "[tensor(0.35484781, requires_grad=True)]        [0.797]\n",
      "[tensor(0.35764354, requires_grad=True)]        [0.798]\n",
      "[tensor(0.36044147, requires_grad=True)]        [0.799]\n",
      "[tensor(0.3632416, requires_grad=True)]        [0.8]\n",
      "[tensor(0.36604391, requires_grad=True)]        [0.801]\n",
      "[tensor(0.36884841, requires_grad=True)]        [0.802]\n",
      "[tensor(0.37165508, requires_grad=True)]        [0.803]\n",
      "[tensor(0.37446391, requires_grad=True)]        [0.804]\n",
      "[tensor(0.37727489, requires_grad=True)]        [0.805]\n",
      "[tensor(0.38008802, requires_grad=True)]        [0.806]\n",
      "[tensor(0.38290328, requires_grad=True)]        [0.807]\n",
      "[tensor(0.38572067, requires_grad=True)]        [0.808]\n",
      "[tensor(0.38854017, requires_grad=True)]        [0.809]\n",
      "[tensor(0.39136178, requires_grad=True)]        [0.81]\n",
      "[tensor(0.39418549, requires_grad=True)]        [0.811]\n",
      "[tensor(0.39701128, requires_grad=True)]        [0.812]\n",
      "[tensor(0.39983915, requires_grad=True)]        [0.813]\n",
      "[tensor(0.40266908, requires_grad=True)]        [0.814]\n",
      "[tensor(0.40550107, requires_grad=True)]        [0.815]\n",
      "[tensor(0.40833511, requires_grad=True)]        [0.816]\n",
      "[tensor(0.41117118, requires_grad=True)]        [0.817]\n",
      "[tensor(0.41400928, requires_grad=True)]        [0.818]\n",
      "[tensor(0.41684939, requires_grad=True)]        [0.819]\n",
      "[tensor(0.4196915, requires_grad=True)]        [0.82]\n",
      "[tensor(0.42253561, requires_grad=True)]        [0.821]\n",
      "[tensor(0.42538169, requires_grad=True)]        [0.822]\n",
      "[tensor(0.42822975, requires_grad=True)]        [0.823]\n",
      "[tensor(0.43107976, requires_grad=True)]        [0.824]\n",
      "[tensor(0.43393172, requires_grad=True)]        [0.825]\n",
      "[tensor(0.43678561, requires_grad=True)]        [0.826]\n",
      "[tensor(0.43964143, requires_grad=True)]        [0.827]\n",
      "[tensor(0.44249916, requires_grad=True)]        [0.828]\n",
      "[tensor(0.44535879, requires_grad=True)]        [0.829]\n",
      "[tensor(0.4482203, requires_grad=True)]        [0.83]\n",
      "[tensor(0.45108369, requires_grad=True)]        [0.831]\n",
      "[tensor(0.45394894, requires_grad=True)]        [0.832]\n",
      "[tensor(0.45681604, requires_grad=True)]        [0.833]\n",
      "[tensor(0.45968497, requires_grad=True)]        [0.834]\n",
      "[tensor(0.46255572, requires_grad=True)]        [0.835]\n",
      "[tensor(0.46542829, requires_grad=True)]        [0.836]\n",
      "[tensor(0.46830264, requires_grad=True)]        [0.837]\n",
      "[tensor(0.47117878, requires_grad=True)]        [0.838]\n",
      "[tensor(0.47405669, requires_grad=True)]        [0.839]\n",
      "[tensor(0.47693635, requires_grad=True)]        [0.84]\n",
      "[tensor(0.47981775, requires_grad=True)]        [0.841]\n",
      "[tensor(0.48270087, requires_grad=True)]        [0.842]\n",
      "[tensor(0.4855857, requires_grad=True)]        [0.843]\n",
      "[tensor(0.48847223, requires_grad=True)]        [0.844]\n",
      "[tensor(0.49136044, requires_grad=True)]        [0.845]\n",
      "[tensor(0.49425031, requires_grad=True)]        [0.846]\n",
      "[tensor(0.49714182, requires_grad=True)]        [0.847]\n",
      "[tensor(0.50003497, requires_grad=True)]        [0.848]\n",
      "[tensor(0.50292974, requires_grad=True)]        [0.849]\n",
      "[tensor(0.5058261, requires_grad=True)]        [0.85]\n",
      "[tensor(0.50872405, requires_grad=True)]        [0.851]\n",
      "[tensor(0.51162357, requires_grad=True)]        [0.852]\n",
      "[tensor(0.51452463, requires_grad=True)]        [0.853]\n",
      "[tensor(0.51742723, requires_grad=True)]        [0.854]\n",
      "[tensor(0.52033133, requires_grad=True)]        [0.855]\n",
      "[tensor(0.52323694, requires_grad=True)]        [0.856]\n",
      "[tensor(0.52614402, requires_grad=True)]        [0.857]\n",
      "[tensor(0.52905256, requires_grad=True)]        [0.858]\n",
      "[tensor(0.53196254, requires_grad=True)]        [0.859]\n",
      "[tensor(0.53487394, requires_grad=True)]        [0.86]\n",
      "[tensor(0.53778675, requires_grad=True)]        [0.861]\n",
      "[tensor(0.54070093, requires_grad=True)]        [0.862]\n",
      "[tensor(0.54361648, requires_grad=True)]        [0.863]\n",
      "[tensor(0.54653336, requires_grad=True)]        [0.864]\n",
      "[tensor(0.54945157, requires_grad=True)]        [0.865]\n",
      "[tensor(0.55237108, requires_grad=True)]        [0.866]\n",
      "[tensor(0.55529186, requires_grad=True)]        [0.867]\n",
      "[tensor(0.5582139, requires_grad=True)]        [0.868]\n",
      "[tensor(0.56113717, requires_grad=True)]        [0.869]\n",
      "[tensor(0.56406165, requires_grad=True)]        [0.87]\n",
      "[tensor(0.56698732, requires_grad=True)]        [0.871]\n",
      "[tensor(0.56991415, requires_grad=True)]        [0.872]\n",
      "[tensor(0.57284212, requires_grad=True)]        [0.873]\n",
      "[tensor(0.57577121, requires_grad=True)]        [0.874]\n",
      "[tensor(0.57870138, requires_grad=True)]        [0.875]\n",
      "[tensor(0.58163262, requires_grad=True)]        [0.876]\n",
      "[tensor(0.5845649, requires_grad=True)]        [0.877]\n",
      "[tensor(0.58749819, requires_grad=True)]        [0.878]\n",
      "[tensor(0.59043247, requires_grad=True)]        [0.879]\n",
      "[tensor(0.59336771, requires_grad=True)]        [0.88]\n",
      "[tensor(0.59630388, requires_grad=True)]        [0.881]\n",
      "[tensor(0.59924095, requires_grad=True)]        [0.882]\n",
      "[tensor(0.60217889, requires_grad=True)]        [0.883]\n",
      "[tensor(0.60511767, requires_grad=True)]        [0.884]\n",
      "[tensor(0.60805727, requires_grad=True)]        [0.885]\n",
      "[tensor(0.61099766, requires_grad=True)]        [0.886]\n",
      "[tensor(0.61393879, requires_grad=True)]        [0.887]\n",
      "[tensor(0.61688064, requires_grad=True)]        [0.888]\n",
      "[tensor(0.61982318, requires_grad=True)]        [0.889]\n",
      "[tensor(0.62276637, requires_grad=True)]        [0.89]\n",
      "[tensor(0.62571018, requires_grad=True)]        [0.891]\n",
      "[tensor(0.62865458, requires_grad=True)]        [0.892]\n",
      "[tensor(0.63159952, requires_grad=True)]        [0.893]\n",
      "[tensor(0.63454498, requires_grad=True)]        [0.894]\n",
      "[tensor(0.63749091, requires_grad=True)]        [0.895]\n",
      "[tensor(0.64043727, requires_grad=True)]        [0.896]\n",
      "[tensor(0.64338403, requires_grad=True)]        [0.897]\n",
      "[tensor(0.64633115, requires_grad=True)]        [0.898]\n",
      "[tensor(0.64927859, requires_grad=True)]        [0.899]\n",
      "[tensor(0.6522263, requires_grad=True)]        [0.9]\n",
      "[tensor(0.65517425, requires_grad=True)]        [0.901]\n",
      "[tensor(0.65812238, requires_grad=True)]        [0.902]\n",
      "[tensor(0.66107066, requires_grad=True)]        [0.903]\n",
      "[tensor(0.66401903, requires_grad=True)]        [0.904]\n",
      "[tensor(0.66696746, requires_grad=True)]        [0.905]\n",
      "[tensor(0.66991588, requires_grad=True)]        [0.906]\n",
      "[tensor(0.67286426, requires_grad=True)]        [0.907]\n",
      "[tensor(0.67581255, requires_grad=True)]        [0.908]\n",
      "[tensor(0.67876068, requires_grad=True)]        [0.909]\n",
      "[tensor(0.68170861, requires_grad=True)]        [0.91]\n",
      "[tensor(0.68465628, requires_grad=True)]        [0.911]\n",
      "[tensor(0.68760364, requires_grad=True)]        [0.912]\n",
      "[tensor(0.69055062, requires_grad=True)]        [0.913]\n",
      "[tensor(0.69349718, requires_grad=True)]        [0.914]\n",
      "[tensor(0.69644324, requires_grad=True)]        [0.915]\n",
      "[tensor(0.69938875, requires_grad=True)]        [0.916]\n",
      "[tensor(0.70233363, requires_grad=True)]        [0.917]\n",
      "[tensor(0.70527783, requires_grad=True)]        [0.918]\n",
      "[tensor(0.70822128, requires_grad=True)]        [0.919]\n",
      "[tensor(0.7111639, requires_grad=True)]        [0.92]\n",
      "[tensor(0.71410562, requires_grad=True)]        [0.921]\n",
      "[tensor(0.71704637, requires_grad=True)]        [0.922]\n",
      "[tensor(0.71998607, requires_grad=True)]        [0.923]\n",
      "[tensor(0.72292464, requires_grad=True)]        [0.924]\n",
      "[tensor(0.725862, requires_grad=True)]        [0.925]\n",
      "[tensor(0.72879807, requires_grad=True)]        [0.926]\n",
      "[tensor(0.73173275, requires_grad=True)]        [0.927]\n",
      "[tensor(0.73466596, requires_grad=True)]        [0.928]\n",
      "[tensor(0.73759761, requires_grad=True)]        [0.929]\n",
      "[tensor(0.74052759, requires_grad=True)]        [0.93]\n",
      "[tensor(0.74345581, requires_grad=True)]        [0.931]\n",
      "[tensor(0.74638216, requires_grad=True)]        [0.932]\n",
      "[tensor(0.74930655, requires_grad=True)]        [0.933]\n",
      "[tensor(0.75222884, requires_grad=True)]        [0.934]\n",
      "[tensor(0.75514895, requires_grad=True)]        [0.935]\n",
      "[tensor(0.75806673, requires_grad=True)]        [0.936]\n",
      "[tensor(0.76098207, requires_grad=True)]        [0.937]\n",
      "[tensor(0.76389485, requires_grad=True)]        [0.938]\n",
      "[tensor(0.76680492, requires_grad=True)]        [0.939]\n",
      "[tensor(0.76971215, requires_grad=True)]        [0.94]\n",
      "[tensor(0.7726164, requires_grad=True)]        [0.941]\n",
      "[tensor(0.77551751, requires_grad=True)]        [0.942]\n",
      "[tensor(0.77841533, requires_grad=True)]        [0.943]\n",
      "[tensor(0.78130969, requires_grad=True)]        [0.944]\n",
      "[tensor(0.78420043, requires_grad=True)]        [0.945]\n",
      "[tensor(0.78708736, requires_grad=True)]        [0.946]\n",
      "[tensor(0.78997031, requires_grad=True)]        [0.947]\n",
      "[tensor(0.79284907, requires_grad=True)]        [0.948]\n",
      "[tensor(0.79572344, requires_grad=True)]        [0.949]\n",
      "[tensor(0.79859321, requires_grad=True)]        [0.95]\n",
      "[tensor(0.80145816, requires_grad=True)]        [0.951]\n",
      "[tensor(0.80431804, requires_grad=True)]        [0.952]\n",
      "[tensor(0.80717262, requires_grad=True)]        [0.953]\n",
      "[tensor(0.81002163, requires_grad=True)]        [0.954]\n",
      "[tensor(0.81286481, requires_grad=True)]        [0.955]\n",
      "[tensor(0.81570185, requires_grad=True)]        [0.956]\n",
      "[tensor(0.81853246, requires_grad=True)]        [0.957]\n",
      "[tensor(0.82135631, requires_grad=True)]        [0.958]\n",
      "[tensor(0.82417306, requires_grad=True)]        [0.959]\n",
      "[tensor(0.82698236, requires_grad=True)]        [0.96]\n",
      "[tensor(0.82978381, requires_grad=True)]        [0.961]\n",
      "[tensor(0.83257701, requires_grad=True)]        [0.962]\n",
      "[tensor(0.83536153, requires_grad=True)]        [0.963]\n",
      "[tensor(0.8381369, requires_grad=True)]        [0.964]\n",
      "[tensor(0.84090262, requires_grad=True)]        [0.965]\n",
      "[tensor(0.84365817, requires_grad=True)]        [0.966]\n",
      "[tensor(0.84640298, requires_grad=True)]        [0.967]\n",
      "[tensor(0.84913643, requires_grad=True)]        [0.968]\n",
      "[tensor(0.85185787, requires_grad=True)]        [0.969]\n",
      "[tensor(0.85456659, requires_grad=True)]        [0.97]\n",
      "[tensor(0.85726181, requires_grad=True)]        [0.971]\n",
      "[tensor(0.8599427, requires_grad=True)]        [0.972]\n",
      "[tensor(0.86260834, requires_grad=True)]        [0.973]\n",
      "[tensor(0.86525776, requires_grad=True)]        [0.974]\n",
      "[tensor(0.86788984, requires_grad=True)]        [0.975]\n",
      "[tensor(0.8705034, requires_grad=True)]        [0.976]\n",
      "[tensor(0.87309712, requires_grad=True)]        [0.977]\n",
      "[tensor(0.87566952, requires_grad=True)]        [0.978]\n",
      "[tensor(0.87821898, requires_grad=True)]        [0.979]\n",
      "[tensor(0.88074366, requires_grad=True)]        [0.98]\n",
      "[tensor(0.88324151, requires_grad=True)]        [0.981]\n",
      "[tensor(0.88571021, requires_grad=True)]        [0.982]\n",
      "[tensor(0.88814709, requires_grad=True)]        [0.983]\n",
      "[tensor(0.89054912, requires_grad=True)]        [0.984]\n",
      "[tensor(0.89291276, requires_grad=True)]        [0.985]\n",
      "[tensor(0.8952339, requires_grad=True)]        [0.986]\n",
      "[tensor(0.89750768, requires_grad=True)]        [0.987]\n",
      "[tensor(0.89972828, requires_grad=True)]        [0.988]\n",
      "[tensor(0.90188866, requires_grad=True)]        [0.989]\n",
      "[tensor(0.90398014, requires_grad=True)]        [0.99]\n",
      "[tensor(0.90599183, requires_grad=True)]        [0.991]\n",
      "[tensor(0.90790972, requires_grad=True)]        [0.992]\n",
      "[tensor(0.90971527, requires_grad=True)]        [0.993]\n",
      "[tensor(0.91138308, requires_grad=True)]        [0.994]\n",
      "[tensor(0.91287658, requires_grad=True)]        [0.995]\n",
      "[tensor(0.91413976, requires_grad=True)]        [0.996]\n",
      "[tensor(0.91507842, requires_grad=True)]        [0.997]\n",
      "[tensor(0.91550915, requires_grad=True)]        [0.998]\n",
      "[tensor(0.91495909, requires_grad=True)]        [0.999]\n",
      "[tensor(0.90846017, requires_grad=True)]        [1.]\n",
      "Total cost = [[tensor(0.90846017, requires_grad=True)], [tensor(0.88689037, requires_grad=True)], [tensor(0.87376801, requires_grad=True)], [tensor(0.862062, requires_grad=True)], [tensor(0.85110175, requires_grad=True)], [tensor(0.84062678, requires_grad=True)], [tensor(0.83050316, requires_grad=True)], [tensor(0.82065114, requires_grad=True)], [tensor(0.81101859, requires_grad=True)], [tensor(0.80156924, requires_grad=True)], [tensor(0.7922766, requires_grad=True)], [tensor(0.78312062, requires_grad=True)], [tensor(0.77408568, requires_grad=True)], [tensor(0.76515935, requires_grad=True)], [tensor(0.7563315, requires_grad=True)], [tensor(0.74759377, requires_grad=True)], [tensor(0.73893916, requires_grad=True)], [tensor(0.73036173, requires_grad=True)], [tensor(0.72185638, requires_grad=True)], [tensor(0.71341871, requires_grad=True)], [tensor(0.70504488, requires_grad=True)], [tensor(0.69673152, requires_grad=True)], [tensor(0.68847563, requires_grad=True)], [tensor(0.68027458, requires_grad=True)], [tensor(0.67212597, requires_grad=True)], [tensor(0.66402767, requires_grad=True)], [tensor(0.65597775, requires_grad=True)], [tensor(0.64797447, requires_grad=True)], [tensor(0.64001622, requires_grad=True)], [tensor(0.63210156, requires_grad=True)], [tensor(0.62422914, requires_grad=True)], [tensor(0.61639774, requires_grad=True)], [tensor(0.60860622, requires_grad=True)], [tensor(0.60085354, requires_grad=True)], [tensor(0.59313873, requires_grad=True)], [tensor(0.58546088, requires_grad=True)], [tensor(0.57781916, requires_grad=True)], [tensor(0.57021277, requires_grad=True)], [tensor(0.56264098, requires_grad=True)], [tensor(0.55510312, requires_grad=True)], [tensor(0.54759852, requires_grad=True)], [tensor(0.54012659, requires_grad=True)], [tensor(0.53268674, requires_grad=True)], [tensor(0.52527846, requires_grad=True)], [tensor(0.51790121, requires_grad=True)], [tensor(0.51055452, requires_grad=True)], [tensor(0.50323794, requires_grad=True)], [tensor(0.49595103, requires_grad=True)], [tensor(0.48869338, requires_grad=True)], [tensor(0.4814646, requires_grad=True)], [tensor(0.47426431, requires_grad=True)], [tensor(0.46709217, requires_grad=True)], [tensor(0.45994783, requires_grad=True)], [tensor(0.45283098, requires_grad=True)], [tensor(0.4457413, requires_grad=True)], [tensor(0.43867849, requires_grad=True)], [tensor(0.43164229, requires_grad=True)], [tensor(0.42463241, requires_grad=True)], [tensor(0.41764859, requires_grad=True)], [tensor(0.4106906, requires_grad=True)], [tensor(0.40375818, requires_grad=True)], [tensor(0.39685111, requires_grad=True)], [tensor(0.38996917, requires_grad=True)], [tensor(0.38311214, requires_grad=True)], [tensor(0.37627983, requires_grad=True)], [tensor(0.36947203, requires_grad=True)], [tensor(0.36268855, requires_grad=True)], [tensor(0.35592921, requires_grad=True)], [tensor(0.34919383, requires_grad=True)], [tensor(0.34248225, requires_grad=True)], [tensor(0.33579429, requires_grad=True)], [tensor(0.32912979, requires_grad=True)], [tensor(0.32248861, requires_grad=True)], [tensor(0.31587059, requires_grad=True)], [tensor(0.30927558, requires_grad=True)], [tensor(0.30270345, requires_grad=True)], [tensor(0.29615406, requires_grad=True)], [tensor(0.28962727, requires_grad=True)], [tensor(0.28312297, requires_grad=True)], [tensor(0.27664102, requires_grad=True)], [tensor(0.2701813, requires_grad=True)], [tensor(0.26374369, requires_grad=True)], [tensor(0.25732809, requires_grad=True)], [tensor(0.25093438, requires_grad=True)], [tensor(0.24456245, requires_grad=True)], [tensor(0.2382122, requires_grad=True)], [tensor(0.23188353, requires_grad=True)], [tensor(0.22557633, requires_grad=True)], [tensor(0.21929051, requires_grad=True)], [tensor(0.21302598, requires_grad=True)], [tensor(0.20678264, requires_grad=True)], [tensor(0.2005604, requires_grad=True)], [tensor(0.19435917, requires_grad=True)], [tensor(0.18817888, requires_grad=True)], [tensor(0.18201943, requires_grad=True)], [tensor(0.17588075, requires_grad=True)], [tensor(0.16976275, requires_grad=True)], [tensor(0.16366536, requires_grad=True)], [tensor(0.15758851, requires_grad=True)], [tensor(0.15153211, requires_grad=True)], [tensor(0.1454961, requires_grad=True)], [tensor(0.1394804, requires_grad=True)], [tensor(0.13348495, requires_grad=True)], [tensor(0.12750968, requires_grad=True)], [tensor(0.12155452, requires_grad=True)], [tensor(0.11561941, requires_grad=True)], [tensor(0.10970428, requires_grad=True)], [tensor(0.10380907, requires_grad=True)], [tensor(0.09793372, requires_grad=True)], [tensor(0.09207818, requires_grad=True)], [tensor(0.08624237, requires_grad=True)], [tensor(0.08042625, requires_grad=True)], [tensor(0.07462976, requires_grad=True)], [tensor(0.06885284, requires_grad=True)], [tensor(0.06309544, requires_grad=True)], [tensor(0.05735751, requires_grad=True)], [tensor(0.051639, requires_grad=True)], [tensor(0.04593985, requires_grad=True)], [tensor(0.04026001, requires_grad=True)], [tensor(0.03459943, requires_grad=True)], [tensor(0.02895808, requires_grad=True)], [tensor(0.02333589, requires_grad=True)], [tensor(0.01773282, requires_grad=True)], [tensor(0.01214883, requires_grad=True)], [tensor(0.00658388, requires_grad=True)], [tensor(0.00103791, requires_grad=True)], [tensor(-0.00448912, requires_grad=True)], [tensor(-0.00999724, requires_grad=True)], [tensor(-0.01548651, requires_grad=True)], [tensor(-0.02095695, requires_grad=True)], [tensor(-0.02640862, requires_grad=True)], [tensor(-0.03184155, requires_grad=True)], [tensor(-0.03725578, requires_grad=True)], [tensor(-0.04265135, requires_grad=True)], [tensor(-0.04802829, requires_grad=True)], [tensor(-0.05338666, requires_grad=True)], [tensor(-0.05872647, requires_grad=True)], [tensor(-0.06404777, requires_grad=True)], [tensor(-0.0693506, requires_grad=True)], [tensor(-0.07463498, requires_grad=True)], [tensor(-0.07990096, requires_grad=True)], [tensor(-0.08514857, requires_grad=True)], [tensor(-0.09037783, requires_grad=True)], [tensor(-0.09558879, requires_grad=True)], [tensor(-0.10078148, requires_grad=True)], [tensor(-0.10595593, requires_grad=True)], [tensor(-0.11111216, requires_grad=True)], [tensor(-0.11625022, requires_grad=True)], [tensor(-0.12137013, requires_grad=True)], [tensor(-0.12647193, requires_grad=True)], [tensor(-0.13155563, requires_grad=True)], [tensor(-0.13662128, requires_grad=True)], [tensor(-0.1416689, requires_grad=True)], [tensor(-0.14669852, requires_grad=True)], [tensor(-0.15171017, requires_grad=True)], [tensor(-0.15670387, requires_grad=True)], [tensor(-0.16167966, requires_grad=True)], [tensor(-0.16663756, requires_grad=True)], [tensor(-0.1715776, requires_grad=True)], [tensor(-0.1764998, requires_grad=True)], [tensor(-0.1814042, requires_grad=True)], [tensor(-0.18629081, requires_grad=True)], [tensor(-0.19115966, requires_grad=True)], [tensor(-0.19601078, requires_grad=True)], [tensor(-0.20084419, requires_grad=True)], [tensor(-0.20565992, requires_grad=True)], [tensor(-0.21045799, requires_grad=True)], [tensor(-0.21523842, requires_grad=True)], [tensor(-0.22000125, requires_grad=True)], [tensor(-0.22474648, requires_grad=True)], [tensor(-0.22947415, requires_grad=True)], [tensor(-0.23418428, requires_grad=True)], [tensor(-0.23887689, requires_grad=True)], [tensor(-0.24355201, requires_grad=True)], [tensor(-0.24820964, requires_grad=True)], [tensor(-0.25284983, requires_grad=True)], [tensor(-0.25747259, requires_grad=True)], [tensor(-0.26207793, requires_grad=True)], [tensor(-0.26666589, requires_grad=True)], [tensor(-0.27123648, requires_grad=True)], [tensor(-0.27578972, requires_grad=True)], [tensor(-0.28032563, requires_grad=True)], [tensor(-0.28484424, requires_grad=True)], [tensor(-0.28934556, requires_grad=True)], [tensor(-0.29382962, requires_grad=True)], [tensor(-0.29829642, requires_grad=True)], [tensor(-0.302746, requires_grad=True)], [tensor(-0.30717838, requires_grad=True)], [tensor(-0.31159356, requires_grad=True)], [tensor(-0.31599157, requires_grad=True)], [tensor(-0.32037243, requires_grad=True)], [tensor(-0.32473615, requires_grad=True)], [tensor(-0.32908276, requires_grad=True)], [tensor(-0.33341227, requires_grad=True)], [tensor(-0.3377247, requires_grad=True)], [tensor(-0.34202007, requires_grad=True)], [tensor(-0.3462984, requires_grad=True)], [tensor(-0.3505597, requires_grad=True)], [tensor(-0.35480398, requires_grad=True)], [tensor(-0.35903128, requires_grad=True)], [tensor(-0.3632416, requires_grad=True)], [tensor(-0.36743496, requires_grad=True)], [tensor(-0.37161137, requires_grad=True)], [tensor(-0.37577086, requires_grad=True)], [tensor(-0.37991344, requires_grad=True)], [tensor(-0.38403913, requires_grad=True)], [tensor(-0.38814793, requires_grad=True)], [tensor(-0.39223988, requires_grad=True)], [tensor(-0.39631497, requires_grad=True)], [tensor(-0.40037324, requires_grad=True)], [tensor(-0.40441469, requires_grad=True)], [tensor(-0.40843934, requires_grad=True)], [tensor(-0.4124472, requires_grad=True)], [tensor(-0.4164383, requires_grad=True)], [tensor(-0.42041263, requires_grad=True)], [tensor(-0.42437023, requires_grad=True)], [tensor(-0.4283111, requires_grad=True)], [tensor(-0.43223525, requires_grad=True)], [tensor(-0.43614271, requires_grad=True)], [tensor(-0.44003349, requires_grad=True)], [tensor(-0.4439076, requires_grad=True)], [tensor(-0.44776505, requires_grad=True)], [tensor(-0.45160586, requires_grad=True)], [tensor(-0.45543004, requires_grad=True)], [tensor(-0.45923761, requires_grad=True)], [tensor(-0.46302858, requires_grad=True)], [tensor(-0.46680296, requires_grad=True)], [tensor(-0.47056077, requires_grad=True)], [tensor(-0.47430202, requires_grad=True)], [tensor(-0.47802672, requires_grad=True)], [tensor(-0.48173488, requires_grad=True)], [tensor(-0.48542653, requires_grad=True)], [tensor(-0.48910166, requires_grad=True)], [tensor(-0.4927603, requires_grad=True)], [tensor(-0.49640246, requires_grad=True)], [tensor(-0.50002815, requires_grad=True)], [tensor(-0.50363738, requires_grad=True)], [tensor(-0.50723016, requires_grad=True)], [tensor(-0.51080651, requires_grad=True)], [tensor(-0.51436644, requires_grad=True)], [tensor(-0.51790996, requires_grad=True)], [tensor(-0.52143708, requires_grad=True)], [tensor(-0.52494782, requires_grad=True)], [tensor(-0.52844218, requires_grad=True)], [tensor(-0.53192019, requires_grad=True)], [tensor(-0.53538184, requires_grad=True)], [tensor(-0.53882715, requires_grad=True)], [tensor(-0.54225614, requires_grad=True)], [tensor(-0.54566881, requires_grad=True)], [tensor(-0.54906518, requires_grad=True)], [tensor(-0.55244526, requires_grad=True)], [tensor(-0.55580905, requires_grad=True)], [tensor(-0.55915658, requires_grad=True)], [tensor(-0.56248784, requires_grad=True)], [tensor(-0.56580286, requires_grad=True)], [tensor(-0.56910164, requires_grad=True)], [tensor(-0.57238419, requires_grad=True)], [tensor(-0.57565053, requires_grad=True)], [tensor(-0.57890066, requires_grad=True)], [tensor(-0.5821346, requires_grad=True)], [tensor(-0.58535236, requires_grad=True)], [tensor(-0.58855394, requires_grad=True)], [tensor(-0.59173936, requires_grad=True)], [tensor(-0.59490862, requires_grad=True)], [tensor(-0.59806175, requires_grad=True)], [tensor(-0.60119874, requires_grad=True)], [tensor(-0.60431961, requires_grad=True)], [tensor(-0.60742437, requires_grad=True)], [tensor(-0.61051303, requires_grad=True)], [tensor(-0.61358559, requires_grad=True)], [tensor(-0.61664208, requires_grad=True)], [tensor(-0.61968249, requires_grad=True)], [tensor(-0.62270684, requires_grad=True)], [tensor(-0.62571514, requires_grad=True)], [tensor(-0.6287074, requires_grad=True)], [tensor(-0.63168362, requires_grad=True)], [tensor(-0.63464382, requires_grad=True)], [tensor(-0.63758801, requires_grad=True)], [tensor(-0.6405162, requires_grad=True)], [tensor(-0.64342839, requires_grad=True)], [tensor(-0.64632459, requires_grad=True)], [tensor(-0.64920482, requires_grad=True)], [tensor(-0.65206908, requires_grad=True)], [tensor(-0.65491739, requires_grad=True)], [tensor(-0.65774974, requires_grad=True)], [tensor(-0.66056616, requires_grad=True)], [tensor(-0.66336665, requires_grad=True)], [tensor(-0.66615122, requires_grad=True)], [tensor(-0.66891987, requires_grad=True)], [tensor(-0.67167263, requires_grad=True)], [tensor(-0.67440949, requires_grad=True)], [tensor(-0.67713046, requires_grad=True)], [tensor(-0.67983556, requires_grad=True)], [tensor(-0.68252479, requires_grad=True)], [tensor(-0.68519816, requires_grad=True)], [tensor(-0.68785569, requires_grad=True)], [tensor(-0.69049737, requires_grad=True)], [tensor(-0.69312322, requires_grad=True)], [tensor(-0.69573324, requires_grad=True)], [tensor(-0.69832745, requires_grad=True)], [tensor(-0.70090585, requires_grad=True)], [tensor(-0.70346846, requires_grad=True)], [tensor(-0.70601527, requires_grad=True)], [tensor(-0.7085463, requires_grad=True)], [tensor(-0.71106156, requires_grad=True)], [tensor(-0.71356105, requires_grad=True)], [tensor(-0.71604478, requires_grad=True)], [tensor(-0.71851277, requires_grad=True)], [tensor(-0.72096502, requires_grad=True)], [tensor(-0.72340153, requires_grad=True)], [tensor(-0.72582232, requires_grad=True)], [tensor(-0.72822739, requires_grad=True)], [tensor(-0.73061675, requires_grad=True)], [tensor(-0.73299042, requires_grad=True)], [tensor(-0.73534839, requires_grad=True)], [tensor(-0.73769067, requires_grad=True)], [tensor(-0.74001728, requires_grad=True)], [tensor(-0.74232822, requires_grad=True)], [tensor(-0.7446235, requires_grad=True)], [tensor(-0.74690313, requires_grad=True)], [tensor(-0.74916711, requires_grad=True)], [tensor(-0.75141545, requires_grad=True)], [tensor(-0.75364816, requires_grad=True)], [tensor(-0.75586525, requires_grad=True)], [tensor(-0.75806673, requires_grad=True)], [tensor(-0.7602526, requires_grad=True)], [tensor(-0.76242287, requires_grad=True)], [tensor(-0.76457754, requires_grad=True)], [tensor(-0.76671664, requires_grad=True)], [tensor(-0.76884015, requires_grad=True)], [tensor(-0.7709481, requires_grad=True)], [tensor(-0.77304048, requires_grad=True)], [tensor(-0.77511731, requires_grad=True)], [tensor(-0.77717859, requires_grad=True)], [tensor(-0.77922433, requires_grad=True)], [tensor(-0.78125453, requires_grad=True)], [tensor(-0.78326922, requires_grad=True)], [tensor(-0.78526838, requires_grad=True)], [tensor(-0.78725203, requires_grad=True)], [tensor(-0.78922018, requires_grad=True)], [tensor(-0.79117283, requires_grad=True)], [tensor(-0.79310999, requires_grad=True)], [tensor(-0.79503167, requires_grad=True)], [tensor(-0.79693788, requires_grad=True)], [tensor(-0.79882861, requires_grad=True)], [tensor(-0.80070389, requires_grad=True)], [tensor(-0.80256371, requires_grad=True)], [tensor(-0.80440808, requires_grad=True)], [tensor(-0.80623701, requires_grad=True)], [tensor(-0.80805051, requires_grad=True)], [tensor(-0.80984858, requires_grad=True)], [tensor(-0.81163123, requires_grad=True)], [tensor(-0.81339847, requires_grad=True)], [tensor(-0.81515031, requires_grad=True)], [tensor(-0.81688674, requires_grad=True)], [tensor(-0.81860779, requires_grad=True)], [tensor(-0.82031345, requires_grad=True)], [tensor(-0.82200372, requires_grad=True)], [tensor(-0.82367863, requires_grad=True)], [tensor(-0.82533817, requires_grad=True)], [tensor(-0.82698236, requires_grad=True)], [tensor(-0.82861119, requires_grad=True)], [tensor(-0.83022468, requires_grad=True)], [tensor(-0.83182283, requires_grad=True)], [tensor(-0.83340564, requires_grad=True)], [tensor(-0.83497313, requires_grad=True)], [tensor(-0.83652531, requires_grad=True)], [tensor(-0.83806217, requires_grad=True)], [tensor(-0.83958372, requires_grad=True)], [tensor(-0.84108998, requires_grad=True)], [tensor(-0.84258094, requires_grad=True)], [tensor(-0.84405662, requires_grad=True)], [tensor(-0.84551702, requires_grad=True)], [tensor(-0.84696215, requires_grad=True)], [tensor(-0.848392, requires_grad=True)], [tensor(-0.8498066, requires_grad=True)], [tensor(-0.85120595, requires_grad=True)], [tensor(-0.85259005, requires_grad=True)], [tensor(-0.8539589, requires_grad=True)], [tensor(-0.85531252, requires_grad=True)], [tensor(-0.85665092, requires_grad=True)], [tensor(-0.85797409, requires_grad=True)], [tensor(-0.85928205, requires_grad=True)], [tensor(-0.86057479, requires_grad=True)], [tensor(-0.86185234, requires_grad=True)], [tensor(-0.86311468, requires_grad=True)], [tensor(-0.86436184, requires_grad=True)], [tensor(-0.86559381, requires_grad=True)], [tensor(-0.8668106, requires_grad=True)], [tensor(-0.86801223, requires_grad=True)], [tensor(-0.86919868, requires_grad=True)], [tensor(-0.87036998, requires_grad=True)], [tensor(-0.87152612, requires_grad=True)], [tensor(-0.87266712, requires_grad=True)], [tensor(-0.87379297, requires_grad=True)], [tensor(-0.87490369, requires_grad=True)], [tensor(-0.87599928, requires_grad=True)], [tensor(-0.87707975, requires_grad=True)], [tensor(-0.8781451, requires_grad=True)], [tensor(-0.87919534, requires_grad=True)], [tensor(-0.88023047, requires_grad=True)], [tensor(-0.88125051, requires_grad=True)], [tensor(-0.88225545, requires_grad=True)], [tensor(-0.88324531, requires_grad=True)], [tensor(-0.88422009, requires_grad=True)], [tensor(-0.88517979, requires_grad=True)], [tensor(-0.88612442, requires_grad=True)], [tensor(-0.88705399, requires_grad=True)], [tensor(-0.88796851, requires_grad=True)], [tensor(-0.88886797, requires_grad=True)], [tensor(-0.88975239, requires_grad=True)], [tensor(-0.89062177, requires_grad=True)], [tensor(-0.89147611, requires_grad=True)], [tensor(-0.89231543, requires_grad=True)], [tensor(-0.89313973, requires_grad=True)], [tensor(-0.89394901, requires_grad=True)], [tensor(-0.89474328, requires_grad=True)], [tensor(-0.89552255, requires_grad=True)], [tensor(-0.89628682, requires_grad=True)], [tensor(-0.8970361, requires_grad=True)], [tensor(-0.89777039, requires_grad=True)], [tensor(-0.89848971, requires_grad=True)], [tensor(-0.89919404, requires_grad=True)], [tensor(-0.89988341, requires_grad=True)], [tensor(-0.90055782, requires_grad=True)], [tensor(-0.90121727, requires_grad=True)], [tensor(-0.90186176, requires_grad=True)], [tensor(-0.90249131, requires_grad=True)], [tensor(-0.90310593, requires_grad=True)], [tensor(-0.9037056, requires_grad=True)], [tensor(-0.90429035, requires_grad=True)], [tensor(-0.90486018, requires_grad=True)], [tensor(-0.90541509, requires_grad=True)], [tensor(-0.90595508, requires_grad=True)], [tensor(-0.90648018, requires_grad=True)], [tensor(-0.90699037, requires_grad=True)], [tensor(-0.90748567, requires_grad=True)], [tensor(-0.90796607, requires_grad=True)], [tensor(-0.9084316, requires_grad=True)], [tensor(-0.90888225, requires_grad=True)], [tensor(-0.90931803, requires_grad=True)], [tensor(-0.90973894, requires_grad=True)], [tensor(-0.91014499, requires_grad=True)], [tensor(-0.91053618, requires_grad=True)], [tensor(-0.91091253, requires_grad=True)], [tensor(-0.91127404, requires_grad=True)], [tensor(-0.9116207, requires_grad=True)], [tensor(-0.91195254, requires_grad=True)], [tensor(-0.91226954, requires_grad=True)], [tensor(-0.91257173, requires_grad=True)], [tensor(-0.9128591, requires_grad=True)], [tensor(-0.91313166, requires_grad=True)], [tensor(-0.91338942, requires_grad=True)], [tensor(-0.91363237, requires_grad=True)], [tensor(-0.91386054, requires_grad=True)], [tensor(-0.91407392, requires_grad=True)], [tensor(-0.91427251, requires_grad=True)], [tensor(-0.91445633, requires_grad=True)], [tensor(-0.91462538, requires_grad=True)], [tensor(-0.91477966, requires_grad=True)], [tensor(-0.91491918, requires_grad=True)], [tensor(-0.91504395, requires_grad=True)], [tensor(-0.91515397, requires_grad=True)], [tensor(-0.91524925, requires_grad=True)], [tensor(-0.91532979, requires_grad=True)], [tensor(-0.91539559, requires_grad=True)], [tensor(-0.91544667, requires_grad=True)], [tensor(-0.91548303, requires_grad=True)], [tensor(-0.91550467, requires_grad=True)], [tensor(-0.91551161, requires_grad=True)], [tensor(-0.91550384, requires_grad=True)], [tensor(-0.91548136, requires_grad=True)], [tensor(-0.9154442, requires_grad=True)], [tensor(-0.91539235, requires_grad=True)], [tensor(-0.91532581, requires_grad=True)], [tensor(-0.9152446, requires_grad=True)], [tensor(-0.91514871, requires_grad=True)], [tensor(-0.91503816, requires_grad=True)], [tensor(-0.91491295, requires_grad=True)], [tensor(-0.91477309, requires_grad=True)], [tensor(-0.91461857, requires_grad=True)], [tensor(-0.91444941, requires_grad=True)], [tensor(-0.91426561, requires_grad=True)], [tensor(-0.91406717, requires_grad=True)], [tensor(-0.91385411, requires_grad=True)], [tensor(-0.91362643, requires_grad=True)], [tensor(-0.91338413, requires_grad=True)], [tensor(-0.91312722, requires_grad=True)], [tensor(-0.9128557, requires_grad=True)], [tensor(-0.91256958, requires_grad=True)], [tensor(-0.91226886, requires_grad=True)], [tensor(-0.91195356, requires_grad=True)], [tensor(-0.91162367, requires_grad=True)], [tensor(-0.9112792, requires_grad=True)], [tensor(-0.91092016, requires_grad=True)], [tensor(-0.91054655, requires_grad=True)], [tensor(-0.91015838, requires_grad=True)], [tensor(-0.90975565, requires_grad=True)], [tensor(-0.90933837, requires_grad=True)], [tensor(-0.90890654, requires_grad=True)], [tensor(-0.90846017, requires_grad=True)], [tensor(-0.90799927, requires_grad=True)], [tensor(-0.90752384, requires_grad=True)], [tensor(-0.90703388, requires_grad=True)], [tensor(-0.9065294, requires_grad=True)], [tensor(-0.90601041, requires_grad=True)], [tensor(-0.90547691, requires_grad=True)], [tensor(-0.90492891, requires_grad=True)], [tensor(-0.90436642, requires_grad=True)], [tensor(-0.90378943, requires_grad=True)], [tensor(-0.90319795, requires_grad=True)], [tensor(-0.90259199, requires_grad=True)], [tensor(-0.90197156, requires_grad=True)], [tensor(-0.90133666, requires_grad=True)], [tensor(-0.90068729, requires_grad=True)], [tensor(-0.90002346, requires_grad=True)], [tensor(-0.89934518, requires_grad=True)], [tensor(-0.89865245, requires_grad=True)], [tensor(-0.89794528, requires_grad=True)], [tensor(-0.89722367, requires_grad=True)], [tensor(-0.89648763, requires_grad=True)], [tensor(-0.89573717, requires_grad=True)], [tensor(-0.89497228, requires_grad=True)], [tensor(-0.89419298, requires_grad=True)], [tensor(-0.89339926, requires_grad=True)], [tensor(-0.89259115, requires_grad=True)], [tensor(-0.89176863, requires_grad=True)], [tensor(-0.89093172, requires_grad=True)], [tensor(-0.89008042, requires_grad=True)], [tensor(-0.88921474, requires_grad=True)], [tensor(-0.88833469, requires_grad=True)], [tensor(-0.88744026, requires_grad=True)], [tensor(-0.88653146, requires_grad=True)], [tensor(-0.88560831, requires_grad=True)], [tensor(-0.8846708, requires_grad=True)], [tensor(-0.88371894, requires_grad=True)], [tensor(-0.88275273, requires_grad=True)], [tensor(-0.88177219, requires_grad=True)], [tensor(-0.88077731, requires_grad=True)], [tensor(-0.87976811, requires_grad=True)], [tensor(-0.87874458, requires_grad=True)], [tensor(-0.87770674, requires_grad=True)], [tensor(-0.87665459, requires_grad=True)], [tensor(-0.87558813, requires_grad=True)], [tensor(-0.87450737, requires_grad=True)], [tensor(-0.87341232, requires_grad=True)], [tensor(-0.87230298, requires_grad=True)], [tensor(-0.87117936, requires_grad=True)], [tensor(-0.87004146, requires_grad=True)], [tensor(-0.86888928, requires_grad=True)], [tensor(-0.86772284, requires_grad=True)], [tensor(-0.86654214, requires_grad=True)], [tensor(-0.86534718, requires_grad=True)], [tensor(-0.86413798, requires_grad=True)], [tensor(-0.86291453, requires_grad=True)], [tensor(-0.86167684, requires_grad=True)], [tensor(-0.86042492, requires_grad=True)], [tensor(-0.85915877, requires_grad=True)], [tensor(-0.8578784, requires_grad=True)], [tensor(-0.85658381, requires_grad=True)], [tensor(-0.85527502, requires_grad=True)], [tensor(-0.85395201, requires_grad=True)], [tensor(-0.85261481, requires_grad=True)], [tensor(-0.85126342, requires_grad=True)], [tensor(-0.84989784, requires_grad=True)], [tensor(-0.84851807, requires_grad=True)], [tensor(-0.84712413, requires_grad=True)], [tensor(-0.84571602, requires_grad=True)], [tensor(-0.84429374, requires_grad=True)], [tensor(-0.84285731, requires_grad=True)], [tensor(-0.84140672, requires_grad=True)], [tensor(-0.83994198, requires_grad=True)], [tensor(-0.8384631, requires_grad=True)], [tensor(-0.83697008, requires_grad=True)], [tensor(-0.83546294, requires_grad=True)], [tensor(-0.83394167, requires_grad=True)], [tensor(-0.83240627, requires_grad=True)], [tensor(-0.83085677, requires_grad=True)], [tensor(-0.82929316, requires_grad=True)], [tensor(-0.82771544, requires_grad=True)], [tensor(-0.82612363, requires_grad=True)], [tensor(-0.82451773, requires_grad=True)], [tensor(-0.82289775, requires_grad=True)], [tensor(-0.82126368, requires_grad=True)], [tensor(-0.81961555, requires_grad=True)], [tensor(-0.81795334, requires_grad=True)], [tensor(-0.81627708, requires_grad=True)], [tensor(-0.81458676, requires_grad=True)], [tensor(-0.81288239, requires_grad=True)], [tensor(-0.81116397, requires_grad=True)], [tensor(-0.80943152, requires_grad=True)], [tensor(-0.80768504, requires_grad=True)], [tensor(-0.80592453, requires_grad=True)], [tensor(-0.80415, requires_grad=True)], [tensor(-0.80236146, requires_grad=True)], [tensor(-0.80055891, requires_grad=True)], [tensor(-0.79874236, requires_grad=True)], [tensor(-0.79691181, requires_grad=True)], [tensor(-0.79506727, requires_grad=True)], [tensor(-0.79320875, requires_grad=True)], [tensor(-0.79133625, requires_grad=True)], [tensor(-0.78944977, requires_grad=True)], [tensor(-0.78754933, requires_grad=True)], [tensor(-0.78563494, requires_grad=True)], [tensor(-0.78370658, requires_grad=True)], [tensor(-0.78176428, requires_grad=True)], [tensor(-0.77980804, requires_grad=True)], [tensor(-0.77783786, requires_grad=True)], [tensor(-0.77585376, requires_grad=True)], [tensor(-0.77385572, requires_grad=True)], [tensor(-0.77184378, requires_grad=True)], [tensor(-0.76981792, requires_grad=True)], [tensor(-0.76777815, requires_grad=True)], [tensor(-0.76572449, requires_grad=True)], [tensor(-0.76365693, requires_grad=True)], [tensor(-0.76157549, requires_grad=True)], [tensor(-0.75948017, requires_grad=True)], [tensor(-0.75737097, requires_grad=True)], [tensor(-0.75524791, requires_grad=True)], [tensor(-0.75311099, requires_grad=True)], [tensor(-0.75096021, requires_grad=True)], [tensor(-0.74879558, requires_grad=True)], [tensor(-0.74661711, requires_grad=True)], [tensor(-0.7444248, requires_grad=True)], [tensor(-0.74221866, requires_grad=True)], [tensor(-0.7399987, requires_grad=True)], [tensor(-0.73776492, requires_grad=True)], [tensor(-0.73551734, requires_grad=True)], [tensor(-0.73325594, requires_grad=True)], [tensor(-0.73098075, requires_grad=True)], [tensor(-0.72869177, requires_grad=True)], [tensor(-0.72638901, requires_grad=True)], [tensor(-0.72407246, requires_grad=True)], [tensor(-0.72174215, requires_grad=True)], [tensor(-0.71939807, requires_grad=True)], [tensor(-0.71704023, requires_grad=True)], [tensor(-0.71466864, requires_grad=True)], [tensor(-0.7122833, requires_grad=True)], [tensor(-0.70988422, requires_grad=True)], [tensor(-0.70747141, requires_grad=True)], [tensor(-0.70504488, requires_grad=True)], [tensor(-0.70260463, requires_grad=True)], [tensor(-0.70015066, requires_grad=True)], [tensor(-0.69768299, requires_grad=True)], [tensor(-0.69520162, requires_grad=True)], [tensor(-0.69270656, requires_grad=True)], [tensor(-0.69019781, requires_grad=True)], [tensor(-0.68767538, requires_grad=True)], [tensor(-0.68513929, requires_grad=True)], [tensor(-0.68258952, requires_grad=True)], [tensor(-0.6800261, requires_grad=True)], [tensor(-0.67744903, requires_grad=True)], [tensor(-0.67485832, requires_grad=True)], [tensor(-0.67225396, requires_grad=True)], [tensor(-0.66963598, requires_grad=True)], [tensor(-0.66700437, requires_grad=True)], [tensor(-0.66435915, requires_grad=True)], [tensor(-0.66170031, requires_grad=True)], [tensor(-0.65902788, requires_grad=True)], [tensor(-0.65634185, requires_grad=True)], [tensor(-0.65364223, requires_grad=True)], [tensor(-0.65092903, requires_grad=True)], [tensor(-0.64820226, requires_grad=True)], [tensor(-0.64546191, requires_grad=True)], [tensor(-0.64270801, requires_grad=True)], [tensor(-0.63994056, requires_grad=True)], [tensor(-0.63715956, requires_grad=True)], [tensor(-0.63436503, requires_grad=True)], [tensor(-0.63155696, requires_grad=True)], [tensor(-0.62873537, requires_grad=True)], [tensor(-0.62590027, requires_grad=True)], [tensor(-0.62305165, requires_grad=True)], [tensor(-0.62018954, requires_grad=True)], [tensor(-0.61731393, requires_grad=True)], [tensor(-0.61442484, requires_grad=True)], [tensor(-0.61152226, requires_grad=True)], [tensor(-0.60860622, requires_grad=True)], [tensor(-0.60567671, requires_grad=True)], [tensor(-0.60273375, requires_grad=True)], [tensor(-0.59977734, requires_grad=True)], [tensor(-0.59680749, requires_grad=True)], [tensor(-0.5938242, requires_grad=True)], [tensor(-0.59082749, requires_grad=True)], [tensor(-0.58781736, requires_grad=True)], [tensor(-0.58479382, requires_grad=True)], [tensor(-0.58175688, requires_grad=True)], [tensor(-0.57870655, requires_grad=True)], [tensor(-0.57564283, requires_grad=True)], [tensor(-0.57256573, requires_grad=True)], [tensor(-0.56947526, requires_grad=True)], [tensor(-0.56637143, requires_grad=True)], [tensor(-0.56325425, requires_grad=True)], [tensor(-0.56012372, requires_grad=True)], [tensor(-0.55697985, requires_grad=True)], [tensor(-0.55382265, requires_grad=True)], [tensor(-0.55065213, requires_grad=True)], [tensor(-0.54746829, requires_grad=True)], [tensor(-0.54427115, requires_grad=True)], [tensor(-0.54106072, requires_grad=True)], [tensor(-0.53783699, requires_grad=True)], [tensor(-0.53459998, requires_grad=True)], [tensor(-0.5313497, requires_grad=True)], [tensor(-0.52808616, requires_grad=True)], [tensor(-0.52480937, requires_grad=True)], [tensor(-0.52151932, requires_grad=True)], [tensor(-0.51821604, requires_grad=True)], [tensor(-0.51489953, requires_grad=True)], [tensor(-0.5115698, requires_grad=True)], [tensor(-0.50822685, requires_grad=True)], [tensor(-0.5048707, requires_grad=True)], [tensor(-0.50150136, requires_grad=True)], [tensor(-0.49811883, requires_grad=True)], [tensor(-0.49472313, requires_grad=True)], [tensor(-0.49131426, requires_grad=True)], [tensor(-0.48789222, requires_grad=True)], [tensor(-0.48445704, requires_grad=True)], [tensor(-0.48100872, requires_grad=True)], [tensor(-0.47754726, requires_grad=True)], [tensor(-0.47407269, requires_grad=True)], [tensor(-0.47058499, requires_grad=True)], [tensor(-0.4670842, requires_grad=True)], [tensor(-0.46357031, requires_grad=True)], [tensor(-0.46004333, requires_grad=True)], [tensor(-0.45650328, requires_grad=True)], [tensor(-0.45295016, requires_grad=True)], [tensor(-0.44938398, requires_grad=True)], [tensor(-0.44580476, requires_grad=True)], [tensor(-0.4422125, requires_grad=True)], [tensor(-0.43860721, requires_grad=True)], [tensor(-0.4349889, requires_grad=True)], [tensor(-0.43135758, requires_grad=True)], [tensor(-0.42771326, requires_grad=True)], [tensor(-0.42405596, requires_grad=True)], [tensor(-0.42038567, requires_grad=True)], [tensor(-0.41670241, requires_grad=True)], [tensor(-0.4130062, requires_grad=True)], [tensor(-0.40929704, requires_grad=True)], [tensor(-0.40557493, requires_grad=True)], [tensor(-0.4018399, requires_grad=True)], [tensor(-0.39809195, requires_grad=True)], [tensor(-0.39433109, requires_grad=True)], [tensor(-0.39055734, requires_grad=True)], [tensor(-0.3867707, requires_grad=True)], [tensor(-0.38297118, requires_grad=True)], [tensor(-0.3791588, requires_grad=True)], [tensor(-0.37533356, requires_grad=True)], [tensor(-0.37149547, requires_grad=True)], [tensor(-0.36764456, requires_grad=True)], [tensor(-0.36378082, requires_grad=True)], [tensor(-0.35990427, requires_grad=True)], [tensor(-0.35601491, requires_grad=True)], [tensor(-0.35211277, requires_grad=True)], [tensor(-0.34819785, requires_grad=True)], [tensor(-0.34427017, requires_grad=True)], [tensor(-0.34032973, requires_grad=True)], [tensor(-0.33637654, requires_grad=True)], [tensor(-0.33241063, requires_grad=True)], [tensor(-0.32843199, requires_grad=True)], [tensor(-0.32444064, requires_grad=True)], [tensor(-0.3204366, requires_grad=True)], [tensor(-0.31641986, requires_grad=True)], [tensor(-0.31239046, requires_grad=True)], [tensor(-0.30834839, requires_grad=True)], [tensor(-0.30429368, requires_grad=True)], [tensor(-0.30022633, requires_grad=True)], [tensor(-0.29614635, requires_grad=True)], [tensor(-0.29205376, requires_grad=True)], [tensor(-0.28794857, requires_grad=True)], [tensor(-0.28383079, requires_grad=True)], [tensor(-0.27970043, requires_grad=True)], [tensor(-0.27555752, requires_grad=True)], [tensor(-0.27140205, requires_grad=True)], [tensor(-0.26723405, requires_grad=True)], [tensor(-0.26305353, requires_grad=True)], [tensor(-0.25886049, requires_grad=True)], [tensor(-0.25465496, requires_grad=True)], [tensor(-0.25043694, requires_grad=True)], [tensor(-0.24620645, requires_grad=True)], [tensor(-0.24196351, requires_grad=True)], [tensor(-0.23770812, requires_grad=True)], [tensor(-0.23344031, requires_grad=True)], [tensor(-0.22916008, requires_grad=True)], [tensor(-0.22486744, requires_grad=True)], [tensor(-0.22056242, requires_grad=True)], [tensor(-0.21624503, requires_grad=True)], [tensor(-0.21191528, requires_grad=True)], [tensor(-0.20757318, requires_grad=True)], [tensor(-0.20321876, requires_grad=True)], [tensor(-0.19885201, requires_grad=True)], [tensor(-0.19447297, requires_grad=True)], [tensor(-0.19008165, requires_grad=True)], [tensor(-0.18567805, requires_grad=True)], [tensor(-0.1812622, requires_grad=True)], [tensor(-0.17683411, requires_grad=True)], [tensor(-0.1723938, requires_grad=True)], [tensor(-0.16794128, requires_grad=True)], [tensor(-0.16347656, requires_grad=True)], [tensor(-0.15899967, requires_grad=True)], [tensor(-0.15451062, requires_grad=True)], [tensor(-0.15000942, requires_grad=True)], [tensor(-0.1454961, requires_grad=True)], [tensor(-0.14097067, requires_grad=True)], [tensor(-0.13643314, requires_grad=True)], [tensor(-0.13188353, requires_grad=True)], [tensor(-0.12732186, requires_grad=True)], [tensor(-0.12274815, requires_grad=True)], [tensor(-0.11816242, requires_grad=True)], [tensor(-0.11356467, requires_grad=True)], [tensor(-0.10895493, requires_grad=True)], [tensor(-0.10433322, requires_grad=True)], [tensor(-0.09969956, requires_grad=True)], [tensor(-0.09505396, requires_grad=True)], [tensor(-0.09039644, requires_grad=True)], [tensor(-0.08572702, requires_grad=True)], [tensor(-0.08104572, requires_grad=True)], [tensor(-0.07635255, requires_grad=True)], [tensor(-0.07164755, requires_grad=True)], [tensor(-0.06693072, requires_grad=True)], [tensor(-0.06220208, requires_grad=True)], [tensor(-0.05746166, requires_grad=True)], [tensor(-0.05270948, requires_grad=True)], [tensor(-0.04794556, requires_grad=True)], [tensor(-0.04316991, requires_grad=True)], [tensor(-0.03838255, requires_grad=True)], [tensor(-0.03358352, requires_grad=True)], [tensor(-0.02877282, requires_grad=True)], [tensor(-0.02395049, requires_grad=True)], [tensor(-0.01911654, requires_grad=True)], [tensor(-0.01427099, requires_grad=True)], [tensor(-0.00941386, requires_grad=True)], [tensor(-0.00454519, requires_grad=True)], [tensor(0.00033502, requires_grad=True)], [tensor(0.00522673, requires_grad=True)], [tensor(0.01012992, requires_grad=True)], [tensor(0.01504457, requires_grad=True)], [tensor(0.01997066, requires_grad=True)], [tensor(0.02490816, requires_grad=True)], [tensor(0.02985705, requires_grad=True)], [tensor(0.0348173, requires_grad=True)], [tensor(0.03978889, requires_grad=True)], [tensor(0.04477179, requires_grad=True)], [tensor(0.04976598, requires_grad=True)], [tensor(0.05477143, requires_grad=True)], [tensor(0.05978811, requires_grad=True)], [tensor(0.06481601, requires_grad=True)], [tensor(0.06985508, requires_grad=True)], [tensor(0.07490531, requires_grad=True)], [tensor(0.07996667, requires_grad=True)], [tensor(0.08503913, requires_grad=True)], [tensor(0.09012266, requires_grad=True)], [tensor(0.09521723, requires_grad=True)], [tensor(0.10032281, requires_grad=True)], [tensor(0.10543937, requires_grad=True)], [tensor(0.11056689, requires_grad=True)], [tensor(0.11570534, requires_grad=True)], [tensor(0.12085467, requires_grad=True)], [tensor(0.12601487, requires_grad=True)], [tensor(0.1311859, requires_grad=True)], [tensor(0.13636772, requires_grad=True)], [tensor(0.14156031, requires_grad=True)], [tensor(0.14676363, requires_grad=True)], [tensor(0.15197765, requires_grad=True)], [tensor(0.15720233, requires_grad=True)], [tensor(0.16243764, requires_grad=True)], [tensor(0.16768355, requires_grad=True)], [tensor(0.17294002, requires_grad=True)], [tensor(0.178207, requires_grad=True)], [tensor(0.18348448, requires_grad=True)], [tensor(0.1887724, requires_grad=True)], [tensor(0.19407073, requires_grad=True)], [tensor(0.19937944, requires_grad=True)], [tensor(0.20469847, requires_grad=True)], [tensor(0.2100278, requires_grad=True)], [tensor(0.21536738, requires_grad=True)], [tensor(0.22071718, requires_grad=True)], [tensor(0.22607714, requires_grad=True)], [tensor(0.23144723, requires_grad=True)], [tensor(0.2368274, requires_grad=True)], [tensor(0.24221761, requires_grad=True)], [tensor(0.24761781, requires_grad=True)], [tensor(0.25302796, requires_grad=True)], [tensor(0.25844802, requires_grad=True)], [tensor(0.26387792, requires_grad=True)], [tensor(0.26931764, requires_grad=True)], [tensor(0.27476711, requires_grad=True)], [tensor(0.28022629, requires_grad=True)], [tensor(0.28569512, requires_grad=True)], [tensor(0.29117356, requires_grad=True)], [tensor(0.29666155, requires_grad=True)], [tensor(0.30215903, requires_grad=True)], [tensor(0.30766596, requires_grad=True)], [tensor(0.31318227, requires_grad=True)], [tensor(0.31870792, requires_grad=True)], [tensor(0.32424283, requires_grad=True)], [tensor(0.32978695, requires_grad=True)], [tensor(0.33534022, requires_grad=True)], [tensor(0.34090258, requires_grad=True)], [tensor(0.34647396, requires_grad=True)], [tensor(0.3520543, requires_grad=True)], [tensor(0.35764354, requires_grad=True)], [tensor(0.3632416, requires_grad=True)], [tensor(0.36884841, requires_grad=True)], [tensor(0.37446391, requires_grad=True)], [tensor(0.38008802, requires_grad=True)], [tensor(0.38572067, requires_grad=True)], [tensor(0.39136178, requires_grad=True)], [tensor(0.39701128, requires_grad=True)], [tensor(0.40266908, requires_grad=True)], [tensor(0.40833511, requires_grad=True)], [tensor(0.41400928, requires_grad=True)], [tensor(0.4196915, requires_grad=True)], [tensor(0.42538169, requires_grad=True)], [tensor(0.43107976, requires_grad=True)], [tensor(0.43678561, requires_grad=True)], [tensor(0.44249916, requires_grad=True)], [tensor(0.4482203, requires_grad=True)], [tensor(0.45394894, requires_grad=True)], [tensor(0.45968497, requires_grad=True)], [tensor(0.46542829, requires_grad=True)], [tensor(0.47117878, requires_grad=True)], [tensor(0.47693635, requires_grad=True)], [tensor(0.48270087, requires_grad=True)], [tensor(0.48847223, requires_grad=True)], [tensor(0.49425031, requires_grad=True)], [tensor(0.50003497, requires_grad=True)], [tensor(0.5058261, requires_grad=True)], [tensor(0.51162357, requires_grad=True)], [tensor(0.51742723, requires_grad=True)], [tensor(0.52323694, requires_grad=True)], [tensor(0.52905256, requires_grad=True)], [tensor(0.53487394, requires_grad=True)], [tensor(0.54070093, requires_grad=True)], [tensor(0.54653336, requires_grad=True)], [tensor(0.55237108, requires_grad=True)], [tensor(0.5582139, requires_grad=True)], [tensor(0.56406165, requires_grad=True)], [tensor(0.56991415, requires_grad=True)], [tensor(0.57577121, requires_grad=True)], [tensor(0.58163262, requires_grad=True)], [tensor(0.58749819, requires_grad=True)], [tensor(0.59336771, requires_grad=True)], [tensor(0.59924095, requires_grad=True)], [tensor(0.60511767, requires_grad=True)], [tensor(0.61099766, requires_grad=True)], [tensor(0.61688064, requires_grad=True)], [tensor(0.62276637, requires_grad=True)], [tensor(0.62865458, requires_grad=True)], [tensor(0.63454498, requires_grad=True)], [tensor(0.64043727, requires_grad=True)], [tensor(0.64633115, requires_grad=True)], [tensor(0.6522263, requires_grad=True)], [tensor(0.65812238, requires_grad=True)], [tensor(0.66401903, requires_grad=True)], [tensor(0.66991588, requires_grad=True)], [tensor(0.67581255, requires_grad=True)], [tensor(0.68170861, requires_grad=True)], [tensor(0.68760364, requires_grad=True)], [tensor(0.69349718, requires_grad=True)], [tensor(0.69938875, requires_grad=True)], [tensor(0.70527783, requires_grad=True)], [tensor(0.7111639, requires_grad=True)], [tensor(0.71704637, requires_grad=True)], [tensor(0.72292464, requires_grad=True)], [tensor(0.72879807, requires_grad=True)], [tensor(0.73466596, requires_grad=True)], [tensor(0.74052759, requires_grad=True)], [tensor(0.74638216, requires_grad=True)], [tensor(0.75222884, requires_grad=True)], [tensor(0.75806673, requires_grad=True)], [tensor(0.76389485, requires_grad=True)], [tensor(0.76971215, requires_grad=True)], [tensor(0.77551751, requires_grad=True)], [tensor(0.78130969, requires_grad=True)], [tensor(0.78708736, requires_grad=True)], [tensor(0.79284907, requires_grad=True)], [tensor(0.79859321, requires_grad=True)], [tensor(0.80431804, requires_grad=True)], [tensor(0.81002163, requires_grad=True)], [tensor(0.81570185, requires_grad=True)], [tensor(0.82135631, requires_grad=True)], [tensor(0.82698236, requires_grad=True)], [tensor(0.83257701, requires_grad=True)], [tensor(0.8381369, requires_grad=True)], [tensor(0.84365817, requires_grad=True)], [tensor(0.84913643, requires_grad=True)], [tensor(0.85456659, requires_grad=True)], [tensor(0.8599427, requires_grad=True)], [tensor(0.86525776, requires_grad=True)], [tensor(0.8705034, requires_grad=True)], [tensor(0.87566952, requires_grad=True)], [tensor(0.88074366, requires_grad=True)], [tensor(0.88571021, requires_grad=True)], [tensor(0.89054912, requires_grad=True)], [tensor(0.8952339, requires_grad=True)], [tensor(0.89972828, requires_grad=True)], [tensor(0.90398014, requires_grad=True)], [tensor(0.90790972, requires_grad=True)], [tensor(0.91138308, requires_grad=True)], [tensor(0.91413976, requires_grad=True)], [tensor(0.91550915, requires_grad=True)], [tensor(0.90846017, requires_grad=True)], [tensor(-0.90846017, requires_grad=True)], [tensor(-0.90823154, requires_grad=True)], [tensor(-0.90799927, requires_grad=True)], [tensor(-0.90776337, requires_grad=True)], [tensor(-0.90752384, requires_grad=True)], [tensor(-0.90728067, requires_grad=True)], [tensor(-0.90703388, requires_grad=True)], [tensor(-0.90678346, requires_grad=True)], [tensor(-0.9065294, requires_grad=True)], [tensor(-0.90627172, requires_grad=True)], [tensor(-0.90601041, requires_grad=True)], [tensor(-0.90574548, requires_grad=True)], [tensor(-0.90547691, requires_grad=True)], [tensor(-0.90520473, requires_grad=True)], [tensor(-0.90492891, requires_grad=True)], [tensor(-0.90464948, requires_grad=True)], [tensor(-0.90436642, requires_grad=True)], [tensor(-0.90407973, requires_grad=True)], [tensor(-0.90378943, requires_grad=True)], [tensor(-0.9034955, requires_grad=True)], [tensor(-0.90319795, requires_grad=True)], [tensor(-0.90289678, requires_grad=True)], [tensor(-0.90259199, requires_grad=True)], [tensor(-0.90228358, requires_grad=True)], [tensor(-0.90197156, requires_grad=True)], [tensor(-0.90165592, requires_grad=True)], [tensor(-0.90133666, requires_grad=True)], [tensor(-0.90101378, requires_grad=True)], [tensor(-0.90068729, requires_grad=True)], [tensor(-0.90035718, requires_grad=True)], [tensor(-0.90002346, requires_grad=True)], [tensor(-0.89968613, requires_grad=True)], [tensor(-0.89934518, requires_grad=True)], [tensor(-0.89900062, requires_grad=True)], [tensor(-0.89865245, requires_grad=True)], [tensor(-0.89830067, requires_grad=True)], [tensor(-0.89794528, requires_grad=True)], [tensor(-0.89758628, requires_grad=True)], [tensor(-0.89722367, requires_grad=True)], [tensor(-0.89685746, requires_grad=True)], [tensor(-0.89648763, requires_grad=True)], [tensor(-0.8961142, requires_grad=True)], [tensor(-0.89573717, requires_grad=True)], [tensor(-0.89535653, requires_grad=True)], [tensor(-0.89497228, requires_grad=True)], [tensor(-0.89458443, requires_grad=True)], [tensor(-0.89419298, requires_grad=True)], [tensor(-0.89379792, requires_grad=True)], [tensor(-0.89339926, requires_grad=True)], [tensor(-0.89299701, requires_grad=True)], [tensor(-0.89259115, requires_grad=True)], [tensor(-0.89218169, requires_grad=True)], [tensor(-0.89176863, requires_grad=True)], [tensor(-0.89135197, requires_grad=True)], [tensor(-0.89093172, requires_grad=True)], [tensor(-0.89050787, requires_grad=True)], [tensor(-0.89008042, requires_grad=True)], [tensor(-0.88964938, requires_grad=True)], [tensor(-0.88921474, requires_grad=True)], [tensor(-0.88877651, requires_grad=True)], [tensor(-0.88833469, requires_grad=True)], [tensor(-0.88788927, requires_grad=True)], [tensor(-0.88744026, requires_grad=True)], [tensor(-0.88698765, requires_grad=True)], [tensor(-0.88653146, requires_grad=True)], [tensor(-0.88607168, requires_grad=True)], [tensor(-0.88560831, requires_grad=True)], [tensor(-0.88514134, requires_grad=True)], [tensor(-0.8846708, requires_grad=True)], [tensor(-0.88419666, requires_grad=True)], [tensor(-0.88371894, requires_grad=True)], [tensor(-0.88323763, requires_grad=True)], [tensor(-0.88275273, requires_grad=True)], [tensor(-0.88226425, requires_grad=True)], [tensor(-0.88177219, requires_grad=True)], [tensor(-0.88127654, requires_grad=True)], [tensor(-0.88077731, requires_grad=True)], [tensor(-0.8802745, requires_grad=True)], [tensor(-0.87976811, requires_grad=True)], [tensor(-0.87925814, requires_grad=True)], [tensor(-0.87874458, requires_grad=True)], [tensor(-0.87822745, requires_grad=True)], [tensor(-0.87770674, requires_grad=True)], [tensor(-0.87718245, requires_grad=True)], [tensor(-0.87665459, requires_grad=True)], [tensor(-0.87612315, requires_grad=True)], [tensor(-0.87558813, requires_grad=True)], [tensor(-0.87504954, requires_grad=True)], [tensor(-0.87450737, requires_grad=True)], [tensor(-0.87396163, requires_grad=True)], [tensor(-0.87341232, requires_grad=True)], [tensor(-0.87285944, requires_grad=True)], [tensor(-0.87230298, requires_grad=True)], [tensor(-0.87174295, requires_grad=True)], [tensor(-0.87117936, requires_grad=True)], [tensor(-0.87061219, requires_grad=True)], [tensor(-0.87004146, requires_grad=True)], [tensor(-0.86946715, requires_grad=True)], [tensor(-0.86888928, requires_grad=True)], [tensor(-0.86830784, requires_grad=True)], [tensor(-0.86772284, requires_grad=True)], [tensor(-0.86713427, requires_grad=True)], [tensor(-0.86654214, requires_grad=True)], [tensor(-0.86594644, requires_grad=True)], [tensor(-0.86534718, requires_grad=True)], [tensor(-0.86474436, requires_grad=True)], [tensor(-0.86413798, requires_grad=True)], [tensor(-0.86352803, requires_grad=True)], [tensor(-0.86291453, requires_grad=True)], [tensor(-0.86229746, requires_grad=True)], [tensor(-0.86167684, requires_grad=True)], [tensor(-0.86105266, requires_grad=True)], [tensor(-0.86042492, requires_grad=True)], [tensor(-0.85979362, requires_grad=True)], [tensor(-0.85915877, requires_grad=True)], [tensor(-0.85852036, requires_grad=True)], [tensor(-0.8578784, requires_grad=True)], [tensor(-0.85723288, requires_grad=True)], [tensor(-0.85658381, requires_grad=True)], [tensor(-0.85593119, requires_grad=True)], [tensor(-0.85527502, requires_grad=True)], [tensor(-0.85461529, requires_grad=True)], [tensor(-0.85395201, requires_grad=True)], [tensor(-0.85328519, requires_grad=True)], [tensor(-0.85261481, requires_grad=True)], [tensor(-0.85194089, requires_grad=True)], [tensor(-0.85126342, requires_grad=True)], [tensor(-0.8505824, requires_grad=True)], [tensor(-0.84989784, requires_grad=True)], [tensor(-0.84920973, requires_grad=True)], [tensor(-0.84851807, requires_grad=True)], [tensor(-0.84782287, requires_grad=True)], [tensor(-0.84712413, requires_grad=True)], [tensor(-0.84642185, requires_grad=True)], [tensor(-0.84571602, requires_grad=True)], [tensor(-0.84500665, requires_grad=True)], [tensor(-0.84429374, requires_grad=True)], [tensor(-0.8435773, requires_grad=True)], [tensor(-0.84285731, requires_grad=True)], [tensor(-0.84213378, requires_grad=True)], [tensor(-0.84140672, requires_grad=True)], [tensor(-0.84067612, requires_grad=True)], [tensor(-0.83994198, requires_grad=True)], [tensor(-0.83920431, requires_grad=True)], [tensor(-0.8384631, requires_grad=True)], [tensor(-0.83771836, requires_grad=True)], [tensor(-0.83697008, requires_grad=True)], [tensor(-0.83621828, requires_grad=True)], [tensor(-0.83546294, requires_grad=True)], [tensor(-0.83470407, requires_grad=True)], [tensor(-0.83394167, requires_grad=True)], [tensor(-0.83317573, requires_grad=True)], [tensor(-0.83240627, requires_grad=True)], [tensor(-0.83163329, requires_grad=True)], [tensor(-0.83085677, requires_grad=True)], [tensor(-0.83007673, requires_grad=True)], [tensor(-0.82929316, requires_grad=True)], [tensor(-0.82850606, requires_grad=True)], [tensor(-0.82771544, requires_grad=True)], [tensor(-0.8269213, requires_grad=True)], [tensor(-0.82612363, requires_grad=True)], [tensor(-0.82532244, requires_grad=True)], [tensor(-0.82451773, requires_grad=True)], [tensor(-0.8237095, requires_grad=True)], [tensor(-0.82289775, requires_grad=True)], [tensor(-0.82208247, requires_grad=True)], [tensor(-0.82126368, requires_grad=True)], [tensor(-0.82044137, requires_grad=True)], [tensor(-0.81961555, requires_grad=True)], [tensor(-0.8187862, requires_grad=True)], [tensor(-0.81795334, requires_grad=True)], [tensor(-0.81711697, requires_grad=True)], [tensor(-0.81627708, requires_grad=True)], [tensor(-0.81543367, requires_grad=True)], [tensor(-0.81458676, requires_grad=True)], [tensor(-0.81373633, requires_grad=True)], [tensor(-0.81288239, requires_grad=True)], [tensor(-0.81202493, requires_grad=True)], [tensor(-0.81116397, requires_grad=True)], [tensor(-0.8102995, requires_grad=True)], [tensor(-0.80943152, requires_grad=True)], [tensor(-0.80856003, requires_grad=True)], [tensor(-0.80768504, requires_grad=True)], [tensor(-0.80680654, requires_grad=True)], [tensor(-0.80592453, requires_grad=True)], [tensor(-0.80503902, requires_grad=True)], [tensor(-0.80415, requires_grad=True)], [tensor(-0.80325748, requires_grad=True)], [tensor(-0.80236146, requires_grad=True)], [tensor(-0.80146194, requires_grad=True)], [tensor(-0.80055891, requires_grad=True)], [tensor(-0.79965238, requires_grad=True)], [tensor(-0.79874236, requires_grad=True)], [tensor(-0.79782883, requires_grad=True)], [tensor(-0.79691181, requires_grad=True)], [tensor(-0.79599129, requires_grad=True)], [tensor(-0.79506727, requires_grad=True)], [tensor(-0.79413976, requires_grad=True)], [tensor(-0.79320875, requires_grad=True)], [tensor(-0.79227424, requires_grad=True)], [tensor(-0.79133625, requires_grad=True)], [tensor(-0.79039476, requires_grad=True)], [tensor(-0.78944977, requires_grad=True)], [tensor(-0.7885013, requires_grad=True)], [tensor(-0.78754933, requires_grad=True)], [tensor(-0.78659388, requires_grad=True)], [tensor(-0.78563494, requires_grad=True)], [tensor(-0.7846725, requires_grad=True)], [tensor(-0.78370658, requires_grad=True)], [tensor(-0.78273718, requires_grad=True)], [tensor(-0.78176428, requires_grad=True)], [tensor(-0.7807879, requires_grad=True)], [tensor(-0.77980804, requires_grad=True)], [tensor(-0.77882469, requires_grad=True)], [tensor(-0.77783786, requires_grad=True)], [tensor(-0.77684755, requires_grad=True)], [tensor(-0.77585376, requires_grad=True)], [tensor(-0.77485648, requires_grad=True)], [tensor(-0.77385572, requires_grad=True)], [tensor(-0.77285149, requires_grad=True)], [tensor(-0.77184378, requires_grad=True)], [tensor(-0.77083258, requires_grad=True)], [tensor(-0.76981792, requires_grad=True)], [tensor(-0.76879977, requires_grad=True)], [tensor(-0.76777815, requires_grad=True)], [tensor(-0.76675306, requires_grad=True)], [tensor(-0.76572449, requires_grad=True)], [tensor(-0.76469245, requires_grad=True)], [tensor(-0.76365693, requires_grad=True)], [tensor(-0.76261795, requires_grad=True)], [tensor(-0.76157549, requires_grad=True)], [tensor(-0.76052957, requires_grad=True)], [tensor(-0.75948017, requires_grad=True)], [tensor(-0.75842731, requires_grad=True)], [tensor(-0.75737097, requires_grad=True)], [tensor(-0.75631118, requires_grad=True)], [tensor(-0.75524791, requires_grad=True)], [tensor(-0.75418118, requires_grad=True)], [tensor(-0.75311099, requires_grad=True)], [tensor(-0.75203733, requires_grad=True)], [tensor(-0.75096021, requires_grad=True)], [tensor(-0.74987962, requires_grad=True)], [tensor(-0.74879558, requires_grad=True)], [tensor(-0.74770807, requires_grad=True)], [tensor(-0.74661711, requires_grad=True)], [tensor(-0.74552268, requires_grad=True)], [tensor(-0.7444248, requires_grad=True)], [tensor(-0.74332346, requires_grad=True)], [tensor(-0.74221866, requires_grad=True)], [tensor(-0.74111041, requires_grad=True)], [tensor(-0.7399987, requires_grad=True)], [tensor(-0.73888354, requires_grad=True)], [tensor(-0.73776492, requires_grad=True)], [tensor(-0.73664286, requires_grad=True)], [tensor(-0.73551734, requires_grad=True)], [tensor(-0.73438837, requires_grad=True)], [tensor(-0.73325594, requires_grad=True)], [tensor(-0.73212007, requires_grad=True)], [tensor(-0.73098075, requires_grad=True)], [tensor(-0.72983799, requires_grad=True)], [tensor(-0.72869177, requires_grad=True)], [tensor(-0.72754211, requires_grad=True)], [tensor(-0.72638901, requires_grad=True)], [tensor(-0.72523246, requires_grad=True)], [tensor(-0.72407246, requires_grad=True)], [tensor(-0.72290903, requires_grad=True)], [tensor(-0.72174215, requires_grad=True)], [tensor(-0.72057183, requires_grad=True)], [tensor(-0.71939807, requires_grad=True)], [tensor(-0.71822087, requires_grad=True)], [tensor(-0.71704023, requires_grad=True)], [tensor(-0.71585615, requires_grad=True)], [tensor(-0.71466864, requires_grad=True)], [tensor(-0.71347769, requires_grad=True)], [tensor(-0.7122833, requires_grad=True)], [tensor(-0.71108548, requires_grad=True)], [tensor(-0.70988422, requires_grad=True)], [tensor(-0.70867953, requires_grad=True)], [tensor(-0.70747141, requires_grad=True)], [tensor(-0.70625986, requires_grad=True)], [tensor(-0.70504488, requires_grad=True)], [tensor(-0.70382647, requires_grad=True)], [tensor(-0.70260463, requires_grad=True)], [tensor(-0.70137936, requires_grad=True)], [tensor(-0.70015066, requires_grad=True)], [tensor(-0.69891854, requires_grad=True)], [tensor(-0.69768299, requires_grad=True)], [tensor(-0.69644402, requires_grad=True)], [tensor(-0.69520162, requires_grad=True)], [tensor(-0.6939558, requires_grad=True)], [tensor(-0.69270656, requires_grad=True)], [tensor(-0.69145389, requires_grad=True)], [tensor(-0.69019781, requires_grad=True)], [tensor(-0.68893831, requires_grad=True)], [tensor(-0.68767538, requires_grad=True)], [tensor(-0.68640904, requires_grad=True)], [tensor(-0.68513929, requires_grad=True)], [tensor(-0.68386611, requires_grad=True)], [tensor(-0.68258952, requires_grad=True)], [tensor(-0.68130952, requires_grad=True)], [tensor(-0.6800261, requires_grad=True)], [tensor(-0.67873927, requires_grad=True)], [tensor(-0.67744903, requires_grad=True)], [tensor(-0.67615538, requires_grad=True)], [tensor(-0.67485832, requires_grad=True)], [tensor(-0.67355784, requires_grad=True)], [tensor(-0.67225396, requires_grad=True)], [tensor(-0.67094667, requires_grad=True)], [tensor(-0.66963598, requires_grad=True)], [tensor(-0.66832188, requires_grad=True)], [tensor(-0.66700437, requires_grad=True)], [tensor(-0.66568346, requires_grad=True)], [tensor(-0.66435915, requires_grad=True)], [tensor(-0.66303143, requires_grad=True)], [tensor(-0.66170031, requires_grad=True)], [tensor(-0.6603658, requires_grad=True)], [tensor(-0.65902788, requires_grad=True)], [tensor(-0.65768656, requires_grad=True)], [tensor(-0.65634185, requires_grad=True)], [tensor(-0.65499374, requires_grad=True)], [tensor(-0.65364223, requires_grad=True)], [tensor(-0.65228733, requires_grad=True)], [tensor(-0.65092903, requires_grad=True)], [tensor(-0.64956734, requires_grad=True)], [tensor(-0.64820226, requires_grad=True)], [tensor(-0.64683378, requires_grad=True)], [tensor(-0.64546191, requires_grad=True)], [tensor(-0.64408666, requires_grad=True)], [tensor(-0.64270801, requires_grad=True)], [tensor(-0.64132598, requires_grad=True)], [tensor(-0.63994056, requires_grad=True)], [tensor(-0.63855176, requires_grad=True)], [tensor(-0.63715956, requires_grad=True)], [tensor(-0.63576399, requires_grad=True)], [tensor(-0.63436503, requires_grad=True)], [tensor(-0.63296269, requires_grad=True)], [tensor(-0.63155696, requires_grad=True)], [tensor(-0.63014786, requires_grad=True)], [tensor(-0.62873537, requires_grad=True)], [tensor(-0.62731951, requires_grad=True)], [tensor(-0.62590027, requires_grad=True)], [tensor(-0.62447765, requires_grad=True)], [tensor(-0.62305165, requires_grad=True)], [tensor(-0.62162228, requires_grad=True)], [tensor(-0.62018954, requires_grad=True)], [tensor(-0.61875342, requires_grad=True)], [tensor(-0.61731393, requires_grad=True)], [tensor(-0.61587107, requires_grad=True)], [tensor(-0.61442484, requires_grad=True)], [tensor(-0.61297524, requires_grad=True)], [tensor(-0.61152226, requires_grad=True)], [tensor(-0.61006593, requires_grad=True)], [tensor(-0.60860622, requires_grad=True)], [tensor(-0.60714315, requires_grad=True)], [tensor(-0.60567671, requires_grad=True)], [tensor(-0.60420691, requires_grad=True)], [tensor(-0.60273375, requires_grad=True)], [tensor(-0.60125722, requires_grad=True)], [tensor(-0.59977734, requires_grad=True)], [tensor(-0.59829409, requires_grad=True)], [tensor(-0.59680749, requires_grad=True)], [tensor(-0.59531752, requires_grad=True)], [tensor(-0.5938242, requires_grad=True)], [tensor(-0.59232752, requires_grad=True)], [tensor(-0.59082749, requires_grad=True)], [tensor(-0.5893241, requires_grad=True)], [tensor(-0.58781736, requires_grad=True)], [tensor(-0.58630727, requires_grad=True)], [tensor(-0.58479382, requires_grad=True)], [tensor(-0.58327703, requires_grad=True)], [tensor(-0.58175688, requires_grad=True)], [tensor(-0.58023339, requires_grad=True)], [tensor(-0.57870655, requires_grad=True)], [tensor(-0.57717636, requires_grad=True)], [tensor(-0.57564283, requires_grad=True)], [tensor(-0.57410595, requires_grad=True)], [tensor(-0.57256573, requires_grad=True)], [tensor(-0.57102217, requires_grad=True)], [tensor(-0.56947526, requires_grad=True)], [tensor(-0.56792502, requires_grad=True)], [tensor(-0.56637143, requires_grad=True)], [tensor(-0.56481451, requires_grad=True)], [tensor(-0.56325425, requires_grad=True)], [tensor(-0.56169065, requires_grad=True)], [tensor(-0.56012372, requires_grad=True)], [tensor(-0.55855345, requires_grad=True)], [tensor(-0.55697985, requires_grad=True)], [tensor(-0.55540291, requires_grad=True)], [tensor(-0.55382265, requires_grad=True)], [tensor(-0.55223905, requires_grad=True)], [tensor(-0.55065213, requires_grad=True)], [tensor(-0.54906187, requires_grad=True)], [tensor(-0.54746829, requires_grad=True)], [tensor(-0.54587139, requires_grad=True)], [tensor(-0.54427115, requires_grad=True)], [tensor(-0.5426676, requires_grad=True)], [tensor(-0.54106072, requires_grad=True)], [tensor(-0.53945051, requires_grad=True)], [tensor(-0.53783699, requires_grad=True)], [tensor(-0.53622015, requires_grad=True)], [tensor(-0.53459998, requires_grad=True)], [tensor(-0.5329765, requires_grad=True)], [tensor(-0.5313497, requires_grad=True)], [tensor(-0.52971959, requires_grad=True)], [tensor(-0.52808616, requires_grad=True)], [tensor(-0.52644942, requires_grad=True)], [tensor(-0.52480937, requires_grad=True)], [tensor(-0.523166, requires_grad=True)], [tensor(-0.52151932, requires_grad=True)], [tensor(-0.51986933, requires_grad=True)], [tensor(-0.51821604, requires_grad=True)], [tensor(-0.51655944, requires_grad=True)], [tensor(-0.51489953, requires_grad=True)], [tensor(-0.51323631, requires_grad=True)], [tensor(-0.5115698, requires_grad=True)], [tensor(-0.50989997, requires_grad=True)], [tensor(-0.50822685, requires_grad=True)], [tensor(-0.50655043, requires_grad=True)], [tensor(-0.5048707, requires_grad=True)], [tensor(-0.50318768, requires_grad=True)], [tensor(-0.50150136, requires_grad=True)], [tensor(-0.49981175, requires_grad=True)], [tensor(-0.49811883, requires_grad=True)], [tensor(-0.49642263, requires_grad=True)], [tensor(-0.49472313, requires_grad=True)], [tensor(-0.49302034, requires_grad=True)], [tensor(-0.49131426, requires_grad=True)], [tensor(-0.48960488, requires_grad=True)], [tensor(-0.48789222, requires_grad=True)], [tensor(-0.48617628, requires_grad=True)], [tensor(-0.48445704, requires_grad=True)], [tensor(-0.48273452, requires_grad=True)], [tensor(-0.48100872, requires_grad=True)], [tensor(-0.47927963, requires_grad=True)], [tensor(-0.47754726, requires_grad=True)], [tensor(-0.47581161, requires_grad=True)], [tensor(-0.47407269, requires_grad=True)], [tensor(-0.47233048, requires_grad=True)], [tensor(-0.47058499, requires_grad=True)], [tensor(-0.46883623, requires_grad=True)], [tensor(-0.4670842, requires_grad=True)], [tensor(-0.46532889, requires_grad=True)], [tensor(-0.46357031, requires_grad=True)], [tensor(-0.46180846, requires_grad=True)], [tensor(-0.46004333, requires_grad=True)], [tensor(-0.45827494, requires_grad=True)], [tensor(-0.45650328, requires_grad=True)], [tensor(-0.45472835, requires_grad=True)], [tensor(-0.45295016, requires_grad=True)], [tensor(-0.4511687, requires_grad=True)], [tensor(-0.44938398, requires_grad=True)], [tensor(-0.447596, requires_grad=True)], [tensor(-0.44580476, requires_grad=True)], [tensor(-0.44401026, requires_grad=True)], [tensor(-0.4422125, requires_grad=True)], [tensor(-0.44041148, requires_grad=True)], [tensor(-0.43860721, requires_grad=True)], [tensor(-0.43679968, requires_grad=True)], [tensor(-0.4349889, requires_grad=True)], [tensor(-0.43317486, requires_grad=True)], [tensor(-0.43135758, requires_grad=True)], [tensor(-0.42953705, requires_grad=True)], [tensor(-0.42771326, requires_grad=True)], [tensor(-0.42588623, requires_grad=True)], [tensor(-0.42405596, requires_grad=True)], [tensor(-0.42222243, requires_grad=True)], [tensor(-0.42038567, requires_grad=True)], [tensor(-0.41854566, requires_grad=True)], [tensor(-0.41670241, requires_grad=True)], [tensor(-0.41485593, requires_grad=True)], [tensor(-0.4130062, requires_grad=True)], [tensor(-0.41115324, requires_grad=True)], [tensor(-0.40929704, requires_grad=True)], [tensor(-0.4074376, requires_grad=True)], [tensor(-0.40557493, requires_grad=True)], [tensor(-0.40370903, requires_grad=True)], [tensor(-0.4018399, requires_grad=True)], [tensor(-0.39996754, requires_grad=True)], [tensor(-0.39809195, requires_grad=True)], [tensor(-0.39621314, requires_grad=True)], [tensor(-0.39433109, requires_grad=True)], [tensor(-0.39244583, requires_grad=True)], [tensor(-0.39055734, requires_grad=True)], [tensor(-0.38866563, requires_grad=True)], [tensor(-0.3867707, requires_grad=True)], [tensor(-0.38487255, requires_grad=True)], [tensor(-0.38297118, requires_grad=True)], [tensor(-0.38106659, requires_grad=True)], [tensor(-0.3791588, requires_grad=True)], [tensor(-0.37724778, requires_grad=True)], [tensor(-0.37533356, requires_grad=True)], [tensor(-0.37341612, requires_grad=True)], [tensor(-0.37149547, requires_grad=True)], [tensor(-0.36957162, requires_grad=True)], [tensor(-0.36764456, requires_grad=True)], [tensor(-0.36571429, requires_grad=True)], [tensor(-0.36378082, requires_grad=True)], [tensor(-0.36184414, requires_grad=True)], [tensor(-0.35990427, requires_grad=True)], [tensor(-0.35796119, requires_grad=True)], [tensor(-0.35601491, requires_grad=True)], [tensor(-0.35406544, requires_grad=True)], [tensor(-0.35211277, requires_grad=True)], [tensor(-0.35015691, requires_grad=True)], [tensor(-0.34819785, requires_grad=True)], [tensor(-0.34623561, requires_grad=True)], [tensor(-0.34427017, requires_grad=True)], [tensor(-0.34230154, requires_grad=True)], [tensor(-0.34032973, requires_grad=True)], [tensor(-0.33835473, requires_grad=True)], [tensor(-0.33637654, requires_grad=True)], [tensor(-0.33439518, requires_grad=True)], [tensor(-0.33241063, requires_grad=True)], [tensor(-0.3304229, requires_grad=True)], [tensor(-0.32843199, requires_grad=True)], [tensor(-0.3264379, requires_grad=True)], [tensor(-0.32444064, requires_grad=True)], [tensor(-0.3224402, requires_grad=True)], [tensor(-0.3204366, requires_grad=True)], [tensor(-0.31842981, requires_grad=True)], [tensor(-0.31641986, requires_grad=True)], [tensor(-0.31440675, requires_grad=True)], [tensor(-0.31239046, requires_grad=True)], [tensor(-0.31037101, requires_grad=True)], [tensor(-0.30834839, requires_grad=True)], [tensor(-0.30632262, requires_grad=True)], [tensor(-0.30429368, requires_grad=True)], [tensor(-0.30226158, requires_grad=True)], [tensor(-0.30022633, requires_grad=True)], [tensor(-0.29818791, requires_grad=True)], [tensor(-0.29614635, requires_grad=True)], [tensor(-0.29410163, requires_grad=True)], [tensor(-0.29205376, requires_grad=True)], [tensor(-0.29000274, requires_grad=True)], [tensor(-0.28794857, requires_grad=True)], [tensor(-0.28589125, requires_grad=True)], [tensor(-0.28383079, requires_grad=True)], [tensor(-0.28176718, requires_grad=True)], [tensor(-0.27970043, requires_grad=True)], [tensor(-0.27763055, requires_grad=True)], [tensor(-0.27555752, requires_grad=True)], [tensor(-0.27348135, requires_grad=True)], [tensor(-0.27140205, requires_grad=True)], [tensor(-0.26931962, requires_grad=True)], [tensor(-0.26723405, requires_grad=True)], [tensor(-0.26514535, requires_grad=True)], [tensor(-0.26305353, requires_grad=True)], [tensor(-0.26095857, requires_grad=True)], [tensor(-0.25886049, requires_grad=True)], [tensor(-0.25675929, requires_grad=True)], [tensor(-0.25465496, requires_grad=True)], [tensor(-0.25254751, requires_grad=True)], [tensor(-0.25043694, requires_grad=True)], [tensor(-0.24832326, requires_grad=True)], [tensor(-0.24620645, requires_grad=True)], [tensor(-0.24408654, requires_grad=True)], [tensor(-0.24196351, requires_grad=True)], [tensor(-0.23983737, requires_grad=True)], [tensor(-0.23770812, requires_grad=True)], [tensor(-0.23557577, requires_grad=True)], [tensor(-0.23344031, requires_grad=True)], [tensor(-0.23130174, requires_grad=True)], [tensor(-0.22916008, requires_grad=True)], [tensor(-0.22701531, requires_grad=True)], [tensor(-0.22486744, requires_grad=True)], [tensor(-0.22271648, requires_grad=True)], [tensor(-0.22056242, requires_grad=True)], [tensor(-0.21840527, requires_grad=True)], [tensor(-0.21624503, requires_grad=True)], [tensor(-0.2140817, requires_grad=True)], [tensor(-0.21191528, requires_grad=True)], [tensor(-0.20974577, requires_grad=True)], [tensor(-0.20757318, requires_grad=True)], [tensor(-0.20539751, requires_grad=True)], [tensor(-0.20321876, requires_grad=True)], [tensor(-0.20103692, requires_grad=True)], [tensor(-0.19885201, requires_grad=True)], [tensor(-0.19666403, requires_grad=True)], [tensor(-0.19447297, requires_grad=True)], [tensor(-0.19227885, requires_grad=True)], [tensor(-0.19008165, requires_grad=True)], [tensor(-0.18788138, requires_grad=True)], [tensor(-0.18567805, requires_grad=True)], [tensor(-0.18347166, requires_grad=True)], [tensor(-0.1812622, requires_grad=True)], [tensor(-0.17904969, requires_grad=True)], [tensor(-0.17683411, requires_grad=True)], [tensor(-0.17461548, requires_grad=True)], [tensor(-0.1723938, requires_grad=True)], [tensor(-0.17016906, requires_grad=True)], [tensor(-0.16794128, requires_grad=True)], [tensor(-0.16571044, requires_grad=True)], [tensor(-0.16347656, requires_grad=True)], [tensor(-0.16123964, requires_grad=True)], [tensor(-0.15899967, requires_grad=True)], [tensor(-0.15675666, requires_grad=True)], [tensor(-0.15451062, requires_grad=True)], [tensor(-0.15226154, requires_grad=True)], [tensor(-0.15000942, requires_grad=True)], [tensor(-0.14775428, requires_grad=True)], [tensor(-0.1454961, requires_grad=True)], [tensor(-0.1432349, requires_grad=True)], [tensor(-0.14097067, requires_grad=True)], [tensor(-0.13870341, requires_grad=True)], [tensor(-0.13643314, requires_grad=True)], [tensor(-0.13415984, requires_grad=True)], [tensor(-0.13188353, requires_grad=True)], [tensor(-0.1296042, requires_grad=True)], [tensor(-0.12732186, requires_grad=True)], [tensor(-0.12503651, requires_grad=True)], [tensor(-0.12274815, requires_grad=True)], [tensor(-0.12045679, requires_grad=True)], [tensor(-0.11816242, requires_grad=True)], [tensor(-0.11586504, requires_grad=True)], [tensor(-0.11356467, requires_grad=True)], [tensor(-0.1112613, requires_grad=True)], [tensor(-0.10895493, requires_grad=True)], [tensor(-0.10664557, requires_grad=True)], [tensor(-0.10433322, requires_grad=True)], [tensor(-0.10201788, requires_grad=True)], [tensor(-0.09969956, requires_grad=True)], [tensor(-0.09737825, requires_grad=True)], [tensor(-0.09505396, requires_grad=True)], [tensor(-0.09272669, requires_grad=True)], [tensor(-0.09039644, requires_grad=True)], [tensor(-0.08806321, requires_grad=True)], [tensor(-0.08572702, requires_grad=True)], [tensor(-0.08338785, requires_grad=True)], [tensor(-0.08104572, requires_grad=True)], [tensor(-0.07870062, requires_grad=True)], [tensor(-0.07635255, requires_grad=True)], [tensor(-0.07400153, requires_grad=True)], [tensor(-0.07164755, requires_grad=True)], [tensor(-0.06929061, requires_grad=True)], [tensor(-0.06693072, requires_grad=True)], [tensor(-0.06456787, requires_grad=True)], [tensor(-0.06220208, requires_grad=True)], [tensor(-0.05983334, requires_grad=True)], [tensor(-0.05746166, requires_grad=True)], [tensor(-0.05508704, requires_grad=True)], [tensor(-0.05270948, requires_grad=True)], [tensor(-0.05032899, requires_grad=True)], [tensor(-0.04794556, requires_grad=True)], [tensor(-0.0455592, requires_grad=True)], [tensor(-0.04316991, requires_grad=True)], [tensor(-0.04077769, requires_grad=True)], [tensor(-0.03838255, requires_grad=True)], [tensor(-0.0359845, requires_grad=True)], [tensor(-0.03358352, requires_grad=True)], [tensor(-0.03117963, requires_grad=True)], [tensor(-0.02877282, requires_grad=True)], [tensor(-0.02636311, requires_grad=True)], [tensor(-0.02395049, requires_grad=True)], [tensor(-0.02153496, requires_grad=True)], [tensor(-0.01911654, requires_grad=True)], [tensor(-0.01669521, requires_grad=True)], [tensor(-0.01427099, requires_grad=True)], [tensor(-0.01184387, requires_grad=True)], [tensor(-0.00941386, requires_grad=True)], [tensor(-0.00698097, requires_grad=True)], [tensor(-0.00454519, requires_grad=True)], [tensor(-0.00210653, requires_grad=True)], [tensor(0.00033502, requires_grad=True)], [tensor(0.00277943, requires_grad=True)], [tensor(0.00522673, requires_grad=True)], [tensor(0.00767689, requires_grad=True)], [tensor(0.01012992, requires_grad=True)], [tensor(0.01258581, requires_grad=True)], [tensor(0.01504457, requires_grad=True)], [tensor(0.01750619, requires_grad=True)], [tensor(0.01997066, requires_grad=True)], [tensor(0.02243798, requires_grad=True)], [tensor(0.02490816, requires_grad=True)], [tensor(0.02738118, requires_grad=True)], [tensor(0.02985705, requires_grad=True)], [tensor(0.03233575, requires_grad=True)], [tensor(0.0348173, requires_grad=True)], [tensor(0.03730168, requires_grad=True)], [tensor(0.03978889, requires_grad=True)], [tensor(0.04227892, requires_grad=True)], [tensor(0.04477179, requires_grad=True)], [tensor(0.04726747, requires_grad=True)], [tensor(0.04976598, requires_grad=True)], [tensor(0.05226729, requires_grad=True)], [tensor(0.05477143, requires_grad=True)], [tensor(0.05727837, requires_grad=True)], [tensor(0.05978811, requires_grad=True)], [tensor(0.06230066, requires_grad=True)], [tensor(0.06481601, requires_grad=True)], [tensor(0.06733415, requires_grad=True)], [tensor(0.06985508, requires_grad=True)], [tensor(0.0723788, requires_grad=True)], [tensor(0.07490531, requires_grad=True)], [tensor(0.0774346, requires_grad=True)], [tensor(0.07996667, requires_grad=True)], [tensor(0.08250151, requires_grad=True)], [tensor(0.08503913, requires_grad=True)], [tensor(0.08757951, requires_grad=True)], [tensor(0.09012266, requires_grad=True)], [tensor(0.09266856, requires_grad=True)], [tensor(0.09521723, requires_grad=True)], [tensor(0.09776864, requires_grad=True)], [tensor(0.10032281, requires_grad=True)], [tensor(0.10287972, requires_grad=True)], [tensor(0.10543937, requires_grad=True)], [tensor(0.10800177, requires_grad=True)], [tensor(0.11056689, requires_grad=True)], [tensor(0.11313475, requires_grad=True)], [tensor(0.11570534, requires_grad=True)], [tensor(0.11827865, requires_grad=True)], [tensor(0.12085467, requires_grad=True)], [tensor(0.12343342, requires_grad=True)], [tensor(0.12601487, requires_grad=True)], [tensor(0.12859903, requires_grad=True)], [tensor(0.1311859, requires_grad=True)], [tensor(0.13377546, requires_grad=True)], [tensor(0.13636772, requires_grad=True)], [tensor(0.13896267, requires_grad=True)], [tensor(0.14156031, requires_grad=True)], [tensor(0.14416063, requires_grad=True)], [tensor(0.14676363, requires_grad=True)], [tensor(0.1493693, requires_grad=True)], [tensor(0.15197765, requires_grad=True)], [tensor(0.15458866, requires_grad=True)], [tensor(0.15720233, requires_grad=True)], [tensor(0.15981866, requires_grad=True)], [tensor(0.16243764, requires_grad=True)], [tensor(0.16505927, requires_grad=True)], [tensor(0.16768355, requires_grad=True)], [tensor(0.17031047, requires_grad=True)], [tensor(0.17294002, requires_grad=True)], [tensor(0.1755722, requires_grad=True)], [tensor(0.178207, requires_grad=True)], [tensor(0.18084443, requires_grad=True)], [tensor(0.18348448, requires_grad=True)], [tensor(0.18612713, requires_grad=True)], [tensor(0.1887724, requires_grad=True)], [tensor(0.19142027, requires_grad=True)], [tensor(0.19407073, requires_grad=True)], [tensor(0.19672379, requires_grad=True)], [tensor(0.19937944, requires_grad=True)], [tensor(0.20203767, requires_grad=True)], [tensor(0.20469847, requires_grad=True)], [tensor(0.20736185, requires_grad=True)], [tensor(0.2100278, requires_grad=True)], [tensor(0.21269631, requires_grad=True)], [tensor(0.21536738, requires_grad=True)], [tensor(0.21804101, requires_grad=True)], [tensor(0.22071718, requires_grad=True)], [tensor(0.22339589, requires_grad=True)], [tensor(0.22607714, requires_grad=True)], [tensor(0.22876092, requires_grad=True)], [tensor(0.23144723, requires_grad=True)], [tensor(0.23413605, requires_grad=True)], [tensor(0.2368274, requires_grad=True)], [tensor(0.23952125, requires_grad=True)], [tensor(0.24221761, requires_grad=True)], [tensor(0.24491646, requires_grad=True)], [tensor(0.24761781, requires_grad=True)], [tensor(0.25032164, requires_grad=True)], [tensor(0.25302796, requires_grad=True)], [tensor(0.25573675, requires_grad=True)], [tensor(0.25844802, requires_grad=True)], [tensor(0.26116174, requires_grad=True)], [tensor(0.26387792, requires_grad=True)], [tensor(0.26659656, requires_grad=True)], [tensor(0.26931764, requires_grad=True)], [tensor(0.27204116, requires_grad=True)], [tensor(0.27476711, requires_grad=True)], [tensor(0.27749549, requires_grad=True)], [tensor(0.28022629, requires_grad=True)], [tensor(0.2829595, requires_grad=True)], [tensor(0.28569512, requires_grad=True)], [tensor(0.28843314, requires_grad=True)], [tensor(0.29117356, requires_grad=True)], [tensor(0.29391636, requires_grad=True)], [tensor(0.29666155, requires_grad=True)], [tensor(0.29940911, requires_grad=True)], [tensor(0.30215903, requires_grad=True)], [tensor(0.30491132, requires_grad=True)], [tensor(0.30766596, requires_grad=True)], [tensor(0.31042295, requires_grad=True)], [tensor(0.31318227, requires_grad=True)], [tensor(0.31594393, requires_grad=True)], [tensor(0.31870792, requires_grad=True)], [tensor(0.32147422, requires_grad=True)], [tensor(0.32424283, requires_grad=True)], [tensor(0.32701374, requires_grad=True)], [tensor(0.32978695, requires_grad=True)], [tensor(0.33256245, requires_grad=True)], [tensor(0.33534022, requires_grad=True)], [tensor(0.33812027, requires_grad=True)], [tensor(0.34090258, requires_grad=True)], [tensor(0.34368715, requires_grad=True)], [tensor(0.34647396, requires_grad=True)], [tensor(0.34926302, requires_grad=True)], [tensor(0.3520543, requires_grad=True)], [tensor(0.35484781, requires_grad=True)], [tensor(0.35764354, requires_grad=True)], [tensor(0.36044147, requires_grad=True)], [tensor(0.3632416, requires_grad=True)], [tensor(0.36604391, requires_grad=True)], [tensor(0.36884841, requires_grad=True)], [tensor(0.37165508, requires_grad=True)], [tensor(0.37446391, requires_grad=True)], [tensor(0.37727489, requires_grad=True)], [tensor(0.38008802, requires_grad=True)], [tensor(0.38290328, requires_grad=True)], [tensor(0.38572067, requires_grad=True)], [tensor(0.38854017, requires_grad=True)], [tensor(0.39136178, requires_grad=True)], [tensor(0.39418549, requires_grad=True)], [tensor(0.39701128, requires_grad=True)], [tensor(0.39983915, requires_grad=True)], [tensor(0.40266908, requires_grad=True)], [tensor(0.40550107, requires_grad=True)], [tensor(0.40833511, requires_grad=True)], [tensor(0.41117118, requires_grad=True)], [tensor(0.41400928, requires_grad=True)], [tensor(0.41684939, requires_grad=True)], [tensor(0.4196915, requires_grad=True)], [tensor(0.42253561, requires_grad=True)], [tensor(0.42538169, requires_grad=True)], [tensor(0.42822975, requires_grad=True)], [tensor(0.43107976, requires_grad=True)], [tensor(0.43393172, requires_grad=True)], [tensor(0.43678561, requires_grad=True)], [tensor(0.43964143, requires_grad=True)], [tensor(0.44249916, requires_grad=True)], [tensor(0.44535879, requires_grad=True)], [tensor(0.4482203, requires_grad=True)], [tensor(0.45108369, requires_grad=True)], [tensor(0.45394894, requires_grad=True)], [tensor(0.45681604, requires_grad=True)], [tensor(0.45968497, requires_grad=True)], [tensor(0.46255572, requires_grad=True)], [tensor(0.46542829, requires_grad=True)], [tensor(0.46830264, requires_grad=True)], [tensor(0.47117878, requires_grad=True)], [tensor(0.47405669, requires_grad=True)], [tensor(0.47693635, requires_grad=True)], [tensor(0.47981775, requires_grad=True)], [tensor(0.48270087, requires_grad=True)], [tensor(0.4855857, requires_grad=True)], [tensor(0.48847223, requires_grad=True)], [tensor(0.49136044, requires_grad=True)], [tensor(0.49425031, requires_grad=True)], [tensor(0.49714182, requires_grad=True)], [tensor(0.50003497, requires_grad=True)], [tensor(0.50292974, requires_grad=True)], [tensor(0.5058261, requires_grad=True)], [tensor(0.50872405, requires_grad=True)], [tensor(0.51162357, requires_grad=True)], [tensor(0.51452463, requires_grad=True)], [tensor(0.51742723, requires_grad=True)], [tensor(0.52033133, requires_grad=True)], [tensor(0.52323694, requires_grad=True)], [tensor(0.52614402, requires_grad=True)], [tensor(0.52905256, requires_grad=True)], [tensor(0.53196254, requires_grad=True)], [tensor(0.53487394, requires_grad=True)], [tensor(0.53778675, requires_grad=True)], [tensor(0.54070093, requires_grad=True)], [tensor(0.54361648, requires_grad=True)], [tensor(0.54653336, requires_grad=True)], [tensor(0.54945157, requires_grad=True)], [tensor(0.55237108, requires_grad=True)], [tensor(0.55529186, requires_grad=True)], [tensor(0.5582139, requires_grad=True)], [tensor(0.56113717, requires_grad=True)], [tensor(0.56406165, requires_grad=True)], [tensor(0.56698732, requires_grad=True)], [tensor(0.56991415, requires_grad=True)], [tensor(0.57284212, requires_grad=True)], [tensor(0.57577121, requires_grad=True)], [tensor(0.57870138, requires_grad=True)], [tensor(0.58163262, requires_grad=True)], [tensor(0.5845649, requires_grad=True)], [tensor(0.58749819, requires_grad=True)], [tensor(0.59043247, requires_grad=True)], [tensor(0.59336771, requires_grad=True)], [tensor(0.59630388, requires_grad=True)], [tensor(0.59924095, requires_grad=True)], [tensor(0.60217889, requires_grad=True)], [tensor(0.60511767, requires_grad=True)], [tensor(0.60805727, requires_grad=True)], [tensor(0.61099766, requires_grad=True)], [tensor(0.61393879, requires_grad=True)], [tensor(0.61688064, requires_grad=True)], [tensor(0.61982318, requires_grad=True)], [tensor(0.62276637, requires_grad=True)], [tensor(0.62571018, requires_grad=True)], [tensor(0.62865458, requires_grad=True)], [tensor(0.63159952, requires_grad=True)], [tensor(0.63454498, requires_grad=True)], [tensor(0.63749091, requires_grad=True)], [tensor(0.64043727, requires_grad=True)], [tensor(0.64338403, requires_grad=True)], [tensor(0.64633115, requires_grad=True)], [tensor(0.64927859, requires_grad=True)], [tensor(0.6522263, requires_grad=True)], [tensor(0.65517425, requires_grad=True)], [tensor(0.65812238, requires_grad=True)], [tensor(0.66107066, requires_grad=True)], [tensor(0.66401903, requires_grad=True)], [tensor(0.66696746, requires_grad=True)], [tensor(0.66991588, requires_grad=True)], [tensor(0.67286426, requires_grad=True)], [tensor(0.67581255, requires_grad=True)], [tensor(0.67876068, requires_grad=True)], [tensor(0.68170861, requires_grad=True)], [tensor(0.68465628, requires_grad=True)], [tensor(0.68760364, requires_grad=True)], [tensor(0.69055062, requires_grad=True)], [tensor(0.69349718, requires_grad=True)], [tensor(0.69644324, requires_grad=True)], [tensor(0.69938875, requires_grad=True)], [tensor(0.70233363, requires_grad=True)], [tensor(0.70527783, requires_grad=True)], [tensor(0.70822128, requires_grad=True)], [tensor(0.7111639, requires_grad=True)], [tensor(0.71410562, requires_grad=True)], [tensor(0.71704637, requires_grad=True)], [tensor(0.71998607, requires_grad=True)], [tensor(0.72292464, requires_grad=True)], [tensor(0.725862, requires_grad=True)], [tensor(0.72879807, requires_grad=True)], [tensor(0.73173275, requires_grad=True)], [tensor(0.73466596, requires_grad=True)], [tensor(0.73759761, requires_grad=True)], [tensor(0.74052759, requires_grad=True)], [tensor(0.74345581, requires_grad=True)], [tensor(0.74638216, requires_grad=True)], [tensor(0.74930655, requires_grad=True)], [tensor(0.75222884, requires_grad=True)], [tensor(0.75514895, requires_grad=True)], [tensor(0.75806673, requires_grad=True)], [tensor(0.76098207, requires_grad=True)], [tensor(0.76389485, requires_grad=True)], [tensor(0.76680492, requires_grad=True)], [tensor(0.76971215, requires_grad=True)], [tensor(0.7726164, requires_grad=True)], [tensor(0.77551751, requires_grad=True)], [tensor(0.77841533, requires_grad=True)], [tensor(0.78130969, requires_grad=True)], [tensor(0.78420043, requires_grad=True)], [tensor(0.78708736, requires_grad=True)], [tensor(0.78997031, requires_grad=True)], [tensor(0.79284907, requires_grad=True)], [tensor(0.79572344, requires_grad=True)], [tensor(0.79859321, requires_grad=True)], [tensor(0.80145816, requires_grad=True)], [tensor(0.80431804, requires_grad=True)], [tensor(0.80717262, requires_grad=True)], [tensor(0.81002163, requires_grad=True)], [tensor(0.81286481, requires_grad=True)], [tensor(0.81570185, requires_grad=True)], [tensor(0.81853246, requires_grad=True)], [tensor(0.82135631, requires_grad=True)], [tensor(0.82417306, requires_grad=True)], [tensor(0.82698236, requires_grad=True)], [tensor(0.82978381, requires_grad=True)], [tensor(0.83257701, requires_grad=True)], [tensor(0.83536153, requires_grad=True)], [tensor(0.8381369, requires_grad=True)], [tensor(0.84090262, requires_grad=True)], [tensor(0.84365817, requires_grad=True)], [tensor(0.84640298, requires_grad=True)], [tensor(0.84913643, requires_grad=True)], [tensor(0.85185787, requires_grad=True)], [tensor(0.85456659, requires_grad=True)], [tensor(0.85726181, requires_grad=True)], [tensor(0.8599427, requires_grad=True)], [tensor(0.86260834, requires_grad=True)], [tensor(0.86525776, requires_grad=True)], [tensor(0.86788984, requires_grad=True)], [tensor(0.8705034, requires_grad=True)], [tensor(0.87309712, requires_grad=True)], [tensor(0.87566952, requires_grad=True)], [tensor(0.87821898, requires_grad=True)], [tensor(0.88074366, requires_grad=True)], [tensor(0.88324151, requires_grad=True)], [tensor(0.88571021, requires_grad=True)], [tensor(0.88814709, requires_grad=True)], [tensor(0.89054912, requires_grad=True)], [tensor(0.89291276, requires_grad=True)], [tensor(0.8952339, requires_grad=True)], [tensor(0.89750768, requires_grad=True)], [tensor(0.89972828, requires_grad=True)], [tensor(0.90188866, requires_grad=True)], [tensor(0.90398014, requires_grad=True)], [tensor(0.90599183, requires_grad=True)], [tensor(0.90790972, requires_grad=True)], [tensor(0.90971527, requires_grad=True)], [tensor(0.91138308, requires_grad=True)], [tensor(0.91287658, requires_grad=True)], [tensor(0.91413976, requires_grad=True)], [tensor(0.91507842, requires_grad=True)], [tensor(0.91550915, requires_grad=True)], [tensor(0.91495909, requires_grad=True)], [tensor(0.90846017, requires_grad=True)]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "num_qubits = 6\n",
    "dev = qml.device(\"default.qubit\", wires=num_qubits)\n",
    "@qml.qnode(dev)\n",
    "def variational_circuit1(params, num_layers, variable_values):\n",
    "\n",
    "    # feature maps\n",
    "    for i, value in enumerate(variable_values):\n",
    "        qml.RY(2 * np.arccos(np.clip(value, -1, 1)), wires=i)\n",
    "\n",
    "    # paramterized variational circuits\n",
    "    for layer in range(num_layers):\n",
    "        for i in range(len(variable_values)):\n",
    "            qml.RZ(params[layer, i, 0], wires=i)\n",
    "            qml.RX(params[layer, i, 1], wires=i)\n",
    "        for i in range(len(variable_values) - 1):\n",
    "            qml.CNOT(wires=[i, i + 1])\n",
    "\n",
    "    \n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(len(variable_values))]\n",
    "global fn_values        \n",
    "# Function to calculate the cost fucntion\n",
    "def cost_fn1(params, num_layers, variable_values):\n",
    "    fn_values =[] \n",
    "    total_cost = 0\n",
    "    num_iterations = variable_values.shape[1] if len(variable_values.shape) > 1 else variable_values.shape[0]\n",
    "    for i in range(num_iterations):\n",
    "        selected_values = variable_values[:, i] if len(variable_values.shape) > 1 else variable_values\n",
    "        outputs = variational_circuit1(params, num_layers, selected_values)\n",
    "        fn_values.append(outputs)\n",
    "        print(outputs,'      ',selected_values)\n",
    "        cost = np.sum(outputs)\n",
    "        total_cost += cost\n",
    "    return fn_values\n",
    "\n",
    "num_layers = 4\n",
    "params = np.full((num_layers, num_qubits, 2), 0.10861666144252709)\n",
    "\n",
    "# To choose variables to encode\n",
    "chosen_variables = input(f\"Choose the variables to encode from the list {variable_names} (comma-separated): \")\n",
    "chosen_variables = [v.strip() for v in chosen_variables.split(',')]\n",
    "selected_values = np.concatenate([variable_values[v] for v in chosen_variables], axis=0)\n",
    "\n",
    "# To reshape\n",
    "selected_values = selected_values.reshape(1, -1)\n",
    "total_cost1 = cost_fn1(params, num_layers, selected_values)\n",
    "print(f\"Total cost = {total_cost1}\")\n",
    "# print(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cfb611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value 1: 0.9084601739202316\n",
      "Value 2: 0.8868903666041597\n",
      "Value 3: 0.8737680081724576\n",
      "Value 4: 0.8620620015379343\n",
      "Value 5: 0.8511017458050737\n",
      "Value 6: 0.8406267772258806\n",
      "Value 7: 0.8305031633060763\n",
      "Value 8: 0.8206511363957233\n",
      "Value 9: 0.8110185901739627\n",
      "Value 10: 0.8015692390220326\n",
      "Value 11: 0.7922765962681697\n",
      "Value 12: 0.7831206157117535\n",
      "Value 13: 0.7740856838220107\n",
      "Value 14: 0.765159352387455\n",
      "Value 15: 0.7563315027634337\n",
      "Value 16: 0.7475937745082537\n",
      "Value 17: 0.7389391627799855\n",
      "Value 18: 0.7303617272525244\n",
      "Value 19: 0.721856376940048\n",
      "Value 20: 0.71341870803099\n",
      "Value 21: 0.7050448795783057\n",
      "Value 22: 0.696731516763236\n",
      "Value 23: 0.6884756345980237\n",
      "Value 24: 0.6802745770185292\n",
      "Value 25: 0.6721259677296457\n",
      "Value 26: 0.6640276701412977\n",
      "Value 27: 0.6559777544179635\n",
      "Value 28: 0.6479744701539526\n",
      "Value 29: 0.640016223541314\n",
      "Value 30: 0.6321015581577031\n",
      "Value 31: 0.6242291386952579\n",
      "Value 32: 0.6163977370972223\n",
      "Value 33: 0.6086062206798091\n",
      "Value 34: 0.6008535419018054\n",
      "Value 35: 0.5931387295102835\n",
      "Value 36: 0.5854608808422173\n",
      "Value 37: 0.5778191551023434\n",
      "Value 38: 0.5702127674697143\n",
      "Value 39: 0.5626409839110994\n",
      "Value 40: 0.5551031166000419\n",
      "Value 41: 0.5475985198570692\n",
      "Value 42: 0.5401265865401894\n",
      "Value 43: 0.5326867448259138\n",
      "Value 44: 0.5252784553302392\n",
      "Value 45: 0.5179012085265604\n",
      "Value 46: 0.5105545224238284\n",
      "Value 47: 0.503237940473477\n",
      "Value 48: 0.4959510296780836\n",
      "Value 49: 0.48869337887839587\n",
      "Value 50: 0.48146459719855417\n",
      "Value 51: 0.4742643126319033\n",
      "Value 52: 0.4670921707521474\n",
      "Value 53: 0.45994783353645663\n",
      "Value 54: 0.45283097828882946\n",
      "Value 55: 0.44574129665342216\n",
      "Value 56: 0.4386784937088005\n",
      "Value 57: 0.4316422871350902\n",
      "Value 58: 0.42463240644698164\n",
      "Value 59: 0.41764859228628237\n",
      "Value 60: 0.41069059576845335\n",
      "Value 61: 0.40375817787814905\n",
      "Value 62: 0.396851108909334\n",
      "Value 63: 0.38996916794598263\n",
      "Value 64: 0.3831121423798409\n",
      "Value 65: 0.3762798274620142\n",
      "Value 66: 0.3694720258855455\n",
      "Value 67: 0.3626885473963709\n",
      "Value 68: 0.3559292084303323\n",
      "Value 69: 0.34919383177411484\n",
      "Value 70: 0.34248224624823687\n",
      "Value 71: 0.335794286410308\n",
      "Value 72: 0.3291297922770183\n",
      "Value 73: 0.3224886090634276\n",
      "Value 74: 0.3158705869382169\n",
      "Value 75: 0.30927558079376016\n",
      "Value 76: 0.3027034500298895\n",
      "Value 77: 0.2961540583503955\n",
      "Value 78: 0.28962727357132995\n",
      "Value 79: 0.28312296744029136\n",
      "Value 80: 0.2766410154659281\n",
      "Value 81: 0.27018129675695673\n",
      "Value 82: 0.2637436938700455\n",
      "Value 83: 0.25732809266597956\n",
      "Value 84: 0.2509343821735506\n",
      "Value 85: 0.2445624544606788\n",
      "Value 86: 0.23821220451227915\n",
      "Value 87: 0.23188353011446633\n",
      "Value 88: 0.22557633174468505\n",
      "Value 89: 0.21929051246739334\n",
      "Value 90: 0.21302597783497107\n",
      "Value 91: 0.20678263579352496\n",
      "Value 92: 0.20056039659329317\n",
      "Value 93: 0.1943591727033887\n",
      "Value 94: 0.18817887873060757\n",
      "Value 95: 0.1820194313420863\n",
      "Value 96: 0.17588074919156876\n",
      "Value 97: 0.1697627528490815\n",
      "Value 98: 0.16366536473384224\n",
      "Value 99: 0.157588509050191\n",
      "Value 100: 0.15153211172639397\n",
      "Value 101: 0.14549610035617627\n",
      "Value 102: 0.1394804041428065\n",
      "Value 103: 0.13348495384561576\n",
      "Value 104: 0.12750968172881977\n",
      "Value 105: 0.12155452151252016\n",
      "Value 106: 0.11561940832577189\n",
      "Value 107: 0.10970427866161037\n",
      "Value 108: 0.10380907033394227\n",
      "Value 109: 0.09793372243619586\n",
      "Value 110: 0.09207817530165635\n",
      "Value 111: 0.08624237046539573\n",
      "Value 112: 0.08042625062771086\n",
      "Value 113: 0.07462975961901475\n",
      "Value 114: 0.06885284236609313\n",
      "Value 115: 0.06309544485967006\n",
      "Value 116: 0.05735751412322565\n",
      "Value 117: 0.05163899818298612\n",
      "Value 118: 0.045939846039064425\n",
      "Value 119: 0.04026000763766263\n",
      "Value 120: 0.03459943384431585\n",
      "Value 121: 0.02895807641811432\n",
      "Value 122: 0.023335887986865866\n",
      "Value 123: 0.017732822023158235\n",
      "Value 124: 0.012148832821270994\n",
      "Value 125: 0.006583875474919676\n",
      "Value 126: 0.0010379058557717369\n",
      "Value 127: -0.004489119407277975\n",
      "Value 128: -0.009997242948121043\n",
      "Value 129: -0.015486506682753032\n",
      "Value 130: -0.020956951827939496\n",
      "Value 131: -0.02640861891924634\n",
      "Value 132: -0.0318415478284686\n",
      "Value 133: -0.03725577778047601\n",
      "Value 134: -0.042651347369503934\n",
      "Value 135: -0.04802829457490665\n",
      "Value 136: -0.05338665677640564\n",
      "Value 137: -0.05872647076883847\n",
      "Value 138: -0.06404777277643625\n",
      "Value 139: -0.06935059846665476\n",
      "Value 140: -0.07463498296355514\n",
      "Value 141: -0.07990096086078025\n",
      "Value 142: -0.08514856623411754\n",
      "Value 143: -0.09037783265368032\n",
      "Value 144: -0.09558879319570818\n",
      "Value 145: -0.10078148045401808\n",
      "Value 146: -0.10595592655110136\n",
      "Value 147: -0.11111216314889594\n",
      "Value 148: -0.11625022145922748\n",
      "Value 149: -0.12137013225395354\n",
      "Value 150: -0.12647192587479916\n",
      "Value 151: -0.13155563224291428\n",
      "Value 152: -0.13662128086814979\n",
      "Value 153: -0.14166890085806766\n",
      "Value 154: -0.14669852092669217\n",
      "Value 155: -0.1517101694030208\n",
      "Value 156: -0.15670387423928223\n",
      "Value 157: -0.16167966301897402\n",
      "Value 158: -0.16663756296467408\n",
      "Value 159: -0.1715776009456348\n",
      "Value 160: -0.17649980348516536\n",
      "Value 161: -0.18140419676782465\n",
      "Value 162: -0.18629080664640618\n",
      "Value 163: -0.19115965864874257\n",
      "Value 164: -0.19601077798432642\n",
      "Value 165: -0.20084418955075517\n",
      "Value 166: -0.20565991794000682\n",
      "Value 167: -0.2104579874445462\n",
      "Value 168: -0.21523842206328248\n",
      "Value 169: -0.2200012455073604\n",
      "Value 170: -0.22474648120581137\n",
      "Value 171: -0.2294741523110554\n",
      "Value 172: -0.23418428170426486\n",
      "Value 173: -0.2388768920005903\n",
      "Value 174: -0.2435520055542626\n",
      "Value 175: -0.24820964446355376\n",
      "Value 176: -0.25284983057563104\n",
      "Value 177: -0.25747258549127977\n",
      "Value 178: -0.2620779305695109\n",
      "Value 179: -0.26666588693206883\n",
      "Value 180: -0.27123647546780805\n",
      "Value 181: -0.27578971683698755\n",
      "Value 182: -0.28032563147544476\n",
      "Value 183: -0.2848442395986808\n",
      "Value 184: -0.289345561205844\n",
      "Value 185: -0.2938296160836191\n",
      "Value 186: -0.2982964238100297\n",
      "Value 187: -0.3027460037581513\n",
      "Value 188: -0.3071783750997315\n",
      "Value 189: -0.3115935568087389\n",
      "Value 190: -0.31599156766481623\n",
      "Value 191: -0.32037242625667195\n",
      "Value 192: -0.3247361509853785\n",
      "Value 193: -0.3290827600676079\n",
      "Value 194: -0.33341227153879116\n",
      "Value 195: -0.3377247032562053\n",
      "Value 196: -0.3420200729019928\n",
      "Value 197: -0.3462983979861201\n",
      "Value 198: -0.3505596958492659\n",
      "Value 199: -0.35480398366564064\n",
      "Value 200: -0.3590312784457615\n",
      "Value 201: -0.36324159703915354\n",
      "Value 202: -0.367434956136997\n",
      "Value 203: -0.37161137227471785\n",
      "Value 204: -0.37577086183453\n",
      "Value 205: -0.37991344104790725\n",
      "Value 206: -0.3840391259980265\n",
      "Value 207: -0.3881479326221365\n",
      "Value 208: -0.39223987671389615\n",
      "Value 209: -0.3963149739256531\n",
      "Value 210: -0.4003732397706818\n",
      "Value 211: -0.4044146896253705\n",
      "Value 212: -0.40843933873136634\n",
      "Value 213: -0.4124472021976817\n",
      "Value 214: -0.4164382950027468\n",
      "Value 215: -0.4204126319964349\n",
      "Value 216: -0.42437022790203427\n",
      "Value 217: -0.4283110973181912\n",
      "Value 218: -0.4322352547208079\n",
      "Value 219: -0.43614271446490493\n",
      "Value 220: -0.4400334907864527\n",
      "Value 221: -0.4439075978041577\n",
      "Value 222: -0.4477650495212188\n",
      "Value 223: -0.4516058598270556\n",
      "Value 224: -0.45543004249899105\n",
      "Value 225: -0.45923761120391227\n",
      "Value 226: -0.46302857949989906\n",
      "Value 227: -0.4668029608378143\n",
      "Value 228: -0.4705607685628719\n",
      "Value 229: -0.4743020159161719\n",
      "Value 230: -0.4780267160362086\n",
      "Value 231: -0.4817348819603505\n",
      "Value 232: -0.4854265266262908\n",
      "Value 233: -0.48910166287347495\n",
      "Value 234: -0.49276030344449806\n",
      "Value 235: -0.49640246098648017\n",
      "Value 236: -0.5000281480524164\n",
      "Value 237: -0.5036373771024985\n",
      "Value 238: -0.5072301605054216\n",
      "Value 239: -0.5108065105396549\n",
      "Value 240: -0.5143664393947034\n",
      "Value 241: -0.5179099591723384\n",
      "Value 242: -0.5214370818878082\n",
      "Value 243: -0.5249478194710279\n",
      "Value 244: -0.5284421837677516\n",
      "Value 245: -0.5319201865407175\n",
      "Value 246: -0.5353818394707824\n",
      "Value 247: -0.5388271541580241\n",
      "Value 248: -0.5422561421228398\n",
      "Value 249: -0.5456688148070142\n",
      "Value 250: -0.5490651835747733\n",
      "Value 251: -0.552445259713823\n",
      "Value 252: -0.5558090544363664\n",
      "Value 253: -0.5591565788801055\n",
      "Value 254: -0.5624878441092265\n",
      "Value 255: -0.5658028611153677\n",
      "Value 256: -0.5691016408185754\n",
      "Value 257: -0.5723841940682383\n",
      "Value 258: -0.5756505316440061\n",
      "Value 259: -0.578900664256706\n",
      "Value 260: -0.5821346025492224\n",
      "Value 261: -0.5853523570973851\n",
      "Value 262: -0.5885539384108266\n",
      "Value 263: -0.5917393569338328\n",
      "Value 264: -0.5949086230461826\n",
      "Value 265: -0.5980617470639664\n",
      "Value 266: -0.6011987392403957\n",
      "Value 267: -0.6043196097666066\n",
      "Value 268: -0.6074243687724369\n",
      "Value 269: -0.6105130263272035\n",
      "Value 270: -0.6135855924404596\n",
      "Value 271: -0.6166420770627467\n",
      "Value 272: -0.61968249008633\n",
      "Value 273: -0.6227068413459222\n",
      "Value 274: -0.6257151406194029\n",
      "Value 275: -0.6287073976285187\n",
      "Value 276: -0.6316836220395795\n",
      "Value 277: -0.6346438234641396\n",
      "Value 278: -0.6375880114596673\n",
      "Value 279: -0.6405161955302163\n",
      "Value 280: -0.643428385127069\n",
      "Value 281: -0.646324589649387\n",
      "Value 282: -0.6492048184448371\n",
      "Value 283: -0.6520690808102252\n",
      "Value 284: -0.6549173859921024\n",
      "Value 285: -0.6577497431873769\n",
      "Value 286: -0.6605661615439103\n",
      "Value 287: -0.6633666501611063\n",
      "Value 288: -0.6661512180904885\n",
      "Value 289: -0.6689198743362783\n",
      "Value 290: -0.6716726278559548\n",
      "Value 291: -0.6744094875608104\n",
      "Value 292: -0.6771304623165026\n",
      "Value 293: -0.6798355609435887\n",
      "Value 294: -0.6825247922180689\n",
      "Value 295: -0.6851981648718992\n",
      "Value 296: -0.6878556875935178\n",
      "Value 297: -0.6904973690283551\n",
      "Value 298: -0.6931232177793359\n",
      "Value 299: -0.6957332424073781\n",
      "Value 300: -0.6983274514318822\n",
      "Value 301: -0.7009058533312156\n",
      "Value 302: -0.7034684565431907\n",
      "Value 303: -0.7060152694655331\n",
      "Value 304: -0.7085463004563501\n",
      "Value 305: -0.7110615578345836\n",
      "Value 306: -0.7135610498804685\n",
      "Value 307: -0.716044784835975\n",
      "Value 308: -0.718512770905249\n",
      "Value 309: -0.7209650162550496\n",
      "Value 310: -0.7234015290151758\n",
      "Value 311: -0.7258223172788897\n",
      "Value 312: -0.7282273891033362\n",
      "Value 313: -0.7306167525099532\n",
      "Value 314: -0.732990415484883\n",
      "Value 315: -0.7353483859793695\n",
      "Value 316: -0.7376906719101567\n",
      "Value 317: -0.7400172811598853\n",
      "Value 318: -0.7423282215774722\n",
      "Value 319: -0.7446235009784992\n",
      "Value 320: -0.746903127145586\n",
      "Value 321: -0.7491671078287656\n",
      "Value 322: -0.7514154507458524\n",
      "Value 323: -0.7536481635828028\n",
      "Value 324: -0.755865253994081\n",
      "Value 325: -0.7580667296030044\n",
      "Value 326: -0.7602525980021049\n",
      "Value 327: -0.762422866753465\n",
      "Value 328: -0.7645775433890679\n",
      "Value 329: -0.7667166354111316\n",
      "Value 330: -0.768840150292443\n",
      "Value 331: -0.7709480954766889\n",
      "Value 332: -0.7730404783787833\n",
      "Value 333: -0.7751173063851876\n",
      "Value 334: -0.77717858685423\n",
      "Value 335: -0.7792243271164208\n",
      "Value 336: -0.7812545344747643\n",
      "Value 337: -0.7832692162050645\n",
      "Value 338: -0.7852683795562319\n",
      "Value 339: -0.7872520317505808\n",
      "Value 340: -0.7892201799841312\n",
      "Value 341: -0.7911728314268984\n",
      "Value 342: -0.7931099932231844\n",
      "Value 343: -0.7950316724918705\n",
      "Value 344: -0.7969378763266924\n",
      "Value 345: -0.7988286117965302\n",
      "Value 346: -0.8007038859456795\n",
      "Value 347: -0.8025637057941317\n",
      "Value 348: -0.8044080783378413\n",
      "Value 349: -0.806237010548999\n",
      "Value 350: -0.8080505093762947\n",
      "Value 351: -0.8098485817451822\n",
      "Value 352: -0.8116312345581406\n",
      "Value 353: -0.8133984746949281\n",
      "Value 354: -0.8151503090128431\n",
      "Value 355: -0.8168867443469691\n",
      "Value 356: -0.8186077875104336\n",
      "Value 357: -0.8203134452946432\n",
      "Value 358: -0.8220037244695403\n",
      "Value 359: -0.8236786317838365\n",
      "Value 360: -0.8253381739652565\n",
      "Value 361: -0.8269823577207727\n",
      "Value 362: -0.8286111897368421\n",
      "Value 363: -0.8302246766796375\n",
      "Value 364: -0.831822825195276\n",
      "Value 365: -0.83340564191005\n",
      "Value 366: -0.8349731334306514\n",
      "Value 367: -0.8365253063443921\n",
      "Value 368: -0.838062167219429\n",
      "Value 369: -0.8395837226049809\n",
      "Value 370: -0.8410899790315471\n",
      "Value 371: -0.8425809430111184\n",
      "Value 372: -0.8440566210373954\n",
      "Value 373: -0.8455170195859918\n",
      "Value 374: -0.8469621451146516\n",
      "Value 375: -0.8483920040634491\n",
      "Value 376: -0.8498066028549964\n",
      "Value 377: -0.8512059478946475\n",
      "Value 378: -0.8525900455706965\n",
      "Value 379: -0.8539589022545795\n",
      "Value 380: -0.8553125243010703\n",
      "Value 381: -0.8566509180484762\n",
      "Value 382: -0.8579740898188328\n",
      "Value 383: -0.8592820459180981\n",
      "Value 384: -0.8605747926363359\n",
      "Value 385: -0.8618523362479125\n",
      "Value 386: -0.8631146830116811\n",
      "Value 387: -0.8643618391711649\n",
      "Value 388: -0.8655938109547451\n",
      "Value 389: -0.86681060457584\n",
      "Value 390: -0.8680122262330882\n",
      "Value 391: -0.8691986821105258\n",
      "Value 392: -0.8703699783777665\n",
      "Value 393: -0.8715261211901764\n",
      "Value 394: -0.8726671166890492\n",
      "Value 395: -0.8737929710017793\n",
      "Value 396: -0.8749036902420355\n",
      "Value 397: -0.875999280509931\n",
      "Value 398: -0.8770797478921906\n",
      "Value 399: -0.8781450984623203\n",
      "Value 400: -0.879195338280777\n",
      "Value 401: -0.880230473395128\n",
      "Value 402: -0.8812505098402199\n",
      "Value 403: -0.8822554536383388\n",
      "Value 404: -0.883245310799372\n",
      "Value 405: -0.884220087320972\n",
      "Value 406: -0.8851797891887099\n",
      "Value 407: -0.8861244223762371\n",
      "Value 408: -0.8870539928454424\n",
      "Value 409: -0.8879685065466079\n",
      "Value 410: -0.8888679694185587\n",
      "Value 411: -0.8897523873888229\n",
      "Value 412: -0.8906217663737814\n",
      "Value 413: -0.8914761122788181\n",
      "Value 414: -0.8923154309984712\n",
      "Value 415: -0.893139728416584\n",
      "Value 416: -0.89394901040645\n",
      "Value 417: -0.8947432828309623\n",
      "Value 418: -0.8955225515427602\n",
      "Value 419: -0.896286822384371\n",
      "Value 420: -0.8970361011883614\n",
      "Value 421: -0.8977703937774717\n",
      "Value 422: -0.898489705964766\n",
      "Value 423: -0.8991940435537706\n",
      "Value 424: -0.8998834123386148\n",
      "Value 425: -0.9005578181041699\n",
      "Value 426: -0.9012172666261903\n",
      "Value 427: -0.9018617636714508\n",
      "Value 428: -0.9024913149978827\n",
      "Value 429: -0.9031059263547103\n",
      "Value 430: -0.9037056034825911\n",
      "Value 431: -0.9042903521137426\n",
      "Value 432: -0.9048601779720848\n",
      "Value 433: -0.905415086773368\n",
      "Value 434: -0.9059550842253068\n",
      "Value 435: -0.9064801760277136\n",
      "Value 436: -0.906990367872627\n",
      "Value 437: -0.9074856654444464\n",
      "Value 438: -0.9079660744200571\n",
      "Value 439: -0.9084316004689627\n",
      "Value 440: -0.9088822492534122\n",
      "Value 441: -0.9093180264285283\n",
      "Value 442: -0.9097389376424351\n",
      "Value 443: -0.9101449885363828\n",
      "Value 444: -0.9105361847448762\n",
      "Value 445: -0.9109125318957983\n",
      "Value 446: -0.9112740356105342\n",
      "Value 447: -0.9116207015040992\n",
      "Value 448: -0.9119525351852572\n",
      "Value 449: -0.9122695422566488\n",
      "Value 450: -0.9125717283149105\n",
      "Value 451: -0.9128590989507963\n",
      "Value 452: -0.9131316597493028\n",
      "Value 453: -0.9133894162897862\n",
      "Value 454: -0.9136323741460866\n",
      "Value 455: -0.9138605388866439\n",
      "Value 456: -0.9140739160746211\n",
      "Value 457: -0.9142725112680204\n",
      "Value 458: -0.9144563300198049\n",
      "Value 459: -0.9146253778780121\n",
      "Value 460: -0.9147796603858783\n",
      "Value 461: -0.9149191830819503\n",
      "Value 462: -0.9150439515002046\n",
      "Value 463: -0.9151539711701638\n",
      "Value 464: -0.9152492476170124\n",
      "Value 465: -0.915329786361714\n",
      "Value 466: -0.915395592921125\n",
      "Value 467: -0.91544667280811\n",
      "Value 468: -0.9154830315316582\n",
      "Value 469: -0.9155046745969943\n",
      "Value 470: -0.9155116075056974\n",
      "Value 471: -0.9155038357558096\n",
      "Value 472: -0.9154813648419552\n",
      "Value 473: -0.9154442002554489\n",
      "Value 474: -0.9153923474844093\n",
      "Value 475: -0.9153258120138761\n",
      "Value 476: -0.9152445993259161\n",
      "Value 477: -0.91514871489974\n",
      "Value 478: -0.9150381642118124\n",
      "Value 479: -0.9149129527359637\n",
      "Value 480: -0.9147730859435022\n",
      "Value 481: -0.9146185693033233\n",
      "Value 482: -0.914449408282023\n",
      "Value 483: -0.9142656083440068\n",
      "Value 484: -0.9140671749516021\n",
      "Value 485: -0.9138541135651669\n",
      "Value 486: -0.9136264296432007\n",
      "Value 487: -0.9133841286424552\n",
      "Value 488: -0.9131272160180433\n",
      "Value 489: -0.9128556972235504\n",
      "Value 490: -0.9125695777111422\n",
      "Value 491: -0.9122688629316761\n",
      "Value 492: -0.9119535583348088\n",
      "Value 493: -0.911623669369108\n",
      "Value 494: -0.9112792014821594\n",
      "Value 495: -0.9109201601206774\n",
      "Value 496: -0.9105465507306141\n",
      "Value 497: -0.9101583787572667\n",
      "Value 498: -0.9097556496453892\n",
      "Value 499: -0.9093383688392995\n",
      "Value 500: -0.9089065417829891\n",
      "Value 501: -0.9084601739202316\n",
      "Value 502: -0.9079992706946916\n",
      "Value 503: -0.9075238375500332\n",
      "Value 504: -0.9070338799300294\n",
      "Value 505: -0.9065294032786733\n",
      "Value 506: -0.9060104130402814\n",
      "Value 507: -0.9054769146596078\n",
      "Value 508: -0.9049289135819503\n",
      "Value 509: -0.9043664152532613\n",
      "Value 510: -0.9037894251202544\n",
      "Value 511: -0.9031979486305152\n",
      "Value 512: -0.9025919912326118\n",
      "Value 513: -0.9019715583762005\n",
      "Value 514: -0.9013366555121396\n",
      "Value 515: -0.900687288092595\n",
      "Value 516: -0.9000234615711501\n",
      "Value 517: -0.8993451814029192\n",
      "Value 518: -0.8986524530446539\n",
      "Value 519: -0.8979452819548539\n",
      "Value 520: -0.8972236735938768\n",
      "Value 521: -0.8964876334240505\n",
      "Value 522: -0.8957371669097799\n",
      "Value 523: -0.8949722795176609\n",
      "Value 524: -0.8941929767165903\n",
      "Value 525: -0.8933992639778746\n",
      "Value 526: -0.8925911467753456\n",
      "Value 527: -0.8917686305854663\n",
      "Value 528: -0.8909317208874477\n",
      "Value 529: -0.890080423163359\n",
      "Value 530: -0.8892147428982367\n",
      "Value 531: -0.8883346855802015\n",
      "Value 532: -0.8874402567005688\n",
      "Value 533: -0.8865314617539604\n",
      "Value 534: -0.8856083062384198\n",
      "Value 535: -0.8846707956555243\n",
      "Value 536: -0.8837189355105018\n",
      "Value 537: -0.8827527313123394\n",
      "Value 538: -0.881772188573902\n",
      "Value 539: -0.8807773128120467\n",
      "Value 540: -0.8797681095477359\n",
      "Value 541: -0.8787445843061553\n",
      "Value 542: -0.8777067426168264\n",
      "Value 543: -0.8766545900137257\n",
      "Value 544: -0.8755881320354026\n",
      "Value 545: -0.8745073742250895\n",
      "Value 546: -0.8734123221308265\n",
      "Value 547: -0.8723029813055763\n",
      "Value 548: -0.8711793573073398\n",
      "Value 549: -0.8700414556992822\n",
      "Value 550: -0.8688892820498415\n",
      "Value 551: -0.867722841932858\n",
      "Value 552: -0.8665421409276887\n",
      "Value 553: -0.8653471846193288\n",
      "Value 554: -0.8641379785985347\n",
      "Value 555: -0.8629145284619418\n",
      "Value 556: -0.8616768398121898\n",
      "Value 557: -0.8604249182580437\n",
      "Value 558: -0.8591587694145174\n",
      "Value 559: -0.8578783989029972\n",
      "Value 560: -0.856583812351367\n",
      "Value 561: -0.8552750153941296\n",
      "Value 562: -0.8539520136725364\n",
      "Value 563: -0.8526148128347111\n",
      "Value 564: -0.851263418535776\n",
      "Value 565: -0.8498978364379808\n",
      "Value 566: -0.8485180722108283\n",
      "Value 567: -0.8471241315312057\n",
      "Value 568: -0.8457160200835095\n",
      "Value 569: -0.8442937435597808\n",
      "Value 570: -0.842857307659831\n",
      "Value 571: -0.8414067180913742\n",
      "Value 572: -0.8399419805701623\n",
      "Value 573: -0.8384631008201131\n",
      "Value 574: -0.8369700845734466\n",
      "Value 575: -0.8354629375708175\n",
      "Value 576: -0.8339416655614516\n",
      "Value 577: -0.8324062743032813\n",
      "Value 578: -0.8308567695630802\n",
      "Value 579: -0.8292931571166019\n",
      "Value 580: -0.8277154427487186\n",
      "Value 581: -0.8261236322535603\n",
      "Value 582: -0.8245177314346523\n",
      "Value 583: -0.8228977461050577\n",
      "Value 584: -0.8212636820875201\n",
      "Value 585: -0.819615545214602\n",
      "Value 586: -0.8179533413288345\n",
      "Value 587: -0.8162770762828546\n",
      "Value 588: -0.8145867559395564\n",
      "Value 589: -0.8128823861722334\n",
      "Value 590: -0.8111639728647276\n",
      "Value 591: -0.8094315219115785\n",
      "Value 592: -0.8076850392181703\n",
      "Value 593: -0.8059245307008824\n",
      "Value 594: -0.8041500022872435\n",
      "Value 595: -0.8023614599160804\n",
      "Value 596: -0.8005589095376724\n",
      "Value 597: -0.79874235711391\n",
      "Value 598: -0.7969118086184439\n",
      "Value 599: -0.7950672700368463\n",
      "Value 600: -0.7932087473667684\n",
      "Value 601: -0.7913362466180984\n",
      "Value 602: -0.7894497738131221\n",
      "Value 603: -0.7875493349866856\n",
      "Value 604: -0.7856349361863569\n",
      "Value 605: -0.7837065834725923\n",
      "Value 606: -0.7817642829188982\n",
      "Value 607: -0.7798080406120003\n",
      "Value 608: -0.7778378626520108\n",
      "Value 609: -0.7758537551525979\n",
      "Value 610: -0.7738557242411568\n",
      "Value 611: -0.7718437760589807\n",
      "Value 612: -0.7698179167614364\n",
      "Value 613: -0.7677781525181374\n",
      "Value 614: -0.7657244895131197\n",
      "Value 615: -0.7636569339450214\n",
      "Value 616: -0.7615754920272619\n",
      "Value 617: -0.7594801699882209\n",
      "Value 618: -0.7573709740714233\n",
      "Value 619: -0.7552479105357208\n",
      "Value 620: -0.7531109856554796\n",
      "Value 621: -0.750960205720766\n",
      "Value 622: -0.7487955770375361\n",
      "Value 623: -0.7466171059278244\n",
      "Value 624: -0.7444247987299399\n",
      "Value 625: -0.7422186617986564\n",
      "Value 626: -0.7399987015054095\n",
      "Value 627: -0.7377649242384933\n",
      "Value 628: -0.7355173364032612\n",
      "Value 629: -0.7332559444223261\n",
      "Value 630: -0.7309807547357635\n",
      "Value 631: -0.7286917738013142\n",
      "Value 632: -0.7263890080945946\n",
      "Value 633: -0.7240724641093044\n",
      "Value 634: -0.7217421483574349\n",
      "Value 635: -0.7193980673694849\n",
      "Value 636: -0.7170402276946725\n",
      "Value 637: -0.7146686359011549\n",
      "Value 638: -0.7122832985762462\n",
      "Value 639: -0.709884222326636\n",
      "Value 640: -0.707471413778616\n",
      "Value 641: -0.705044879578306\n",
      "Value 642: -0.7026046263918773\n",
      "Value 643: -0.7001506609057858\n",
      "Value 644: -0.6976829898270053\n",
      "Value 645: -0.6952016198832612\n",
      "Value 646: -0.6927065578232644\n",
      "Value 647: -0.6901978104169548\n",
      "Value 648: -0.6876753844557439\n",
      "Value 649: -0.685139286752755\n",
      "Value 650: -0.6825895241430742\n",
      "Value 651: -0.6800261034839973\n",
      "Value 652: -0.6774490316552856\n",
      "Value 653: -0.674858315559416\n",
      "Value 654: -0.6722539621218431\n",
      "Value 655: -0.6696359782912567\n",
      "Value 656: -0.667004371039847\n",
      "Value 657: -0.6643591473635686\n",
      "Value 658: -0.6617003142824138\n",
      "Value 659: -0.6590278788406787\n",
      "Value 660: -0.6563418481072405\n",
      "Value 661: -0.6536422291758388\n",
      "Value 662: -0.6509290291653507\n",
      "Value 663: -0.6482022552200815\n",
      "Value 664: -0.6454619145100455\n",
      "Value 665: -0.6427080142312614\n",
      "Value 666: -0.6399405616060455\n",
      "Value 667: -0.6371595638833079\n",
      "Value 668: -0.634365028338852\n",
      "Value 669: -0.631556962275682\n",
      "Value 670: -0.628735373024308\n",
      "Value 671: -0.6259002679430588\n",
      "Value 672: -0.6230516544183964\n",
      "Value 673: -0.6201895398652338\n",
      "Value 674: -0.6173139317272569\n",
      "Value 675: -0.6144248374772557\n",
      "Value 676: -0.6115222646174455\n",
      "Value 677: -0.6086062206798091\n",
      "Value 678: -0.6056767132264319\n",
      "Value 679: -0.6027337498498426\n",
      "Value 680: -0.5997773381733607\n",
      "Value 681: -0.5968074858514493\n",
      "Value 682: -0.5938242005700662\n",
      "Value 683: -0.5908274900470238\n",
      "Value 684: -0.5878173620323566\n",
      "Value 685: -0.5847938243086838\n",
      "Value 686: -0.5817568846915877\n",
      "Value 687: -0.578706551029985\n",
      "Value 688: -0.5756428312065149\n",
      "Value 689: -0.5725657331379231\n",
      "Value 690: -0.569475264775454\n",
      "Value 691: -0.5663714341052477\n",
      "Value 692: -0.5632542491487438\n",
      "Value 693: -0.5601237179630868\n",
      "Value 694: -0.5569798486415393\n",
      "Value 695: -0.5538226493138996\n",
      "Value 696: -0.550652128146926\n",
      "Value 697: -0.5474682933447659\n",
      "Value 698: -0.5442711531493895\n",
      "Value 699: -0.5410607158410297\n",
      "Value 700: -0.5378369897386311\n",
      "Value 701: -0.5345999832002992\n",
      "Value 702: -0.5313497046237607\n",
      "Value 703: -0.5280861624468272\n",
      "Value 704: -0.5248093651478662\n",
      "Value 705: -0.5215193212462785\n",
      "Value 706: -0.5182160393029815\n",
      "Value 707: -0.5148995279209011\n",
      "Value 708: -0.5115697957454661\n",
      "Value 709: -0.5082268514651156\n",
      "Value 710: -0.5048707038118075\n",
      "Value 711: -0.501501361561538\n",
      "Value 712: -0.4981188335348673\n",
      "Value 713: -0.4947231285974508\n",
      "Value 714: -0.49131425566058284\n",
      "Value 715: -0.4878922236817425\n",
      "Value 716: -0.4844570416651488\n",
      "Value 717: -0.4810087186623291\n",
      "Value 718: -0.47754726377268447\n",
      "Value 719: -0.4740726861440771\n",
      "Value 720: -0.47058499497341494\n",
      "Value 721: -0.4670841995072494\n",
      "Value 722: -0.463570309042386\n",
      "Value 723: -0.46004333292649247\n",
      "Value 724: -0.4565032805587292\n",
      "Value 725: -0.45295016139038\n",
      "Value 726: -0.4493839849254966\n",
      "Value 727: -0.4458047607215482\n",
      "Value 728: -0.4422124983900908\n",
      "Value 729: -0.43860720759743244\n",
      "Value 730: -0.4349888980653197\n",
      "Value 731: -0.4313575795716326\n",
      "Value 732: -0.4277132619510845\n",
      "Value 733: -0.4240559550959399\n",
      "Value 734: -0.42038566895673957\n",
      "Value 735: -0.41670241354303783\n",
      "Value 736: -0.4130061989241507\n",
      "Value 737: -0.4092970352299181\n",
      "Value 738: -0.40557493265147254\n",
      "Value 739: -0.4018399014420286\n",
      "Value 740: -0.3980919519176758\n",
      "Value 741: -0.39433109445819237\n",
      "Value 742: -0.390557339507865\n",
      "Value 743: -0.3867706975763269\n",
      "Value 744: -0.38297117923940466\n",
      "Value 745: -0.37915879513998735\n",
      "Value 746: -0.3753335559888974\n",
      "Value 747: -0.3714954725657878\n",
      "Value 748: -0.36764455572004684\n",
      "Value 749: -0.3637808163717189\n",
      "Value 750: -0.35990426551244425\n",
      "Value 751: -0.35601491420640885\n",
      "Value 752: -0.35211277359131404\n",
      "Value 753: -0.34819785487936344\n",
      "Value 754: -0.34427016935826155\n",
      "Value 755: -0.34032972839223685\n",
      "Value 756: -0.33637654342307227\n",
      "Value 757: -0.3324106259711649\n",
      "Value 758: -0.3284319876365934\n",
      "Value 759: -0.3244406401002147\n",
      "Value 760: -0.32043659512476635\n",
      "Value 761: -0.31641986455600235\n",
      "Value 762: -0.3123904603238381\n",
      "Value 763: -0.30834839444352263\n",
      "Value 764: -0.30429367901682663\n",
      "Value 765: -0.3002263262332532\n",
      "Value 766: -0.296146348371275\n",
      "Value 767: -0.29205375779958476\n",
      "Value 768: -0.28794856697837434\n",
      "Value 769: -0.28383078846064047\n",
      "Value 770: -0.279700434893502\n",
      "Value 771: -0.27555751901955444\n",
      "Value 772: -0.2714020536782429\n",
      "Value 773: -0.2672340518072607\n",
      "Value 774: -0.2630535264439764\n",
      "Value 775: -0.25886049072688383\n",
      "Value 776: -0.2546549578970831\n",
      "Value 777: -0.2504369412997901\n",
      "Value 778: -0.2462064543858652\n",
      "Value 779: -0.24196351071338884\n",
      "Value 780: -0.237708123949248\n",
      "Value 781: -0.23344030787076714\n",
      "Value 782: -0.22916007636736296\n",
      "Value 783: -0.22486744344223808\n",
      "Value 784: -0.22056242321409703\n",
      "Value 785: -0.2162450299189087\n",
      "Value 786: -0.21191527791169507\n",
      "Value 787: -0.2075731816683597\n",
      "Value 788: -0.20321875578754722\n",
      "Value 789: -0.19885201499254668\n",
      "Value 790: -0.19447297413323006\n",
      "Value 791: -0.1900816481880292\n",
      "Value 792: -0.1856780522659548\n",
      "Value 793: -0.18126220160865547\n",
      "Value 794: -0.17683411159251966\n",
      "Value 795: -0.17239379773082053\n",
      "Value 796: -0.16794127567590633\n",
      "Value 797: -0.16347656122143528\n",
      "Value 798: -0.158999670304658\n",
      "Value 799: -0.15451061900874857\n",
      "Value 800: -0.1500094235651842\n",
      "Value 801: -0.14549610035617616\n",
      "Value 802: -0.14097066591715152\n",
      "Value 803: -0.1364331369392895\n",
      "Value 804: -0.1318835302721169\n",
      "Value 805: -0.12732186292614783\n",
      "Value 806: -0.12274815207559764\n",
      "Value 807: -0.11816241506114133\n",
      "Value 808: -0.11356466939274457\n",
      "Value 809: -0.10895493275255286\n",
      "Value 810: -0.10433322299784226\n",
      "Value 811: -0.09969955816404275\n",
      "Value 812: -0.09505395646782644\n",
      "Value 813: -0.09039643631026761\n",
      "Value 814: -0.08572701628007207\n",
      "Value 815: -0.08104571515688574\n",
      "Value 816: -0.07635255191467383\n",
      "Value 817: -0.07164754572518639\n",
      "Value 818: -0.06693071596149702\n",
      "Value 819: -0.06220208220162987\n",
      "Value 820: -0.057461664232270726\n",
      "Value 821: -0.05270948205256759\n",
      "Value 822: -0.04794555587802113\n",
      "Value 823: -0.04316990614446914\n",
      "Value 824: -0.03838255351216974\n",
      "Value 825: -0.03358351886998018\n",
      "Value 826: -0.028772823339640485\n",
      "Value 827: -0.023950488280164883\n",
      "Value 828: -0.01911653529233731\n",
      "Value 829: -0.014270986223325177\n",
      "Value 830: -0.009413863171401526\n",
      "Value 831: -0.004545188490795493\n",
      "Value 832: 0.0003350152033401721\n",
      "Value 833: 0.005226725029834733\n",
      "Value 834: 0.010129917836267488\n",
      "Value 835: 0.015044570193608053\n",
      "Value 836: 0.01997065839070994\n",
      "Value 837: 0.024908158428666893\n",
      "Value 838: 0.029857046015011768\n",
      "Value 839: 0.034817296557766386\n",
      "Value 840: 0.03978888515933349\n",
      "Value 841: 0.044771786610221076\n",
      "Value 842: 0.04976597538259697\n",
      "Value 843: 0.05477142562366655\n",
      "Value 844: 0.059788111148872\n",
      "Value 845: 0.06481600543490279\n",
      "Value 846: 0.06985508161250692\n",
      "Value 847: 0.07490531245910853\n",
      "Value 848: 0.0799666703912077\n",
      "Value 849: 0.08503912745657582\n",
      "Value 850: 0.09012265532621694\n",
      "Value 851: 0.09521722528610521\n",
      "Value 852: 0.10032280822867895\n",
      "Value 853: 0.10543937464408865\n",
      "Value 854: 0.1105668946111828\n",
      "Value 855: 0.11570533778823677\n",
      "Value 856: 0.12085467340339329\n",
      "Value 857: 0.126014870244826\n",
      "Value 858: 0.13118589665059832\n",
      "Value 859: 0.13636772049821827\n",
      "Value 860: 0.1415603091938682\n",
      "Value 861: 0.1467636296613089\n",
      "Value 862: 0.15197764833042776\n",
      "Value 863: 0.1572023311254363\n",
      "Value 864: 0.16243764345269313\n",
      "Value 865: 0.16768355018813502\n",
      "Value 866: 0.17294001566430822\n",
      "Value 867: 0.17820700365698067\n",
      "Value 868: 0.1834844773713134\n",
      "Value 869: 0.1887723994275879\n",
      "Value 870: 0.1940707318464473\n",
      "Value 871: 0.19937943603365804\n",
      "Value 872: 0.20469847276434905\n",
      "Value 873: 0.21002780216672706\n",
      "Value 874: 0.21536738370522474\n",
      "Value 875: 0.2207171761630765\n",
      "Value 876: 0.22607713762428583\n",
      "Value 877: 0.23144722545496366\n",
      "Value 878: 0.23682739628400407\n",
      "Value 879: 0.24221760598307313\n",
      "Value 880: 0.2476178096458868\n",
      "Value 881: 0.25302796156672563\n",
      "Value 882: 0.2584480152181769\n",
      "Value 883: 0.2638779232280483\n",
      "Value 884: 0.26931763735543024\n",
      "Value 885: 0.2747671084658577\n",
      "Value 886: 0.2802262865055331\n",
      "Value 887: 0.285695120474568\n",
      "Value 888: 0.2911735583991905\n",
      "Value 889: 0.29666154730287947\n",
      "Value 890: 0.30215903317635917\n",
      "Value 891: 0.30766596094641635\n",
      "Value 892: 0.31318227444346364\n",
      "Value 893: 0.31870791636779766\n",
      "Value 894: 0.32424282825448814\n",
      "Value 895: 0.3297869504368234\n",
      "Value 896: 0.33534022200823127\n",
      "Value 897: 0.3409025807826176\n",
      "Value 898: 0.34647396325301777\n",
      "Value 899: 0.35205430454848763\n",
      "Value 900: 0.35764353838912677\n",
      "Value 901: 0.3632415970391533\n",
      "Value 902: 0.3688484112578983\n",
      "Value 903: 0.37446391024862835\n",
      "Value 904: 0.3800880216050686\n",
      "Value 905: 0.3857206712554876\n",
      "Value 906: 0.39136178340422517\n",
      "Value 907: 0.39701128047049516\n",
      "Value 908: 0.402669083024328\n",
      "Value 909: 0.4083351097194668\n",
      "Value 910: 0.4140092772230477\n",
      "Value 911: 0.41969150014186746\n",
      "Value 912: 0.42538169094503764\n",
      "Value 913: 0.431079759882797\n",
      "Value 914: 0.436785614901252\n",
      "Value 915: 0.4424991615527823\n",
      "Value 916: 0.44822030290184783\n",
      "Value 917: 0.45394893942589165\n",
      "Value 918: 0.4596849689110286\n",
      "Value 919: 0.46542828634217526\n",
      "Value 920: 0.4711787837872484\n",
      "Value 921: 0.47693635027504155\n",
      "Value 922: 0.4827008716663405\n",
      "Value 923: 0.4884722305178141\n",
      "Value 924: 0.4942503059381771\n",
      "Value 925: 0.5000349734360776\n",
      "Value 926: 0.5058261047591166\n",
      "Value 927: 0.5116235677233436\n",
      "Value 928: 0.5174272260325501\n",
      "Value 929: 0.5232369390865691\n",
      "Value 930: 0.5290525617777727\n",
      "Value 931: 0.5348739442748439\n",
      "Value 932: 0.5407009317928383\n",
      "Value 933: 0.5465333643484505\n",
      "Value 934: 0.5523710764992903\n",
      "Value 935: 0.5582138970658719\n",
      "Value 936: 0.5640616488348849\n",
      "Value 937: 0.5699141482421684\n",
      "Value 938: 0.5757712050336603\n",
      "Value 939: 0.5816326219024011\n",
      "Value 940: 0.5874981940994991\n",
      "Value 941: 0.5933677090166973\n",
      "Value 942: 0.5992409457379733\n",
      "Value 943: 0.6051176745572884\n",
      "Value 944: 0.6109976564592997\n",
      "Value 945: 0.6168806425594674\n",
      "Value 946: 0.622766373499599\n",
      "Value 947: 0.6286545787943834\n",
      "Value 948: 0.6345449761239494\n",
      "Value 949: 0.6404372705668592\n",
      "Value 950: 0.6463311537672722\n",
      "Value 951: 0.6522263030291848\n",
      "Value 952: 0.6581223803297674\n",
      "Value 953: 0.664019031242725\n",
      "Value 954: 0.6699158837614028\n",
      "Value 955: 0.6758125470099394\n",
      "Value 956: 0.681708609829085\n",
      "Value 957: 0.6876036392214141\n",
      "Value 958: 0.6934971786383619\n",
      "Value 959: 0.6993887460888782\n",
      "Value 960: 0.7052778320463616\n",
      "Value 961: 0.711163897126804\n",
      "Value 962: 0.7170463695067208\n",
      "Value 963: 0.7229246420441164\n",
      "Value 964: 0.7287980690595208\n",
      "Value 965: 0.734665962726476\n",
      "Value 966: 0.7405275890117526\n",
      "Value 967: 0.7463821630944028\n",
      "Value 968: 0.7522288441791612\n",
      "Value 969: 0.7580667296030043\n",
      "Value 970: 0.7638948481130037\n",
      "Value 971: 0.7697121521679453\n",
      "Value 972: 0.7755175090840434\n",
      "Value 973: 0.7813096908045407\n",
      "Value 974: 0.7870873620215761\n",
      "Value 975: 0.7928490663128049\n",
      "Value 976: 0.7985932098702754\n",
      "Value 977: 0.8043180422882977\n",
      "Value 978: 0.8100216337313491\n",
      "Value 979: 0.815701847609356\n",
      "Value 980: 0.8213563076272102\n",
      "Value 981: 0.8269823577207727\n",
      "Value 982: 0.8325770129022864\n",
      "Value 983: 0.8381368983529907\n",
      "Value 984: 0.843658173125843\n",
      "Value 985: 0.8491364334092755\n",
      "Value 986: 0.8545665882174672\n",
      "Value 987: 0.8599426972243113\n",
      "Value 988: 0.8652577555878804\n",
      "Value 989: 0.8705034028664805\n",
      "Value 990: 0.8756695204154584\n",
      "Value 991: 0.8807436600233284\n",
      "Value 992: 0.8857102081593184\n",
      "Value 993: 0.8905491186228051\n",
      "Value 994: 0.895233904742027\n",
      "Value 995: 0.899728280898223\n",
      "Value 996: 0.9039801407705325\n",
      "Value 997: 0.9079097167090182\n",
      "Value 998: 0.9113830762194022\n",
      "Value 999: 0.914139755553689\n",
      "Value 1000: 0.9155091538163628\n",
      "Value 1001: 0.9084601739202316\n",
      "Value 1002: -0.9084601739202316\n",
      "Value 1003: -0.9082315388875815\n",
      "Value 1004: -0.9079992706946916\n",
      "Value 1005: -0.9077633700220195\n",
      "Value 1006: -0.9075238375500332\n",
      "Value 1007: -0.9072806739592063\n",
      "Value 1008: -0.9070338799300294\n",
      "Value 1009: -0.9067834561430096\n",
      "Value 1010: -0.9065294032786733\n",
      "Value 1011: -0.9062717220175714\n",
      "Value 1012: -0.9060104130402814\n",
      "Value 1013: -0.9057454770274128\n",
      "Value 1014: -0.9054769146596078\n",
      "Value 1015: -0.9052047266175474\n",
      "Value 1016: -0.9049289135819503\n",
      "Value 1017: -0.9046494762335852\n",
      "Value 1018: -0.9043664152532613\n",
      "Value 1019: -0.9040797313218448\n",
      "Value 1020: -0.9037894251202544\n",
      "Value 1021: -0.9034954973294651\n",
      "Value 1022: -0.9031979486305152\n",
      "Value 1023: -0.902896779704507\n",
      "Value 1024: -0.9025919912326118\n",
      "Value 1025: -0.9022835838960699\n",
      "Value 1026: -0.9019715583762005\n",
      "Value 1027: -0.9016559153543984\n",
      "Value 1028: -0.9013366555121396\n",
      "Value 1029: -0.9010137795309883\n",
      "Value 1030: -0.900687288092595\n",
      "Value 1031: -0.9003571818787024\n",
      "Value 1032: -0.9000234615711501\n",
      "Value 1033: -0.8996861278518761\n",
      "Value 1034: -0.8993451814029192\n",
      "Value 1035: -0.8990006229064268\n",
      "Value 1036: -0.8986524530446539\n",
      "Value 1037: -0.8983006724999683\n",
      "Value 1038: -0.8979452819548539\n",
      "Value 1039: -0.8975862820919149\n",
      "Value 1040: -0.8972236735938768\n",
      "Value 1041: -0.8968574571435947\n",
      "Value 1042: -0.8964876334240505\n",
      "Value 1043: -0.8961142031183614\n",
      "Value 1044: -0.8957371669097799\n",
      "Value 1045: -0.895356525481701\n",
      "Value 1046: -0.8949722795176609\n",
      "Value 1047: -0.894584429701346\n",
      "Value 1048: -0.8941929767165903\n",
      "Value 1049: -0.893797921247384\n",
      "Value 1050: -0.8933992639778746\n",
      "Value 1051: -0.8929970055923707\n",
      "Value 1052: -0.8925911467753456\n",
      "Value 1053: -0.8921816882114397\n",
      "Value 1054: -0.8917686305854663\n",
      "Value 1055: -0.8913519745824138\n",
      "Value 1056: -0.8909317208874477\n",
      "Value 1057: -0.8905078701859184\n",
      "Value 1058: -0.890080423163359\n",
      "Value 1059: -0.8896493805054934\n",
      "Value 1060: -0.8892147428982367\n",
      "Value 1061: -0.8887765110277028\n",
      "Value 1062: -0.8883346855802015\n",
      "Value 1063: -0.8878892672422503\n",
      "Value 1064: -0.8874402567005688\n",
      "Value 1065: -0.88698765464209\n",
      "Value 1066: -0.8865314617539604\n",
      "Value 1067: -0.8860716787235416\n",
      "Value 1068: -0.8856083062384198\n",
      "Value 1069: -0.8851413449864013\n",
      "Value 1070: -0.8846707956555243\n",
      "Value 1071: -0.8841966589340569\n",
      "Value 1072: -0.8837189355105017\n",
      "Value 1073: -0.8832376260736013\n",
      "Value 1074: -0.8827527313123394\n",
      "Value 1075: -0.8822642519159465\n",
      "Value 1076: -0.881772188573902\n",
      "Value 1077: -0.8812765419759397\n",
      "Value 1078: -0.8807773128120469\n",
      "Value 1079: -0.8802745017724745\n",
      "Value 1080: -0.8797681095477359\n",
      "Value 1081: -0.8792581368286128\n",
      "Value 1082: -0.8787445843061553\n",
      "Value 1083: -0.8782274526716913\n",
      "Value 1084: -0.8777067426168264\n",
      "Value 1085: -0.8771824548334473\n",
      "Value 1086: -0.8766545900137257\n",
      "Value 1087: -0.8761231488501269\n",
      "Value 1088: -0.8755881320354026\n",
      "Value 1089: -0.8750495402626066\n",
      "Value 1090: -0.8745073742250896\n",
      "Value 1091: -0.8739616346165087\n",
      "Value 1092: -0.8734123221308266\n",
      "Value 1093: -0.872859437462319\n",
      "Value 1094: -0.8723029813055764\n",
      "Value 1095: -0.8717429543555062\n",
      "Value 1096: -0.8711793573073399\n",
      "Value 1097: -0.870612190856636\n",
      "Value 1098: -0.8700414556992823\n",
      "Value 1099: -0.8694671525314978\n",
      "Value 1100: -0.8688892820498415\n",
      "Value 1101: -0.8683078449512132\n",
      "Value 1102: -0.867722841932858\n",
      "Value 1103: -0.8671342736923676\n",
      "Value 1104: -0.8665421409276888\n",
      "Value 1105: -0.8659464443371219\n",
      "Value 1106: -0.8653471846193288\n",
      "Value 1107: -0.8647443624733362\n",
      "Value 1108: -0.8641379785985348\n",
      "Value 1109: -0.8635280336946902\n",
      "Value 1110: -0.8629145284619417\n",
      "Value 1111: -0.8622974636008081\n",
      "Value 1112: -0.8616768398121898\n",
      "Value 1113: -0.8610526577973756\n",
      "Value 1114: -0.8604249182580438\n",
      "Value 1115: -0.8597936218962672\n",
      "Value 1116: -0.8591587694145175\n",
      "Value 1117: -0.8585203615156682\n",
      "Value 1118: -0.8578783989029972\n",
      "Value 1119: -0.8572328822801961\n",
      "Value 1120: -0.8565838123513673\n",
      "Value 1121: -0.8559311898210303\n",
      "Value 1122: -0.8552750153941298\n",
      "Value 1123: -0.854615289776033\n",
      "Value 1124: -0.8539520136725364\n",
      "Value 1125: -0.8532851877898733\n",
      "Value 1126: -0.8526148128347113\n",
      "Value 1127: -0.8519408895141598\n",
      "Value 1128: -0.8512634185357761\n",
      "Value 1129: -0.8505824006075631\n",
      "Value 1130: -0.8498978364379808\n",
      "Value 1131: -0.8492097267359433\n",
      "Value 1132: -0.8485180722108283\n",
      "Value 1133: -0.8478228735724785\n",
      "Value 1134: -0.8471241315312057\n",
      "Value 1135: -0.8464218467977946\n",
      "Value 1136: -0.8457160200835097\n",
      "Value 1137: -0.8450066521000953\n",
      "Value 1138: -0.8442937435597812\n",
      "Value 1139: -0.8435772951752882\n",
      "Value 1140: -0.8428573076598311\n",
      "Value 1141: -0.8421337817271213\n",
      "Value 1142: -0.8414067180913745\n",
      "Value 1143: -0.8406761174673112\n",
      "Value 1144: -0.8399419805701627\n",
      "Value 1145: -0.8392043081156741\n",
      "Value 1146: -0.8384631008201132\n",
      "Value 1147: -0.8377183594002657\n",
      "Value 1148: -0.8369700845734469\n",
      "Value 1149: -0.8362182770575034\n",
      "Value 1150: -0.8354629375708178\n",
      "Value 1151: -0.8347040668323119\n",
      "Value 1152: -0.8339416655614517\n",
      "Value 1153: -0.8331757344782528\n",
      "Value 1154: -0.8324062743032813\n",
      "Value 1155: -0.8316332857576619\n",
      "Value 1156: -0.8308567695630802\n",
      "Value 1157: -0.8300767264417857\n",
      "Value 1158: -0.8292931571166019\n",
      "Value 1159: -0.828506062310921\n",
      "Value 1160: -0.8277154427487184\n",
      "Value 1161: -0.8269212991545503\n",
      "Value 1162: -0.8261236322535603\n",
      "Value 1163: -0.8253224427714833\n",
      "Value 1164: -0.8245177314346523\n",
      "Value 1165: -0.8237094989699978\n",
      "Value 1166: -0.8228977461050577\n",
      "Value 1167: -0.8220824735679786\n",
      "Value 1168: -0.8212636820875201\n",
      "Value 1169: -0.8204413723930613\n",
      "Value 1170: -0.8196155452146019\n",
      "Value 1171: -0.8187862012827728\n",
      "Value 1172: -0.8179533413288345\n",
      "Value 1173: -0.8171169660846824\n",
      "Value 1174: -0.8162770762828545\n",
      "Value 1175: -0.815433672656535\n",
      "Value 1176: -0.8145867559395562\n",
      "Value 1177: -0.8137363268664067\n",
      "Value 1178: -0.812882386172233\n",
      "Value 1179: -0.8120249345928471\n",
      "Value 1180: -0.8111639728647276\n",
      "Value 1181: -0.8102995017250281\n",
      "Value 1182: -0.8094315219115785\n",
      "Value 1183: -0.8085600341628926\n",
      "Value 1184: -0.8076850392181703\n",
      "Value 1185: -0.806806537817304\n",
      "Value 1186: -0.8059245307008824\n",
      "Value 1187: -0.805039018610197\n",
      "Value 1188: -0.8041500022872435\n",
      "Value 1189: -0.8032574824747295\n",
      "Value 1190: -0.8023614599160804\n",
      "Value 1191: -0.8014619353554379\n",
      "Value 1192: -0.8005589095376724\n",
      "Value 1193: -0.7996523832083852\n",
      "Value 1194: -0.79874235711391\n",
      "Value 1195: -0.7978288320013229\n",
      "Value 1196: -0.7969118086184439\n",
      "Value 1197: -0.7959912877138433\n",
      "Value 1198: -0.7950672700368463\n",
      "Value 1199: -0.7941397563375387\n",
      "Value 1200: -0.7932087473667683\n",
      "Value 1201: -0.792274243876157\n",
      "Value 1202: -0.7913362466180984\n",
      "Value 1203: -0.7903947563457665\n",
      "Value 1204: -0.7894497738131221\n",
      "Value 1205: -0.7885012997749131\n",
      "Value 1206: -0.7875493349866856\n",
      "Value 1207: -0.7865938802047836\n",
      "Value 1208: -0.7856349361863569\n",
      "Value 1209: -0.7846725036893685\n",
      "Value 1210: -0.783706583472592\n",
      "Value 1211: -0.7827371762956286\n",
      "Value 1212: -0.7817642829188982\n",
      "Value 1213: -0.780787904103659\n",
      "Value 1214: -0.7798080406120003\n",
      "Value 1215: -0.7788246932068575\n",
      "Value 1216: -0.7778378626520108\n",
      "Value 1217: -0.7768475497120935\n",
      "Value 1218: -0.7758537551525979\n",
      "Value 1219: -0.7748564797398777\n",
      "Value 1220: -0.7738557242411568\n",
      "Value 1221: -0.7728514894245315\n",
      "Value 1222: -0.7718437760589807\n",
      "Value 1223: -0.7708325849143653\n",
      "Value 1224: -0.7698179167614364\n",
      "Value 1225: -0.7687997723718445\n",
      "Value 1226: -0.7677781525181371\n",
      "Value 1227: -0.7667530579737726\n",
      "Value 1228: -0.7657244895131197\n",
      "Value 1229: -0.7646924479114652\n",
      "Value 1230: -0.7636569339450214\n",
      "Value 1231: -0.7626179483909284\n",
      "Value 1232: -0.7615754920272619\n",
      "Value 1233: -0.7605295656330378\n",
      "Value 1234: -0.7594801699882209\n",
      "Value 1235: -0.7584273058737245\n",
      "Value 1236: -0.7573709740714233\n",
      "Value 1237: -0.7563111753641529\n",
      "Value 1238: -0.7552479105357209\n",
      "Value 1239: -0.7541811803709083\n",
      "Value 1240: -0.7531109856554796\n",
      "Value 1241: -0.7520373271761842\n",
      "Value 1242: -0.750960205720766\n",
      "Value 1243: -0.7498796220779671\n",
      "Value 1244: -0.7487955770375361\n",
      "Value 1245: -0.7477080713902293\n",
      "Value 1246: -0.7466171059278244\n",
      "Value 1247: -0.7455226814431186\n",
      "Value 1248: -0.7444247987299399\n",
      "Value 1249: -0.7433234585831511\n",
      "Value 1250: -0.7422186617986564\n",
      "Value 1251: -0.7411104091734066\n",
      "Value 1252: -0.7399987015054095\n",
      "Value 1253: -0.7388835395937277\n",
      "Value 1254: -0.7377649242384933\n",
      "Value 1255: -0.7366428562409102\n",
      "Value 1256: -0.7355173364032612\n",
      "Value 1257: -0.7343883655289138\n",
      "Value 1258: -0.7332559444223261\n",
      "Value 1259: -0.7321200738890561\n",
      "Value 1260: -0.7309807547357635\n",
      "Value 1261: -0.7298379877702197\n",
      "Value 1262: -0.7286917738013142\n",
      "Value 1263: -0.7275421136390586\n",
      "Value 1264: -0.7263890080945946\n",
      "Value 1265: -0.7252324579802027\n",
      "Value 1266: -0.7240724641093044\n",
      "Value 1267: -0.7229090272964722\n",
      "Value 1268: -0.7217421483574349\n",
      "Value 1269: -0.7205718281090848\n",
      "Value 1270: -0.7193980673694849\n",
      "Value 1271: -0.7182208669578731\n",
      "Value 1272: -0.7170402276946725\n",
      "Value 1273: -0.7158561504014966\n",
      "Value 1274: -0.7146686359011549\n",
      "Value 1275: -0.713477685017663\n",
      "Value 1276: -0.7122832985762462\n",
      "Value 1277: -0.711085477403347\n",
      "Value 1278: -0.709884222326636\n",
      "Value 1279: -0.7086795341750121\n",
      "Value 1280: -0.707471413778616\n",
      "Value 1281: -0.7062598619688343\n",
      "Value 1282: -0.705044879578306\n",
      "Value 1283: -0.7038264674409309\n",
      "Value 1284: -0.7026046263918773\n",
      "Value 1285: -0.7013793572675869\n",
      "Value 1286: -0.7001506609057858\n",
      "Value 1287: -0.6989185381454883\n",
      "Value 1288: -0.6976829898270053\n",
      "Value 1289: -0.6964440167919543\n",
      "Value 1290: -0.6952016198832612\n",
      "Value 1291: -0.6939557999451732\n",
      "Value 1292: -0.6927065578232646\n",
      "Value 1293: -0.6914538943644414\n",
      "Value 1294: -0.6901978104169548\n",
      "Value 1295: -0.688938306830404\n",
      "Value 1296: -0.6876753844557439\n",
      "Value 1297: -0.6864090441452961\n",
      "Value 1298: -0.685139286752755\n",
      "Value 1299: -0.6838661131331936\n",
      "Value 1300: -0.6825895241430742\n",
      "Value 1301: -0.6813095206402547\n",
      "Value 1302: -0.6800261034839974\n",
      "Value 1303: -0.6787392735349768\n",
      "Value 1304: -0.6774490316552856\n",
      "Value 1305: -0.6761553787084462\n",
      "Value 1306: -0.674858315559416\n",
      "Value 1307: -0.6735578430745972\n",
      "Value 1308: -0.6722539621218434\n",
      "Value 1309: -0.670946673570468\n",
      "Value 1310: -0.6696359782912569\n",
      "Value 1311: -0.6683218771564673\n",
      "Value 1312: -0.667004371039847\n",
      "Value 1313: -0.6656834608166339\n",
      "Value 1314: -0.6643591473635686\n",
      "Value 1315: -0.6630314315589059\n",
      "Value 1316: -0.6617003142824138\n",
      "Value 1317: -0.6603657964153934\n",
      "Value 1318: -0.6590278788406789\n",
      "Value 1319: -0.6576865624426493\n",
      "Value 1320: -0.6563418481072406\n",
      "Value 1321: -0.6549937367219475\n",
      "Value 1322: -0.6536422291758388\n",
      "Value 1323: -0.652287326359561\n",
      "Value 1324: -0.650929029165351\n",
      "Value 1325: -0.6495673384870442\n",
      "Value 1326: -0.6482022552200815\n",
      "Value 1327: -0.6468337802615214\n",
      "Value 1328: -0.645461914510046\n",
      "Value 1329: -0.6440866588659724\n",
      "Value 1330: -0.6427080142312614\n",
      "Value 1331: -0.6413259815095282\n",
      "Value 1332: -0.639940561606046\n",
      "Value 1333: -0.6385517554277633\n",
      "Value 1334: -0.6371595638833082\n",
      "Value 1335: -0.6357639878829981\n",
      "Value 1336: -0.634365028338852\n",
      "Value 1337: -0.6329626861645974\n",
      "Value 1338: -0.631556962275682\n",
      "Value 1339: -0.6301478575892808\n",
      "Value 1340: -0.628735373024308\n",
      "Value 1341: -0.6273195095014279\n",
      "Value 1342: -0.6259002679430588\n",
      "Value 1343: -0.6244776492733937\n",
      "Value 1344: -0.6230516544183966\n",
      "Value 1345: -0.6216222843058252\n",
      "Value 1346: -0.6201895398652338\n",
      "Value 1347: -0.618753422027984\n",
      "Value 1348: -0.6173139317272569\n",
      "Value 1349: -0.6158710698980647\n",
      "Value 1350: -0.6144248374772557\n",
      "Value 1351: -0.6129752354035289\n",
      "Value 1352: -0.6115222646174455\n",
      "Value 1353: -0.6100659260614347\n",
      "Value 1354: -0.6086062206798095\n",
      "Value 1355: -0.6071431494187725\n",
      "Value 1356: -0.6056767132264319\n",
      "Value 1357: -0.604206913052807\n",
      "Value 1358: -0.6027337498498426\n",
      "Value 1359: -0.6012572245714183\n",
      "Value 1360: -0.5997773381733609\n",
      "Value 1361: -0.5982940916134545\n",
      "Value 1362: -0.5968074858514496\n",
      "Value 1363: -0.5953175218490795\n",
      "Value 1364: -0.5938242005700662\n",
      "Value 1365: -0.5923275229801349\n",
      "Value 1366: -0.5908274900470238\n",
      "Value 1367: -0.5893241027404978\n",
      "Value 1368: -0.5878173620323567\n",
      "Value 1369: -0.5863072688964495\n",
      "Value 1370: -0.5847938243086843\n",
      "Value 1371: -0.5832770292470429\n",
      "Value 1372: -0.581756884691588\n",
      "Value 1373: -0.5802333916244797\n",
      "Value 1374: -0.5787065510299854\n",
      "Value 1375: -0.5771763638944911\n",
      "Value 1376: -0.5756428312065153\n",
      "Value 1377: -0.5741059539567196\n",
      "Value 1378: -0.5725657331379234\n",
      "Value 1379: -0.5710221697451123\n",
      "Value 1380: -0.569475264775454\n",
      "Value 1381: -0.5679250192283102\n",
      "Value 1382: -0.5663714341052483\n",
      "Value 1383: -0.5648145104100528\n",
      "Value 1384: -0.5632542491487443\n",
      "Value 1385: -0.5616906513295821\n",
      "Value 1386: -0.5601237179630868\n",
      "Value 1387: -0.5585534500620483\n",
      "Value 1388: -0.5569798486415393\n",
      "Value 1389: -0.5554029147189297\n",
      "Value 1390: -0.5538226493138997\n",
      "Value 1391: -0.5522390534484514\n",
      "Value 1392: -0.550652128146926\n",
      "Value 1393: -0.549061874436013\n",
      "Value 1394: -0.5474682933447659\n",
      "Value 1395: -0.5458713859046176\n",
      "Value 1396: -0.5442711531493895\n",
      "Value 1397: -0.5426675961153116\n",
      "Value 1398: -0.5410607158410297\n",
      "Value 1399: -0.5394505133676273\n",
      "Value 1400: -0.5378369897386311\n",
      "Value 1401: -0.5362201460000331\n",
      "Value 1402: -0.5345999832002992\n",
      "Value 1403: -0.5329765023903874\n",
      "Value 1404: -0.5313497046237607\n",
      "Value 1405: -0.5297195909564016\n",
      "Value 1406: -0.5280861624468276\n",
      "Value 1407: -0.5264494201561051\n",
      "Value 1408: -0.5248093651478666\n",
      "Value 1409: -0.5231659984883222\n",
      "Value 1410: -0.5215193212462785\n",
      "Value 1411: -0.5198693344931513\n",
      "Value 1412: -0.518216039302981\n",
      "Value 1413: -0.5165594367524516\n",
      "Value 1414: -0.5148995279209011\n",
      "Value 1415: -0.5132363138903395\n",
      "Value 1416: -0.5115697957454661\n",
      "Value 1417: -0.5098999745736839\n",
      "Value 1418: -0.5082268514651156\n",
      "Value 1419: -0.5065504275126196\n",
      "Value 1420: -0.5048707038118075\n",
      "Value 1421: -0.5031876814610587\n",
      "Value 1422: -0.5015013615615376\n",
      "Value 1423: -0.4998117452172128\n",
      "Value 1424: -0.49811883353486686\n",
      "Value 1425: -0.49642262762412215\n",
      "Value 1426: -0.4947231285974508\n",
      "Value 1427: -0.49302033757019437\n",
      "Value 1428: -0.49131425566058284\n",
      "Value 1429: -0.48960488398974783\n",
      "Value 1430: -0.4878922236817425\n",
      "Value 1431: -0.4861762758635596\n",
      "Value 1432: -0.4844570416651488\n",
      "Value 1433: -0.48273452221943364\n",
      "Value 1434: -0.4810087186623291\n",
      "Value 1435: -0.4792796321327609\n",
      "Value 1436: -0.47754726377268425\n",
      "Value 1437: -0.4758116147271008\n",
      "Value 1438: -0.47407268614407666\n",
      "Value 1439: -0.4723304791747638\n",
      "Value 1440: -0.47058499497341466\n",
      "Value 1441: -0.4688362346974044\n",
      "Value 1442: -0.4670841995072494\n",
      "Value 1443: -0.4653288905666256\n",
      "Value 1444: -0.463570309042386\n",
      "Value 1445: -0.4618084561045845\n",
      "Value 1446: -0.46004333292649247\n",
      "Value 1447: -0.4582749406846182\n",
      "Value 1448: -0.4565032805587292\n",
      "Value 1449: -0.45472835373186893\n",
      "Value 1450: -0.45295016139037975\n",
      "Value 1451: -0.4511687047239223\n",
      "Value 1452: -0.44938398492549614\n",
      "Value 1453: -0.4475960031914587\n",
      "Value 1454: -0.4458047607215482\n",
      "Value 1455: -0.44401025871890526\n",
      "Value 1456: -0.4422124983900908\n",
      "Value 1457: -0.4404114809451091\n",
      "Value 1458: -0.43860720759743227\n",
      "Value 1459: -0.4367996795640143\n",
      "Value 1460: -0.4349888980653197\n",
      "Value 1461: -0.4331748643253434\n",
      "Value 1462: -0.4313575795716326\n",
      "Value 1463: -0.42953704503530676\n",
      "Value 1464: -0.4277132619510845\n",
      "Value 1465: -0.42588623155730204\n",
      "Value 1466: -0.4240559550959399\n",
      "Value 1467: -0.422222433812641\n",
      "Value 1468: -0.4203856689567391\n",
      "Value 1469: -0.41854566178127856\n",
      "Value 1470: -0.41670241354303783\n",
      "Value 1471: -0.41485592550255523\n",
      "Value 1472: -0.41300619892415047\n",
      "Value 1473: -0.41115323507595203\n",
      "Value 1474: -0.4092970352299181\n",
      "Value 1475: -0.40743760066185963\n",
      "Value 1476: -0.40557493265147254\n",
      "Value 1477: -0.4037090324823524\n",
      "Value 1478: -0.40183990144202814\n",
      "Value 1479: -0.399967540821982\n",
      "Value 1480: -0.3980919519176758\n",
      "Value 1481: -0.39621313602857994\n",
      "Value 1482: -0.39433109445819237\n",
      "Value 1483: -0.39244582851407417\n",
      "Value 1484: -0.390557339507865\n",
      "Value 1485: -0.38866562875532024\n",
      "Value 1486: -0.3867706975763269\n",
      "Value 1487: -0.3848725472949401\n",
      "Value 1488: -0.38297117923940466\n",
      "Value 1489: -0.38106659474218424\n",
      "Value 1490: -0.37915879513998735\n",
      "Value 1491: -0.3772477817737966\n",
      "Value 1492: -0.3753335559888974\n",
      "Value 1493: -0.3734161191349034\n",
      "Value 1494: -0.3714954725657878\n",
      "Value 1495: -0.3695716176399107\n",
      "Value 1496: -0.36764455572004684\n",
      "Value 1497: -0.36571428817341733\n",
      "Value 1498: -0.3637808163717189\n",
      "Value 1499: -0.36184414169115015\n",
      "Value 1500: -0.35990426551244425\n",
      "Value 1501: -0.35796118922089987\n",
      "Value 1502: -0.35601491420640885\n",
      "Value 1503: -0.3540654418634886\n",
      "Value 1504: -0.35211277359131404\n",
      "Value 1505: -0.35015691079374567\n",
      "Value 1506: -0.34819785487936344\n",
      "Value 1507: -0.346235607261498\n",
      "Value 1508: -0.34427016935826155\n",
      "Value 1509: -0.3423015425925836\n",
      "Value 1510: -0.34032972839223685\n",
      "Value 1511: -0.33835472818987666\n",
      "Value 1512: -0.33637654342307227\n",
      "Value 1513: -0.3343951755343366\n",
      "Value 1514: -0.3324106259711649\n",
      "Value 1515: -0.3304228961860647\n",
      "Value 1516: -0.3284319876365934\n",
      "Value 1517: -0.32643790178539156\n",
      "Value 1518: -0.3244406401002147\n",
      "Value 1519: -0.3224402040539734\n",
      "Value 1520: -0.32043659512476635\n",
      "Value 1521: -0.31842981479591553\n",
      "Value 1522: -0.31641986455600235\n",
      "Value 1523: -0.31440674589890577\n",
      "Value 1524: -0.3123904603238381\n",
      "Value 1525: -0.31037100933538064\n",
      "Value 1526: -0.30834839444352263\n",
      "Value 1527: -0.3063226171636988\n",
      "Value 1528: -0.30429367901682663\n",
      "Value 1529: -0.30226158152934485\n",
      "Value 1530: -0.3002263262332532\n",
      "Value 1531: -0.29818791466615113\n",
      "Value 1532: -0.296146348371275\n",
      "Value 1533: -0.29410162889754143\n",
      "Value 1534: -0.29205375779958476\n",
      "Value 1535: -0.2900027366377973\n",
      "Value 1536: -0.28794856697837434\n",
      "Value 1537: -0.2858912503933499\n",
      "Value 1538: -0.28383078846064047\n",
      "Value 1539: -0.28176718276408785\n",
      "Value 1540: -0.279700434893502\n",
      "Value 1541: -0.27763054644469976\n",
      "Value 1542: -0.27555751901955444\n",
      "Value 1543: -0.27348135422603276\n",
      "Value 1544: -0.2714020536782429\n",
      "Value 1545: -0.2693196189964781\n",
      "Value 1546: -0.2672340518072607\n",
      "Value 1547: -0.2651453537433882\n",
      "Value 1548: -0.2630535264439764\n",
      "Value 1549: -0.26095857155450974\n",
      "Value 1550: -0.25886049072688383\n",
      "Value 1551: -0.2567592856194543\n",
      "Value 1552: -0.2546549578970831\n",
      "Value 1553: -0.25254750923118824\n",
      "Value 1554: -0.2504369412997901\n",
      "Value 1555: -0.24832325578755776\n",
      "Value 1556: -0.2462064543858652\n",
      "Value 1557: -0.2440865387928342\n",
      "Value 1558: -0.24196351071338884\n",
      "Value 1559: -0.23983737185930104\n",
      "Value 1560: -0.237708123949248\n",
      "Value 1561: -0.23557576870885816\n",
      "Value 1562: -0.23344030787076714\n",
      "Value 1563: -0.23130174317466734\n",
      "Value 1564: -0.22916007636736296\n",
      "Value 1565: -0.2270153092028243\n",
      "Value 1566: -0.22486744344223808\n",
      "Value 1567: -0.22271648085406553\n",
      "Value 1568: -0.22056242321409703\n",
      "Value 1569: -0.21840527230550616\n",
      "Value 1570: -0.2162450299189087\n",
      "Value 1571: -0.21408169785241565\n",
      "Value 1572: -0.21191527791169507\n",
      "Value 1573: -0.20974577191002663\n",
      "Value 1574: -0.2075731816683597\n",
      "Value 1575: -0.20539750901537668\n",
      "Value 1576: -0.20321875578754722\n",
      "Value 1577: -0.20103692382919297\n",
      "Value 1578: -0.19885201499254668\n",
      "Value 1579: -0.19666403113781245\n",
      "Value 1580: -0.19447297413323028\n",
      "Value 1581: -0.19227884585513644\n",
      "Value 1582: -0.19008164818802975\n",
      "Value 1583: -0.18788138302463175\n",
      "Value 1584: -0.18567805226595496\n",
      "Value 1585: -0.18347165782136765\n",
      "Value 1586: -0.18126220160865564\n",
      "Value 1587: -0.17904968555409667\n",
      "Value 1588: -0.17683411159251977\n",
      "Value 1589: -0.17461548166737956\n",
      "Value 1590: -0.17239379773082086\n",
      "Value 1591: -0.17016906174375018\n",
      "Value 1592: -0.1679412756759065\n",
      "Value 1593: -0.16571044150592995\n",
      "Value 1594: -0.16347656122143545\n",
      "Value 1595: -0.1612396368190845\n",
      "Value 1596: -0.15899967030465822\n",
      "Value 1597: -0.15675666369313185\n",
      "Value 1598: -0.15451061900874902\n",
      "Value 1599: -0.15226153828509664\n",
      "Value 1600: -0.15000942356518454\n",
      "Value 1601: -0.1477542769015177\n",
      "Value 1602: -0.14549610035617627\n",
      "Value 1603: -0.14323489600089773\n",
      "Value 1604: -0.1409706659171519\n",
      "Value 1605: -0.13870341219622256\n",
      "Value 1606: -0.1364331369392897\n",
      "Value 1607: -0.1341598422575151\n",
      "Value 1608: -0.1318835302721172\n",
      "Value 1609: -0.1296042031144622\n",
      "Value 1610: -0.12732186292614822\n",
      "Value 1611: -0.12503651185908748\n",
      "Value 1612: -0.12274815207559797\n",
      "Value 1613: -0.1204567857484864\n",
      "Value 1614: -0.11816241506114156\n",
      "Value 1615: -0.11586504220762123\n",
      "Value 1616: -0.11356466939274495\n",
      "Value 1617: -0.11126129883218372\n",
      "Value 1618: -0.10895493275255297\n",
      "Value 1619: -0.10664557339150965\n",
      "Value 1620: -0.10433322299784248\n",
      "Value 1621: -0.10201788383157179\n",
      "Value 1622: -0.09969955816404297\n",
      "Value 1623: -0.09737824827802966\n",
      "Value 1624: -0.09505395646782666\n",
      "Value 1625: -0.09272668503935738\n",
      "Value 1626: -0.09039643631026778\n",
      "Value 1627: -0.08806321261003652\n",
      "Value 1628: -0.0857270162800724\n",
      "Value 1629: -0.08338784967382479\n",
      "Value 1630: -0.08104571515688608\n",
      "Value 1631: -0.0787006151071003\n",
      "Value 1632: -0.07635255191467383\n",
      "Value 1633: -0.07400152798228321\n",
      "Value 1634: -0.07164754572518656\n",
      "Value 1635: -0.06929060757133731\n",
      "Value 1636: -0.06693071596149713\n",
      "Value 1637: -0.06456787334935238\n",
      "Value 1638: -0.06220208220163004\n",
      "Value 1639: -0.059833344998214966\n",
      "Value 1640: -0.05746166423227106\n",
      "Value 1641: -0.05508704241036083\n",
      "Value 1642: -0.05270948205256776\n",
      "Value 1643: -0.050328985692621786\n",
      "Value 1644: -0.04794555587802113\n",
      "Value 1645: -0.04555919517016349\n",
      "Value 1646: -0.04316990614446936\n",
      "Value 1647: -0.04077769139051729\n",
      "Value 1648: -0.038382553512170015\n",
      "Value 1649: -0.03598449512771168\n",
      "Value 1650: -0.033583518869980455\n",
      "Value 1651: -0.031179627386504427\n",
      "Value 1652: -0.028772823339640596\n",
      "Value 1653: -0.02636310940671588\n",
      "Value 1654: -0.023950488280165216\n",
      "Value 1655: -0.021534962667676905\n",
      "Value 1656: -0.019116535292337533\n",
      "Value 1657: -0.0166952088927792\n",
      "Value 1658: -0.0142709862233254\n",
      "Value 1659: -0.011843870054144667\n",
      "Value 1660: -0.009413863171401915\n",
      "Value 1661: -0.006980968377411578\n",
      "Value 1662: -0.004545188490795826\n",
      "Value 1663: -0.002106526346641713\n",
      "Value 1664: 0.00033501520333989454\n",
      "Value 1665: 0.0027794332906492247\n",
      "Value 1666: 0.005226725029834456\n",
      "Value 1667: 0.007676887518326292\n",
      "Value 1668: 0.01012991783626771\n",
      "Value 1669: 0.012585813046343375\n",
      "Value 1670: 0.015044570193608053\n",
      "Value 1671: 0.017506186305309257\n",
      "Value 1672: 0.019970658390710216\n",
      "Value 1673: 0.022437983440912967\n",
      "Value 1674: 0.024908158428667282\n",
      "Value 1675: 0.027381180308199027\n",
      "Value 1676: 0.029857046015011934\n",
      "Value 1677: 0.03233575246570136\n",
      "Value 1678: 0.03481729655776661\n",
      "Value 1679: 0.037301675169406745\n",
      "Value 1680: 0.039788885159333764\n",
      "Value 1681: 0.042278923366564525\n",
      "Value 1682: 0.044771786610221576\n",
      "Value 1683: 0.047267471689328044\n",
      "Value 1684: 0.049765975382597194\n",
      "Value 1685: 0.052267294448223756\n",
      "Value 1686: 0.05477142562366666\n",
      "Value 1687: 0.0572783656254372\n",
      "Value 1688: 0.059788111148872336\n",
      "Value 1689: 0.062300658867919356\n",
      "Value 1690: 0.06481600543490323\n",
      "Value 1691: 0.06733414748030081\n",
      "Value 1692: 0.06985508161250753\n",
      "Value 1693: 0.07237880441760225\n",
      "Value 1694: 0.07490531245910875\n",
      "Value 1695: 0.07743460227775001\n",
      "Value 1696: 0.07996667039120786\n",
      "Value 1697: 0.08250151329386934\n",
      "Value 1698: 0.08503912745657621\n",
      "Value 1699: 0.08757950932636627\n",
      "Value 1700: 0.09012265532621716\n",
      "Value 1701: 0.09266856185477829\n",
      "Value 1702: 0.09521722528610532\n",
      "Value 1703: 0.0977686419693895\n",
      "Value 1704: 0.10032280822867934\n",
      "Value 1705: 0.10287972036260362\n",
      "Value 1706: 0.10543937464408865\n",
      "Value 1707: 0.10800176732006489\n",
      "Value 1708: 0.1105668946111828\n",
      "Value 1709: 0.11313475271151091\n",
      "Value 1710: 0.11570533778823677\n",
      "Value 1711: 0.1182786459813619\n",
      "Value 1712: 0.12085467340339329\n",
      "Value 1713: 0.12343341613902531\n",
      "Value 1714: 0.126014870244826\n",
      "Value 1715: 0.12859903174890686\n",
      "Value 1716: 0.13118589665059832\n",
      "Value 1717: 0.1337754609201156\n",
      "Value 1718: 0.13636772049821827\n",
      "Value 1719: 0.13896267129586526\n",
      "Value 1720: 0.1415603091938682\n",
      "Value 1721: 0.14416063004253504\n",
      "Value 1722: 0.1467636296613089\n",
      "Value 1723: 0.1493693038384027\n",
      "Value 1724: 0.15197764833042776\n",
      "Value 1725: 0.15458865886201573\n",
      "Value 1726: 0.1572023311254363\n",
      "Value 1727: 0.15981866078020607\n",
      "Value 1728: 0.16243764345269313\n",
      "Value 1729: 0.16505927473571558\n",
      "Value 1730: 0.16768355018813502\n",
      "Value 1731: 0.17031046533443522\n",
      "Value 1732: 0.17294001566430822\n",
      "Value 1733: 0.17557219663222057\n",
      "Value 1734: 0.17820700365698067\n",
      "Value 1735: 0.18084443212129325\n",
      "Value 1736: 0.1834844773713134\n",
      "Value 1737: 0.18612713471618736\n",
      "Value 1738: 0.1887723994275879\n",
      "Value 1739: 0.19142026673924095\n",
      "Value 1740: 0.1940707318464473\n",
      "Value 1741: 0.1967237899055948\n",
      "Value 1742: 0.19937943603365804\n",
      "Value 1743: 0.20203766530769862\n",
      "Value 1744: 0.20469847276434905\n",
      "Value 1745: 0.20736185339929164\n",
      "Value 1746: 0.21002780216672706\n",
      "Value 1747: 0.2126963139788351\n",
      "Value 1748: 0.21536738370522474\n",
      "Value 1749: 0.21804100617237726\n",
      "Value 1750: 0.2207171761630765\n",
      "Value 1751: 0.2233958884158309\n",
      "Value 1752: 0.22607713762428583\n",
      "Value 1753: 0.2287609184366265\n",
      "Value 1754: 0.23144722545496366\n",
      "Value 1755: 0.23413605323472225\n",
      "Value 1756: 0.23682739628400407\n",
      "Value 1757: 0.2395212490629458\n",
      "Value 1758: 0.24221760598307313\n",
      "Value 1759: 0.24491646140662565\n",
      "Value 1760: 0.2476178096458868\n",
      "Value 1761: 0.2503216449624919\n",
      "Value 1762: 0.25302796156672563\n",
      "Value 1763: 0.25573675361681103\n",
      "Value 1764: 0.2584480152181769\n",
      "Value 1765: 0.2611617404227198\n",
      "Value 1766: 0.2638779232280483\n",
      "Value 1767: 0.26659655757671424\n",
      "Value 1768: 0.26931763735543024\n",
      "Value 1769: 0.27204115639426985\n",
      "Value 1770: 0.2747671084658577\n",
      "Value 1771: 0.27749548728453843\n",
      "Value 1772: 0.2802262865055331\n",
      "Value 1773: 0.2829594997240833\n",
      "Value 1774: 0.285695120474568\n",
      "Value 1775: 0.28843314222961547\n",
      "Value 1776: 0.2911735583991905\n",
      "Value 1777: 0.2939163623296666\n",
      "Value 1778: 0.29666154730287947\n",
      "Value 1779: 0.2994091065351613\n",
      "Value 1780: 0.30215903317635917\n",
      "Value 1781: 0.3049113203088302\n",
      "Value 1782: 0.30766596094641635\n",
      "Value 1783: 0.3104229480334056\n",
      "Value 1784: 0.31318227444346364\n",
      "Value 1785: 0.31594393297854645\n",
      "Value 1786: 0.31870791636779766\n",
      "Value 1787: 0.321474217266413\n",
      "Value 1788: 0.32424282825448814\n",
      "Value 1789: 0.32701374183584503\n",
      "Value 1790: 0.3297869504368234\n",
      "Value 1791: 0.33256244640505905\n",
      "Value 1792: 0.33534022200823127\n",
      "Value 1793: 0.3381202694327833\n",
      "Value 1794: 0.3409025807826176\n",
      "Value 1795: 0.343687148077764\n",
      "Value 1796: 0.34647396325301777\n",
      "Value 1797: 0.34926301815655\n",
      "Value 1798: 0.35205430454848763\n",
      "Value 1799: 0.35484781409946115\n",
      "Value 1800: 0.35764353838912677\n",
      "Value 1801: 0.36044146890464923\n",
      "Value 1802: 0.3632415970391533\n",
      "Value 1803: 0.3660439140901463\n",
      "Value 1804: 0.3688484112578983\n",
      "Value 1805: 0.37165507964379063\n",
      "Value 1806: 0.37446391024862835\n",
      "Value 1807: 0.37727489397091163\n",
      "Value 1808: 0.3800880216050686\n",
      "Value 1809: 0.3829032838396515\n",
      "Value 1810: 0.3857206712554876\n",
      "Value 1811: 0.3885401743237907\n",
      "Value 1812: 0.39136178340422517\n",
      "Value 1813: 0.3941854887429299\n",
      "Value 1814: 0.39701128047049516\n",
      "Value 1815: 0.3998391485998866\n",
      "Value 1816: 0.402669083024328\n",
      "Value 1817: 0.4055010735151305\n",
      "Value 1818: 0.4083351097194668\n",
      "Value 1819: 0.41117118115809953\n",
      "Value 1820: 0.4140092772230477\n",
      "Value 1821: 0.41684938717519904\n",
      "Value 1822: 0.41969150014186746\n",
      "Value 1823: 0.4225356051142853\n",
      "Value 1824: 0.42538169094503764\n",
      "Value 1825: 0.42822974634543076\n",
      "Value 1826: 0.431079759882797\n",
      "Value 1827: 0.4339317199777301\n",
      "Value 1828: 0.436785614901252\n",
      "Value 1829: 0.43964143277190626\n",
      "Value 1830: 0.4424991615527823\n",
      "Value 1831: 0.44535878904845383\n",
      "Value 1832: 0.44822030290184783\n",
      "Value 1833: 0.45108369059102743\n",
      "Value 1834: 0.45394893942589165\n",
      "Value 1835: 0.45681603654478564\n",
      "Value 1836: 0.4596849689110285\n",
      "Value 1837: 0.4625557233093389\n",
      "Value 1838: 0.46542828634217503\n",
      "Value 1839: 0.46830264442596464\n",
      "Value 1840: 0.4711787837872479\n",
      "Value 1841: 0.4740566904586968\n",
      "Value 1842: 0.4769363502750412\n",
      "Value 1843: 0.4798177488688744\n",
      "Value 1844: 0.48270087166634007\n",
      "Value 1845: 0.4855857038827088\n",
      "Value 1846: 0.48847223051781385\n",
      "Value 1847: 0.4913604363513751\n",
      "Value 1848: 0.49425030593817687\n",
      "Value 1849: 0.49714182360311054\n",
      "Value 1850: 0.5000349734360774\n",
      "Value 1851: 0.5029297392867399\n",
      "Value 1852: 0.5058261047591164\n",
      "Value 1853: 0.5087240532060223\n",
      "Value 1854: 0.5116235677233436\n",
      "Value 1855: 0.5145246311441358\n",
      "Value 1856: 0.5174272260325499\n",
      "Value 1857: 0.5203313346775718\n",
      "Value 1858: 0.5232369390865689\n",
      "Value 1859: 0.526144020978643\n",
      "Value 1860: 0.5290525617777725\n",
      "Value 1861: 0.5319625426057395\n",
      "Value 1862: 0.5348739442748436\n",
      "Value 1863: 0.5377867472803708\n",
      "Value 1864: 0.5407009317928378\n",
      "Value 1865: 0.5436164776499735\n",
      "Value 1866: 0.5465333643484502\n",
      "Value 1867: 0.5494515710353391\n",
      "Value 1868: 0.55237107649929\n",
      "Value 1869: 0.555291859161415\n",
      "Value 1870: 0.5582138970658715\n",
      "Value 1871: 0.5611371678701249\n",
      "Value 1872: 0.5640616488348843\n",
      "Value 1873: 0.5669873168136947\n",
      "Value 1874: 0.5699141482421682\n",
      "Value 1875: 0.5728421191268439\n",
      "Value 1876: 0.57577120503366\n",
      "Value 1877: 0.578701381076012\n",
      "Value 1878: 0.5816326219024008\n",
      "Value 1879: 0.5845649016836209\n",
      "Value 1880: 0.5874981940994987\n",
      "Value 1881: 0.5904324723251443\n",
      "Value 1882: 0.5933677090166969\n",
      "Value 1883: 0.59630387629654\n",
      "Value 1884: 0.5992409457379728\n",
      "Value 1885: 0.6021788883492942\n",
      "Value 1886: 0.605117674557288\n",
      "Value 1887: 0.6080572741900763\n",
      "Value 1888: 0.6109976564592994\n",
      "Value 1889: 0.6139387899416178\n",
      "Value 1890: 0.6168806425594671\n",
      "Value 1891: 0.6198231815610633\n",
      "Value 1892: 0.6227663734995987\n",
      "Value 1893: 0.6257101842115956\n",
      "Value 1894: 0.628654578794383\n",
      "Value 1895: 0.6315995215826372\n",
      "Value 1896: 0.634544976123949\n",
      "Value 1897: 0.6374909051533675\n",
      "Value 1898: 0.640437270566859\n",
      "Value 1899: 0.6433840333936335\n",
      "Value 1900: 0.6463311537672719\n",
      "Value 1901: 0.6492785908955907\n",
      "Value 1902: 0.6522263030291846\n",
      "Value 1903: 0.6551742474285542\n",
      "Value 1904: 0.6581223803297672\n",
      "Value 1905: 0.6610706569085494\n",
      "Value 1906: 0.6640190312427245\n",
      "Value 1907: 0.6669674562729176\n",
      "Value 1908: 0.6699158837614023\n",
      "Value 1909: 0.6728642642490064\n",
      "Value 1910: 0.6758125470099391\n",
      "Value 1911: 0.6787606800044375\n",
      "Value 1912: 0.6817086098290848\n",
      "Value 1913: 0.6846562816646667\n",
      "Value 1914: 0.6876036392214137\n",
      "Value 1915: 0.6905506246814612\n",
      "Value 1916: 0.6934971786383615\n",
      "Value 1917: 0.6964432400334514\n",
      "Value 1918: 0.6993887460888779\n",
      "Value 1919: 0.702333632237062\n",
      "Value 1920: 0.7052778320463613\n",
      "Value 1921: 0.7082212771426892\n",
      "Value 1922: 0.7111638971268044\n",
      "Value 1923: 0.714105619486977\n",
      "Value 1924: 0.7170463695067213\n",
      "Value 1925: 0.7199860701672218\n",
      "Value 1926: 0.7229246420441167\n",
      "Value 1927: 0.7258620031981847\n",
      "Value 1928: 0.7287980690595213\n",
      "Value 1929: 0.7317327523047126\n",
      "Value 1930: 0.7346659627264761\n",
      "Value 1931: 0.7375976070952011\n",
      "Value 1932: 0.740527589011753\n",
      "Value 1933: 0.7434558087508731\n",
      "Value 1934: 0.746382163094403\n",
      "Value 1935: 0.749306545153533\n",
      "Value 1936: 0.7522288441791617\n",
      "Value 1937: 0.7551489453593815\n",
      "Value 1938: 0.7580667296030046\n",
      "Value 1939: 0.7609820733079258\n",
      "Value 1940: 0.7638948481130039\n",
      "Value 1941: 0.7668049206319981\n",
      "Value 1942: 0.7697121521679456\n",
      "Value 1943: 0.7726163984061869\n",
      "Value 1944: 0.7755175090840437\n",
      "Value 1945: 0.7784153276349468\n",
      "Value 1946: 0.7813096908045412\n",
      "Value 1947: 0.7842004282360142\n",
      "Value 1948: 0.7870873620215766\n",
      "Value 1949: 0.7899703062166364\n",
      "Value 1950: 0.792849066312805\n",
      "Value 1951: 0.7957234386653613\n",
      "Value 1952: 0.7985932098702755\n",
      "Value 1953: 0.8014581560852219\n",
      "Value 1954: 0.8043180422882981\n",
      "Value 1955: 0.8071726214672892\n",
      "Value 1956: 0.8100216337313495\n",
      "Value 1957: 0.8128648053357921\n",
      "Value 1958: 0.8157018476093563\n",
      "Value 1959: 0.8185324557717228\n",
      "Value 1960: 0.8213563076272107\n",
      "Value 1961: 0.8241730621183926\n",
      "Value 1962: 0.8269823577207727\n",
      "Value 1963: 0.8297838106566107\n",
      "Value 1964: 0.8325770129022864\n",
      "Value 1965: 0.8353615299592108\n",
      "Value 1966: 0.8381368983529907\n",
      "Value 1967: 0.8409026228191391\n",
      "Value 1968: 0.843658173125843\n",
      "Value 1969: 0.8464029804747801\n",
      "Value 1970: 0.8491364334092755\n",
      "Value 1971: 0.8518578731446289\n",
      "Value 1972: 0.8545665882174672\n",
      "Value 1973: 0.857261808328456\n",
      "Value 1974: 0.8599426972243113\n",
      "Value 1975: 0.8626083444290067\n",
      "Value 1976: 0.8652577555878804\n",
      "Value 1977: 0.8678898411287574\n",
      "Value 1978: 0.8705034028664805\n",
      "Value 1979: 0.8730971180750313\n",
      "Value 1980: 0.8756695204154584\n",
      "Value 1981: 0.8782189769249478\n",
      "Value 1982: 0.8807436600233284\n",
      "Value 1983: 0.8832415131495608\n",
      "Value 1984: 0.8857102081593184\n",
      "Value 1985: 0.8881470919295033\n",
      "Value 1986: 0.8905491186228051\n",
      "Value 1987: 0.8929127625986452\n",
      "Value 1988: 0.895233904742027\n",
      "Value 1989: 0.8975076815543946\n",
      "Value 1990: 0.899728280898223\n",
      "Value 1991: 0.9018886593361912\n",
      "Value 1992: 0.9039801407705325\n",
      "Value 1993: 0.9059918290430851\n",
      "Value 1994: 0.9079097167090182\n",
      "Value 1995: 0.9097152723434719\n",
      "Value 1996: 0.9113830762194022\n",
      "Value 1997: 0.9128765787383412\n",
      "Value 1998: 0.914139755553689\n",
      "Value 1999: 0.9150784181920585\n",
      "Value 2000: 0.9155091538163628\n",
      "Value 2001: 0.9149590922643053\n",
      "Value 2002: 0.9084601739202316\n"
     ]
    }
   ],
   "source": [
    "extracted_values = [value[0].item() for value in total_cost1]\n",
    "\n",
    "# Print extracted values\n",
    "for i, value in enumerate(extracted_values):\n",
    "    print(f\"Value {i+1}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9a9324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value 1: 0.9084601739202316\n",
      "Value 2: 0.8737680081724576\n",
      "Value 3: 0.8511017458050737\n",
      "Value 4: 0.8305031633060763\n",
      "Value 5: 0.8110185901739627\n",
      "Value 6: 0.7922765962681697\n",
      "Value 7: 0.7740856838220107\n",
      "Value 8: 0.7563315027634337\n",
      "Value 9: 0.7389391627799855\n",
      "Value 10: 0.721856376940048\n",
      "Value 11: 0.7050448795783057\n",
      "Value 12: 0.6884756345980237\n",
      "Value 13: 0.6721259677296457\n",
      "Value 14: 0.6559777544179635\n",
      "Value 15: 0.640016223541314\n",
      "Value 16: 0.6242291386952579\n",
      "Value 17: 0.6086062206798091\n",
      "Value 18: 0.5931387295102835\n",
      "Value 19: 0.5778191551023434\n",
      "Value 20: 0.5626409839110994\n",
      "Value 21: 0.5475985198570692\n",
      "Value 22: 0.5326867448259138\n",
      "Value 23: 0.5179012085265604\n",
      "Value 24: 0.503237940473477\n",
      "Value 25: 0.48869337887839587\n",
      "Value 26: 0.4742643126319033\n",
      "Value 27: 0.45994783353645663\n",
      "Value 28: 0.44574129665342216\n",
      "Value 29: 0.4316422871350902\n",
      "Value 30: 0.41764859228628237\n",
      "Value 31: 0.40375817787814905\n",
      "Value 32: 0.38996916794598263\n",
      "Value 33: 0.3762798274620142\n",
      "Value 34: 0.3626885473963709\n",
      "Value 35: 0.34919383177411484\n",
      "Value 36: 0.335794286410308\n",
      "Value 37: 0.3224886090634276\n",
      "Value 38: 0.30927558079376016\n",
      "Value 39: 0.2961540583503955\n",
      "Value 40: 0.28312296744029136\n",
      "Value 41: 0.27018129675695673\n",
      "Value 42: 0.25732809266597956\n",
      "Value 43: 0.2445624544606788\n",
      "Value 44: 0.23188353011446633\n",
      "Value 45: 0.21929051246739334\n",
      "Value 46: 0.20678263579352496\n",
      "Value 47: 0.1943591727033887\n",
      "Value 48: 0.1820194313420863\n",
      "Value 49: 0.1697627528490815\n",
      "Value 50: 0.157588509050191\n",
      "Value 51: 0.14549610035617627\n",
      "Value 52: 0.13348495384561576\n",
      "Value 53: 0.12155452151252016\n",
      "Value 54: 0.10970427866161037\n",
      "Value 55: 0.09793372243619586\n",
      "Value 56: 0.08624237046539573\n",
      "Value 57: 0.07462975961901475\n",
      "Value 58: 0.06309544485967006\n",
      "Value 59: 0.05163899818298612\n",
      "Value 60: 0.04026000763766263\n",
      "Value 61: 0.02895807641811432\n",
      "Value 62: 0.017732822023158235\n",
      "Value 63: 0.006583875474919676\n",
      "Value 64: -0.004489119407277975\n",
      "Value 65: -0.015486506682753032\n",
      "Value 66: -0.02640861891924634\n",
      "Value 67: -0.03725577778047601\n",
      "Value 68: -0.04802829457490665\n",
      "Value 69: -0.05872647076883847\n",
      "Value 70: -0.06935059846665476\n",
      "Value 71: -0.07990096086078025\n",
      "Value 72: -0.09037783265368032\n",
      "Value 73: -0.10078148045401808\n",
      "Value 74: -0.11111216314889594\n",
      "Value 75: -0.12137013225395354\n",
      "Value 76: -0.13155563224291428\n",
      "Value 77: -0.14166890085806766\n",
      "Value 78: -0.1517101694030208\n",
      "Value 79: -0.16167966301897402\n",
      "Value 80: -0.1715776009456348\n",
      "Value 81: -0.18140419676782465\n",
      "Value 82: -0.19115965864874257\n",
      "Value 83: -0.20084418955075517\n",
      "Value 84: -0.2104579874445462\n",
      "Value 85: -0.2200012455073604\n",
      "Value 86: -0.2294741523110554\n",
      "Value 87: -0.2388768920005903\n",
      "Value 88: -0.24820964446355376\n",
      "Value 89: -0.25747258549127977\n",
      "Value 90: -0.26666588693206883\n",
      "Value 91: -0.27578971683698755\n",
      "Value 92: -0.2848442395986808\n",
      "Value 93: -0.2938296160836191\n",
      "Value 94: -0.3027460037581513\n",
      "Value 95: -0.3115935568087389\n",
      "Value 96: -0.32037242625667195\n",
      "Value 97: -0.3290827600676079\n",
      "Value 98: -0.3377247032562053\n",
      "Value 99: -0.3462983979861201\n",
      "Value 100: -0.35480398366564064\n",
      "Value 101: -0.36324159703915354\n",
      "Value 102: -0.37161137227471785\n",
      "Value 103: -0.37991344104790725\n",
      "Value 104: -0.3881479326221365\n",
      "Value 105: -0.3963149739256531\n",
      "Value 106: -0.4044146896253705\n",
      "Value 107: -0.4124472021976817\n",
      "Value 108: -0.4204126319964349\n",
      "Value 109: -0.4283110973181912\n",
      "Value 110: -0.43614271446490493\n",
      "Value 111: -0.4439075978041577\n",
      "Value 112: -0.4516058598270556\n",
      "Value 113: -0.45923761120391227\n",
      "Value 114: -0.4668029608378143\n",
      "Value 115: -0.4743020159161719\n",
      "Value 116: -0.4817348819603505\n",
      "Value 117: -0.48910166287347495\n",
      "Value 118: -0.49640246098648017\n",
      "Value 119: -0.5036373771024985\n",
      "Value 120: -0.5108065105396549\n",
      "Value 121: -0.5179099591723384\n",
      "Value 122: -0.5249478194710279\n",
      "Value 123: -0.5319201865407175\n",
      "Value 124: -0.5388271541580241\n",
      "Value 125: -0.5456688148070142\n",
      "Value 126: -0.552445259713823\n",
      "Value 127: -0.5591565788801055\n",
      "Value 128: -0.5658028611153677\n",
      "Value 129: -0.5723841940682383\n",
      "Value 130: -0.578900664256706\n",
      "Value 131: -0.5853523570973851\n",
      "Value 132: -0.5917393569338328\n",
      "Value 133: -0.5980617470639664\n",
      "Value 134: -0.6043196097666066\n",
      "Value 135: -0.6105130263272035\n",
      "Value 136: -0.6166420770627467\n",
      "Value 137: -0.6227068413459222\n",
      "Value 138: -0.6287073976285187\n",
      "Value 139: -0.6346438234641396\n",
      "Value 140: -0.6405161955302163\n",
      "Value 141: -0.646324589649387\n",
      "Value 142: -0.6520690808102252\n",
      "Value 143: -0.6577497431873769\n",
      "Value 144: -0.6633666501611063\n",
      "Value 145: -0.6689198743362783\n",
      "Value 146: -0.6744094875608104\n",
      "Value 147: -0.6798355609435887\n",
      "Value 148: -0.6851981648718992\n",
      "Value 149: -0.6904973690283551\n",
      "Value 150: -0.6957332424073781\n",
      "Value 151: -0.7009058533312156\n",
      "Value 152: -0.7060152694655331\n",
      "Value 153: -0.7110615578345836\n",
      "Value 154: -0.716044784835975\n",
      "Value 155: -0.7209650162550496\n",
      "Value 156: -0.7258223172788897\n",
      "Value 157: -0.7306167525099532\n",
      "Value 158: -0.7353483859793695\n",
      "Value 159: -0.7400172811598853\n",
      "Value 160: -0.7446235009784992\n",
      "Value 161: -0.7491671078287656\n",
      "Value 162: -0.7536481635828028\n",
      "Value 163: -0.7580667296030044\n",
      "Value 164: -0.762422866753465\n",
      "Value 165: -0.7667166354111316\n",
      "Value 166: -0.7709480954766889\n",
      "Value 167: -0.7751173063851876\n",
      "Value 168: -0.7792243271164208\n",
      "Value 169: -0.7832692162050645\n",
      "Value 170: -0.7872520317505808\n",
      "Value 171: -0.7911728314268984\n",
      "Value 172: -0.7950316724918705\n",
      "Value 173: -0.7988286117965302\n",
      "Value 174: -0.8025637057941317\n",
      "Value 175: -0.806237010548999\n",
      "Value 176: -0.8098485817451822\n",
      "Value 177: -0.8133984746949281\n",
      "Value 178: -0.8168867443469691\n",
      "Value 179: -0.8203134452946432\n",
      "Value 180: -0.8236786317838365\n",
      "Value 181: -0.8269823577207727\n",
      "Value 182: -0.8302246766796375\n",
      "Value 183: -0.83340564191005\n",
      "Value 184: -0.8365253063443921\n",
      "Value 185: -0.8395837226049809\n",
      "Value 186: -0.8425809430111184\n",
      "Value 187: -0.8455170195859918\n",
      "Value 188: -0.8483920040634491\n",
      "Value 189: -0.8512059478946475\n",
      "Value 190: -0.8539589022545795\n",
      "Value 191: -0.8566509180484762\n",
      "Value 192: -0.8592820459180981\n",
      "Value 193: -0.8618523362479125\n",
      "Value 194: -0.8643618391711649\n",
      "Value 195: -0.86681060457584\n",
      "Value 196: -0.8691986821105258\n",
      "Value 197: -0.8715261211901764\n",
      "Value 198: -0.8737929710017793\n",
      "Value 199: -0.875999280509931\n",
      "Value 200: -0.8781450984623203\n",
      "Value 201: -0.880230473395128\n",
      "Value 202: -0.8822554536383388\n",
      "Value 203: -0.884220087320972\n",
      "Value 204: -0.8861244223762371\n",
      "Value 205: -0.8879685065466079\n",
      "Value 206: -0.8897523873888229\n",
      "Value 207: -0.8914761122788181\n",
      "Value 208: -0.893139728416584\n",
      "Value 209: -0.8947432828309623\n",
      "Value 210: -0.896286822384371\n",
      "Value 211: -0.8977703937774717\n",
      "Value 212: -0.8991940435537706\n",
      "Value 213: -0.9005578181041699\n",
      "Value 214: -0.9018617636714508\n",
      "Value 215: -0.9031059263547103\n",
      "Value 216: -0.9042903521137426\n",
      "Value 217: -0.905415086773368\n",
      "Value 218: -0.9064801760277136\n",
      "Value 219: -0.9074856654444464\n",
      "Value 220: -0.9084316004689627\n",
      "Value 221: -0.9093180264285283\n",
      "Value 222: -0.9101449885363828\n",
      "Value 223: -0.9109125318957983\n",
      "Value 224: -0.9116207015040992\n",
      "Value 225: -0.9122695422566488\n",
      "Value 226: -0.9128590989507963\n",
      "Value 227: -0.9133894162897862\n",
      "Value 228: -0.9138605388866439\n",
      "Value 229: -0.9142725112680204\n",
      "Value 230: -0.9146253778780121\n",
      "Value 231: -0.9149191830819503\n",
      "Value 232: -0.9151539711701638\n",
      "Value 233: -0.915329786361714\n",
      "Value 234: -0.91544667280811\n",
      "Value 235: -0.9155046745969943\n",
      "Value 236: -0.9155038357558096\n",
      "Value 237: -0.9154442002554489\n",
      "Value 238: -0.9153258120138761\n",
      "Value 239: -0.91514871489974\n",
      "Value 240: -0.9149129527359637\n",
      "Value 241: -0.9146185693033233\n",
      "Value 242: -0.9142656083440068\n",
      "Value 243: -0.9138541135651669\n",
      "Value 244: -0.9133841286424552\n",
      "Value 245: -0.9128556972235504\n",
      "Value 246: -0.9122688629316761\n",
      "Value 247: -0.911623669369108\n",
      "Value 248: -0.9109201601206774\n",
      "Value 249: -0.9101583787572667\n",
      "Value 250: -0.9093383688392995\n",
      "Value 251: -0.9084601739202316\n",
      "Value 252: -0.9075238375500332\n",
      "Value 253: -0.9065294032786733\n",
      "Value 254: -0.9054769146596078\n",
      "Value 255: -0.9043664152532613\n",
      "Value 256: -0.9031979486305152\n",
      "Value 257: -0.9019715583762005\n",
      "Value 258: -0.900687288092595\n",
      "Value 259: -0.8993451814029192\n",
      "Value 260: -0.8979452819548539\n",
      "Value 261: -0.8964876334240505\n",
      "Value 262: -0.8949722795176609\n",
      "Value 263: -0.8933992639778746\n",
      "Value 264: -0.8917686305854663\n",
      "Value 265: -0.890080423163359\n",
      "Value 266: -0.8883346855802015\n",
      "Value 267: -0.8865314617539604\n",
      "Value 268: -0.8846707956555243\n",
      "Value 269: -0.8827527313123394\n",
      "Value 270: -0.8807773128120467\n",
      "Value 271: -0.8787445843061553\n",
      "Value 272: -0.8766545900137257\n",
      "Value 273: -0.8745073742250895\n",
      "Value 274: -0.8723029813055763\n",
      "Value 275: -0.8700414556992822\n",
      "Value 276: -0.867722841932858\n",
      "Value 277: -0.8653471846193288\n",
      "Value 278: -0.8629145284619418\n",
      "Value 279: -0.8604249182580437\n",
      "Value 280: -0.8578783989029972\n",
      "Value 281: -0.8552750153941296\n",
      "Value 282: -0.8526148128347111\n",
      "Value 283: -0.8498978364379808\n",
      "Value 284: -0.8471241315312057\n",
      "Value 285: -0.8442937435597808\n",
      "Value 286: -0.8414067180913742\n",
      "Value 287: -0.8384631008201131\n",
      "Value 288: -0.8354629375708175\n",
      "Value 289: -0.8324062743032813\n",
      "Value 290: -0.8292931571166019\n",
      "Value 291: -0.8261236322535603\n",
      "Value 292: -0.8228977461050577\n",
      "Value 293: -0.819615545214602\n",
      "Value 294: -0.8162770762828546\n",
      "Value 295: -0.8128823861722334\n",
      "Value 296: -0.8094315219115785\n",
      "Value 297: -0.8059245307008824\n",
      "Value 298: -0.8023614599160804\n",
      "Value 299: -0.79874235711391\n",
      "Value 300: -0.7950672700368463\n",
      "Value 301: -0.7913362466180984\n",
      "Value 302: -0.7875493349866856\n",
      "Value 303: -0.7837065834725923\n",
      "Value 304: -0.7798080406120003\n",
      "Value 305: -0.7758537551525979\n",
      "Value 306: -0.7718437760589807\n",
      "Value 307: -0.7677781525181374\n",
      "Value 308: -0.7636569339450214\n",
      "Value 309: -0.7594801699882209\n",
      "Value 310: -0.7552479105357208\n",
      "Value 311: -0.750960205720766\n",
      "Value 312: -0.7466171059278244\n",
      "Value 313: -0.7422186617986564\n",
      "Value 314: -0.7377649242384933\n",
      "Value 315: -0.7332559444223261\n",
      "Value 316: -0.7286917738013142\n",
      "Value 317: -0.7240724641093044\n",
      "Value 318: -0.7193980673694849\n",
      "Value 319: -0.7146686359011549\n",
      "Value 320: -0.709884222326636\n",
      "Value 321: -0.705044879578306\n",
      "Value 322: -0.7001506609057858\n",
      "Value 323: -0.6952016198832612\n",
      "Value 324: -0.6901978104169548\n",
      "Value 325: -0.685139286752755\n",
      "Value 326: -0.6800261034839973\n",
      "Value 327: -0.674858315559416\n",
      "Value 328: -0.6696359782912567\n",
      "Value 329: -0.6643591473635686\n",
      "Value 330: -0.6590278788406787\n",
      "Value 331: -0.6536422291758388\n",
      "Value 332: -0.6482022552200815\n",
      "Value 333: -0.6427080142312614\n",
      "Value 334: -0.6371595638833079\n",
      "Value 335: -0.631556962275682\n",
      "Value 336: -0.6259002679430588\n",
      "Value 337: -0.6201895398652338\n",
      "Value 338: -0.6144248374772557\n",
      "Value 339: -0.6086062206798091\n",
      "Value 340: -0.6027337498498426\n",
      "Value 341: -0.5968074858514493\n",
      "Value 342: -0.5908274900470238\n",
      "Value 343: -0.5847938243086838\n",
      "Value 344: -0.578706551029985\n",
      "Value 345: -0.5725657331379231\n",
      "Value 346: -0.5663714341052477\n",
      "Value 347: -0.5601237179630868\n",
      "Value 348: -0.5538226493138996\n",
      "Value 349: -0.5474682933447659\n",
      "Value 350: -0.5410607158410297\n",
      "Value 351: -0.5345999832002992\n",
      "Value 352: -0.5280861624468272\n",
      "Value 353: -0.5215193212462785\n",
      "Value 354: -0.5148995279209011\n",
      "Value 355: -0.5082268514651156\n",
      "Value 356: -0.501501361561538\n",
      "Value 357: -0.4947231285974508\n",
      "Value 358: -0.4878922236817425\n",
      "Value 359: -0.4810087186623291\n",
      "Value 360: -0.4740726861440771\n",
      "Value 361: -0.4670841995072494\n",
      "Value 362: -0.46004333292649247\n",
      "Value 363: -0.45295016139038\n",
      "Value 364: -0.4458047607215482\n",
      "Value 365: -0.43860720759743244\n",
      "Value 366: -0.4313575795716326\n",
      "Value 367: -0.4240559550959399\n",
      "Value 368: -0.41670241354303783\n",
      "Value 369: -0.4092970352299181\n",
      "Value 370: -0.4018399014420286\n",
      "Value 371: -0.39433109445819237\n",
      "Value 372: -0.3867706975763269\n",
      "Value 373: -0.37915879513998735\n",
      "Value 374: -0.3714954725657878\n",
      "Value 375: -0.3637808163717189\n",
      "Value 376: -0.35601491420640885\n",
      "Value 377: -0.34819785487936344\n",
      "Value 378: -0.34032972839223685\n",
      "Value 379: -0.3324106259711649\n",
      "Value 380: -0.3244406401002147\n",
      "Value 381: -0.31641986455600235\n",
      "Value 382: -0.30834839444352263\n",
      "Value 383: -0.3002263262332532\n",
      "Value 384: -0.29205375779958476\n",
      "Value 385: -0.28383078846064047\n",
      "Value 386: -0.27555751901955444\n",
      "Value 387: -0.2672340518072607\n",
      "Value 388: -0.25886049072688383\n",
      "Value 389: -0.2504369412997901\n",
      "Value 390: -0.24196351071338884\n",
      "Value 391: -0.23344030787076714\n",
      "Value 392: -0.22486744344223808\n",
      "Value 393: -0.2162450299189087\n",
      "Value 394: -0.2075731816683597\n",
      "Value 395: -0.19885201499254668\n",
      "Value 396: -0.1900816481880292\n",
      "Value 397: -0.18126220160865547\n",
      "Value 398: -0.17239379773082053\n",
      "Value 399: -0.16347656122143528\n",
      "Value 400: -0.15451061900874857\n",
      "Value 401: -0.14549610035617616\n",
      "Value 402: -0.1364331369392895\n",
      "Value 403: -0.12732186292614783\n",
      "Value 404: -0.11816241506114133\n",
      "Value 405: -0.10895493275255286\n",
      "Value 406: -0.09969955816404275\n",
      "Value 407: -0.09039643631026761\n",
      "Value 408: -0.08104571515688574\n",
      "Value 409: -0.07164754572518639\n",
      "Value 410: -0.06220208220162987\n",
      "Value 411: -0.05270948205256759\n",
      "Value 412: -0.04316990614446914\n",
      "Value 413: -0.03358351886998018\n",
      "Value 414: -0.023950488280164883\n",
      "Value 415: -0.014270986223325177\n",
      "Value 416: -0.004545188490795493\n",
      "Value 417: 0.005226725029834733\n",
      "Value 418: 0.015044570193608053\n",
      "Value 419: 0.024908158428666893\n",
      "Value 420: 0.034817296557766386\n",
      "Value 421: 0.044771786610221076\n",
      "Value 422: 0.05477142562366655\n",
      "Value 423: 0.06481600543490279\n",
      "Value 424: 0.07490531245910853\n",
      "Value 425: 0.08503912745657582\n",
      "Value 426: 0.09521722528610521\n",
      "Value 427: 0.10543937464408865\n",
      "Value 428: 0.11570533778823677\n",
      "Value 429: 0.126014870244826\n",
      "Value 430: 0.13636772049821827\n",
      "Value 431: 0.1467636296613089\n",
      "Value 432: 0.1572023311254363\n",
      "Value 433: 0.16768355018813502\n",
      "Value 434: 0.17820700365698067\n",
      "Value 435: 0.1887723994275879\n",
      "Value 436: 0.19937943603365804\n",
      "Value 437: 0.21002780216672706\n",
      "Value 438: 0.2207171761630765\n",
      "Value 439: 0.23144722545496366\n",
      "Value 440: 0.24221760598307313\n",
      "Value 441: 0.25302796156672563\n",
      "Value 442: 0.2638779232280483\n",
      "Value 443: 0.2747671084658577\n",
      "Value 444: 0.285695120474568\n",
      "Value 445: 0.29666154730287947\n",
      "Value 446: 0.30766596094641635\n",
      "Value 447: 0.31870791636779766\n",
      "Value 448: 0.3297869504368234\n",
      "Value 449: 0.3409025807826176\n",
      "Value 450: 0.35205430454848763\n",
      "Value 451: 0.3632415970391533\n",
      "Value 452: 0.37446391024862835\n",
      "Value 453: 0.3857206712554876\n",
      "Value 454: 0.39701128047049516\n",
      "Value 455: 0.4083351097194668\n",
      "Value 456: 0.41969150014186746\n",
      "Value 457: 0.431079759882797\n",
      "Value 458: 0.4424991615527823\n",
      "Value 459: 0.45394893942589165\n",
      "Value 460: 0.46542828634217526\n",
      "Value 461: 0.47693635027504155\n",
      "Value 462: 0.4884722305178141\n",
      "Value 463: 0.5000349734360776\n",
      "Value 464: 0.5116235677233436\n",
      "Value 465: 0.5232369390865691\n",
      "Value 466: 0.5348739442748439\n",
      "Value 467: 0.5465333643484505\n",
      "Value 468: 0.5582138970658719\n",
      "Value 469: 0.5699141482421684\n",
      "Value 470: 0.5816326219024011\n",
      "Value 471: 0.5933677090166973\n",
      "Value 472: 0.6051176745572884\n",
      "Value 473: 0.6168806425594674\n",
      "Value 474: 0.6286545787943834\n",
      "Value 475: 0.6404372705668592\n",
      "Value 476: 0.6522263030291848\n",
      "Value 477: 0.664019031242725\n",
      "Value 478: 0.6758125470099394\n",
      "Value 479: 0.6876036392214141\n",
      "Value 480: 0.6993887460888782\n",
      "Value 481: 0.711163897126804\n",
      "Value 482: 0.7229246420441164\n",
      "Value 483: 0.734665962726476\n",
      "Value 484: 0.7463821630944028\n",
      "Value 485: 0.7580667296030043\n",
      "Value 486: 0.7697121521679453\n",
      "Value 487: 0.7813096908045407\n",
      "Value 488: 0.7928490663128049\n",
      "Value 489: 0.8043180422882977\n",
      "Value 490: 0.815701847609356\n",
      "Value 491: 0.8269823577207727\n",
      "Value 492: 0.8381368983529907\n",
      "Value 493: 0.8491364334092755\n",
      "Value 494: 0.8599426972243113\n",
      "Value 495: 0.8705034028664805\n",
      "Value 496: 0.8807436600233284\n",
      "Value 497: 0.8905491186228051\n",
      "Value 498: 0.899728280898223\n",
      "Value 499: 0.9079097167090182\n",
      "Value 500: 0.914139755553689\n",
      "Value 501: 0.9084601739202316\n",
      "Value 502: -0.9082315388875815\n",
      "Value 503: -0.9077633700220195\n",
      "Value 504: -0.9072806739592063\n",
      "Value 505: -0.9067834561430096\n",
      "Value 506: -0.9062717220175714\n",
      "Value 507: -0.9057454770274128\n",
      "Value 508: -0.9052047266175474\n",
      "Value 509: -0.9046494762335852\n",
      "Value 510: -0.9040797313218448\n",
      "Value 511: -0.9034954973294651\n",
      "Value 512: -0.902896779704507\n",
      "Value 513: -0.9022835838960699\n",
      "Value 514: -0.9016559153543984\n",
      "Value 515: -0.9010137795309883\n",
      "Value 516: -0.9003571818787024\n",
      "Value 517: -0.8996861278518761\n",
      "Value 518: -0.8990006229064268\n",
      "Value 519: -0.8983006724999683\n",
      "Value 520: -0.8975862820919149\n",
      "Value 521: -0.8968574571435947\n",
      "Value 522: -0.8961142031183614\n",
      "Value 523: -0.895356525481701\n",
      "Value 524: -0.894584429701346\n",
      "Value 525: -0.893797921247384\n",
      "Value 526: -0.8929970055923707\n",
      "Value 527: -0.8921816882114397\n",
      "Value 528: -0.8913519745824138\n",
      "Value 529: -0.8905078701859184\n",
      "Value 530: -0.8896493805054934\n",
      "Value 531: -0.8887765110277028\n",
      "Value 532: -0.8878892672422503\n",
      "Value 533: -0.88698765464209\n",
      "Value 534: -0.8860716787235416\n",
      "Value 535: -0.8851413449864013\n",
      "Value 536: -0.8841966589340569\n",
      "Value 537: -0.8832376260736013\n",
      "Value 538: -0.8822642519159465\n",
      "Value 539: -0.8812765419759397\n",
      "Value 540: -0.8802745017724745\n",
      "Value 541: -0.8792581368286128\n",
      "Value 542: -0.8782274526716913\n",
      "Value 543: -0.8771824548334473\n",
      "Value 544: -0.8761231488501269\n",
      "Value 545: -0.8750495402626066\n",
      "Value 546: -0.8739616346165087\n",
      "Value 547: -0.872859437462319\n",
      "Value 548: -0.8717429543555062\n",
      "Value 549: -0.870612190856636\n",
      "Value 550: -0.8694671525314978\n",
      "Value 551: -0.8683078449512132\n",
      "Value 552: -0.8671342736923676\n",
      "Value 553: -0.8659464443371219\n",
      "Value 554: -0.8647443624733362\n",
      "Value 555: -0.8635280336946902\n",
      "Value 556: -0.8622974636008081\n",
      "Value 557: -0.8610526577973756\n",
      "Value 558: -0.8597936218962672\n",
      "Value 559: -0.8585203615156682\n",
      "Value 560: -0.8572328822801961\n",
      "Value 561: -0.8559311898210303\n",
      "Value 562: -0.854615289776033\n",
      "Value 563: -0.8532851877898733\n",
      "Value 564: -0.8519408895141598\n",
      "Value 565: -0.8505824006075631\n",
      "Value 566: -0.8492097267359433\n",
      "Value 567: -0.8478228735724785\n",
      "Value 568: -0.8464218467977946\n",
      "Value 569: -0.8450066521000953\n",
      "Value 570: -0.8435772951752882\n",
      "Value 571: -0.8421337817271213\n",
      "Value 572: -0.8406761174673112\n",
      "Value 573: -0.8392043081156741\n",
      "Value 574: -0.8377183594002657\n",
      "Value 575: -0.8362182770575034\n",
      "Value 576: -0.8347040668323119\n",
      "Value 577: -0.8331757344782528\n",
      "Value 578: -0.8316332857576619\n",
      "Value 579: -0.8300767264417857\n",
      "Value 580: -0.828506062310921\n",
      "Value 581: -0.8269212991545503\n",
      "Value 582: -0.8253224427714833\n",
      "Value 583: -0.8237094989699978\n",
      "Value 584: -0.8220824735679786\n",
      "Value 585: -0.8204413723930613\n",
      "Value 586: -0.8187862012827728\n",
      "Value 587: -0.8171169660846824\n",
      "Value 588: -0.815433672656535\n",
      "Value 589: -0.8137363268664067\n",
      "Value 590: -0.8120249345928471\n",
      "Value 591: -0.8102995017250281\n",
      "Value 592: -0.8085600341628926\n",
      "Value 593: -0.806806537817304\n",
      "Value 594: -0.805039018610197\n",
      "Value 595: -0.8032574824747295\n",
      "Value 596: -0.8014619353554379\n",
      "Value 597: -0.7996523832083852\n",
      "Value 598: -0.7978288320013229\n",
      "Value 599: -0.7959912877138433\n",
      "Value 600: -0.7941397563375387\n",
      "Value 601: -0.792274243876157\n",
      "Value 602: -0.7903947563457665\n",
      "Value 603: -0.7885012997749131\n",
      "Value 604: -0.7865938802047836\n",
      "Value 605: -0.7846725036893685\n",
      "Value 606: -0.7827371762956286\n",
      "Value 607: -0.780787904103659\n",
      "Value 608: -0.7788246932068575\n",
      "Value 609: -0.7768475497120935\n",
      "Value 610: -0.7748564797398777\n",
      "Value 611: -0.7728514894245315\n",
      "Value 612: -0.7708325849143653\n",
      "Value 613: -0.7687997723718445\n",
      "Value 614: -0.7667530579737726\n",
      "Value 615: -0.7646924479114652\n",
      "Value 616: -0.7626179483909284\n",
      "Value 617: -0.7605295656330378\n",
      "Value 618: -0.7584273058737245\n",
      "Value 619: -0.7563111753641529\n",
      "Value 620: -0.7541811803709083\n",
      "Value 621: -0.7520373271761842\n",
      "Value 622: -0.7498796220779671\n",
      "Value 623: -0.7477080713902293\n",
      "Value 624: -0.7455226814431186\n",
      "Value 625: -0.7433234585831511\n",
      "Value 626: -0.7411104091734066\n",
      "Value 627: -0.7388835395937277\n",
      "Value 628: -0.7366428562409102\n",
      "Value 629: -0.7343883655289138\n",
      "Value 630: -0.7321200738890561\n",
      "Value 631: -0.7298379877702197\n",
      "Value 632: -0.7275421136390586\n",
      "Value 633: -0.7252324579802027\n",
      "Value 634: -0.7229090272964722\n",
      "Value 635: -0.7205718281090848\n",
      "Value 636: -0.7182208669578731\n",
      "Value 637: -0.7158561504014966\n",
      "Value 638: -0.713477685017663\n",
      "Value 639: -0.711085477403347\n",
      "Value 640: -0.7086795341750121\n",
      "Value 641: -0.7062598619688343\n",
      "Value 642: -0.7038264674409309\n",
      "Value 643: -0.7013793572675869\n",
      "Value 644: -0.6989185381454883\n",
      "Value 645: -0.6964440167919543\n",
      "Value 646: -0.6939557999451732\n",
      "Value 647: -0.6914538943644414\n",
      "Value 648: -0.688938306830404\n",
      "Value 649: -0.6864090441452961\n",
      "Value 650: -0.6838661131331936\n",
      "Value 651: -0.6813095206402547\n",
      "Value 652: -0.6787392735349768\n",
      "Value 653: -0.6761553787084462\n",
      "Value 654: -0.6735578430745972\n",
      "Value 655: -0.670946673570468\n",
      "Value 656: -0.6683218771564673\n",
      "Value 657: -0.6656834608166339\n",
      "Value 658: -0.6630314315589059\n",
      "Value 659: -0.6603657964153934\n",
      "Value 660: -0.6576865624426493\n",
      "Value 661: -0.6549937367219475\n",
      "Value 662: -0.652287326359561\n",
      "Value 663: -0.6495673384870442\n",
      "Value 664: -0.6468337802615214\n",
      "Value 665: -0.6440866588659724\n",
      "Value 666: -0.6413259815095282\n",
      "Value 667: -0.6385517554277633\n",
      "Value 668: -0.6357639878829981\n",
      "Value 669: -0.6329626861645974\n",
      "Value 670: -0.6301478575892808\n",
      "Value 671: -0.6273195095014279\n",
      "Value 672: -0.6244776492733937\n",
      "Value 673: -0.6216222843058252\n",
      "Value 674: -0.618753422027984\n",
      "Value 675: -0.6158710698980647\n",
      "Value 676: -0.6129752354035289\n",
      "Value 677: -0.6100659260614347\n",
      "Value 678: -0.6071431494187725\n",
      "Value 679: -0.604206913052807\n",
      "Value 680: -0.6012572245714183\n",
      "Value 681: -0.5982940916134545\n",
      "Value 682: -0.5953175218490795\n",
      "Value 683: -0.5923275229801349\n",
      "Value 684: -0.5893241027404978\n",
      "Value 685: -0.5863072688964495\n",
      "Value 686: -0.5832770292470429\n",
      "Value 687: -0.5802333916244797\n",
      "Value 688: -0.5771763638944911\n",
      "Value 689: -0.5741059539567196\n",
      "Value 690: -0.5710221697451123\n",
      "Value 691: -0.5679250192283102\n",
      "Value 692: -0.5648145104100528\n",
      "Value 693: -0.5616906513295821\n",
      "Value 694: -0.5585534500620483\n",
      "Value 695: -0.5554029147189297\n",
      "Value 696: -0.5522390534484514\n",
      "Value 697: -0.549061874436013\n",
      "Value 698: -0.5458713859046176\n",
      "Value 699: -0.5426675961153116\n",
      "Value 700: -0.5394505133676273\n",
      "Value 701: -0.5362201460000331\n",
      "Value 702: -0.5329765023903874\n",
      "Value 703: -0.5297195909564016\n",
      "Value 704: -0.5264494201561051\n",
      "Value 705: -0.5231659984883222\n",
      "Value 706: -0.5198693344931513\n",
      "Value 707: -0.5165594367524516\n",
      "Value 708: -0.5132363138903395\n",
      "Value 709: -0.5098999745736839\n",
      "Value 710: -0.5065504275126196\n",
      "Value 711: -0.5031876814610587\n",
      "Value 712: -0.4998117452172128\n",
      "Value 713: -0.49642262762412215\n",
      "Value 714: -0.49302033757019437\n",
      "Value 715: -0.48960488398974783\n",
      "Value 716: -0.4861762758635596\n",
      "Value 717: -0.48273452221943364\n",
      "Value 718: -0.4792796321327609\n",
      "Value 719: -0.4758116147271008\n",
      "Value 720: -0.4723304791747638\n",
      "Value 721: -0.4688362346974044\n",
      "Value 722: -0.4653288905666256\n",
      "Value 723: -0.4618084561045845\n",
      "Value 724: -0.4582749406846182\n",
      "Value 725: -0.45472835373186893\n",
      "Value 726: -0.4511687047239223\n",
      "Value 727: -0.4475960031914587\n",
      "Value 728: -0.44401025871890526\n",
      "Value 729: -0.4404114809451091\n",
      "Value 730: -0.4367996795640143\n",
      "Value 731: -0.4331748643253434\n",
      "Value 732: -0.42953704503530676\n",
      "Value 733: -0.42588623155730204\n",
      "Value 734: -0.422222433812641\n",
      "Value 735: -0.41854566178127856\n",
      "Value 736: -0.41485592550255523\n",
      "Value 737: -0.41115323507595203\n",
      "Value 738: -0.40743760066185963\n",
      "Value 739: -0.4037090324823524\n",
      "Value 740: -0.399967540821982\n",
      "Value 741: -0.39621313602857994\n",
      "Value 742: -0.39244582851407417\n",
      "Value 743: -0.38866562875532024\n",
      "Value 744: -0.3848725472949401\n",
      "Value 745: -0.38106659474218424\n",
      "Value 746: -0.3772477817737966\n",
      "Value 747: -0.3734161191349034\n",
      "Value 748: -0.3695716176399107\n",
      "Value 749: -0.36571428817341733\n",
      "Value 750: -0.36184414169115015\n",
      "Value 751: -0.35796118922089987\n",
      "Value 752: -0.3540654418634886\n",
      "Value 753: -0.35015691079374567\n",
      "Value 754: -0.346235607261498\n",
      "Value 755: -0.3423015425925836\n",
      "Value 756: -0.33835472818987666\n",
      "Value 757: -0.3343951755343366\n",
      "Value 758: -0.3304228961860647\n",
      "Value 759: -0.32643790178539156\n",
      "Value 760: -0.3224402040539734\n",
      "Value 761: -0.31842981479591553\n",
      "Value 762: -0.31440674589890577\n",
      "Value 763: -0.31037100933538064\n",
      "Value 764: -0.3063226171636988\n",
      "Value 765: -0.30226158152934485\n",
      "Value 766: -0.29818791466615113\n",
      "Value 767: -0.29410162889754143\n",
      "Value 768: -0.2900027366377973\n",
      "Value 769: -0.2858912503933499\n",
      "Value 770: -0.28176718276408785\n",
      "Value 771: -0.27763054644469976\n",
      "Value 772: -0.27348135422603276\n",
      "Value 773: -0.2693196189964781\n",
      "Value 774: -0.2651453537433882\n",
      "Value 775: -0.26095857155450974\n",
      "Value 776: -0.2567592856194543\n",
      "Value 777: -0.25254750923118824\n",
      "Value 778: -0.24832325578755776\n",
      "Value 779: -0.2440865387928342\n",
      "Value 780: -0.23983737185930104\n",
      "Value 781: -0.23557576870885816\n",
      "Value 782: -0.23130174317466734\n",
      "Value 783: -0.2270153092028243\n",
      "Value 784: -0.22271648085406553\n",
      "Value 785: -0.21840527230550616\n",
      "Value 786: -0.21408169785241565\n",
      "Value 787: -0.20974577191002663\n",
      "Value 788: -0.20539750901537668\n",
      "Value 789: -0.20103692382919297\n",
      "Value 790: -0.19666403113781245\n",
      "Value 791: -0.19227884585513644\n",
      "Value 792: -0.18788138302463175\n",
      "Value 793: -0.18347165782136765\n",
      "Value 794: -0.17904968555409667\n",
      "Value 795: -0.17461548166737956\n",
      "Value 796: -0.17016906174375018\n",
      "Value 797: -0.16571044150592995\n",
      "Value 798: -0.1612396368190845\n",
      "Value 799: -0.15675666369313185\n",
      "Value 800: -0.15226153828509664\n",
      "Value 801: -0.1477542769015177\n",
      "Value 802: -0.14323489600089773\n",
      "Value 803: -0.13870341219622256\n",
      "Value 804: -0.1341598422575151\n",
      "Value 805: -0.1296042031144622\n",
      "Value 806: -0.12503651185908748\n",
      "Value 807: -0.1204567857484864\n",
      "Value 808: -0.11586504220762123\n",
      "Value 809: -0.11126129883218372\n",
      "Value 810: -0.10664557339150965\n",
      "Value 811: -0.10201788383157179\n",
      "Value 812: -0.09737824827802966\n",
      "Value 813: -0.09272668503935738\n",
      "Value 814: -0.08806321261003652\n",
      "Value 815: -0.08338784967382479\n",
      "Value 816: -0.0787006151071003\n",
      "Value 817: -0.07400152798228321\n",
      "Value 818: -0.06929060757133731\n",
      "Value 819: -0.06456787334935238\n",
      "Value 820: -0.059833344998214966\n",
      "Value 821: -0.05508704241036083\n",
      "Value 822: -0.050328985692621786\n",
      "Value 823: -0.04555919517016349\n",
      "Value 824: -0.04077769139051729\n",
      "Value 825: -0.03598449512771168\n",
      "Value 826: -0.031179627386504427\n",
      "Value 827: -0.02636310940671588\n",
      "Value 828: -0.021534962667676905\n",
      "Value 829: -0.0166952088927792\n",
      "Value 830: -0.011843870054144667\n",
      "Value 831: -0.006980968377411578\n",
      "Value 832: -0.002106526346641713\n",
      "Value 833: 0.0027794332906492247\n",
      "Value 834: 0.007676887518326292\n",
      "Value 835: 0.012585813046343375\n",
      "Value 836: 0.017506186305309257\n",
      "Value 837: 0.022437983440912967\n",
      "Value 838: 0.027381180308199027\n",
      "Value 839: 0.03233575246570136\n",
      "Value 840: 0.037301675169406745\n",
      "Value 841: 0.042278923366564525\n",
      "Value 842: 0.047267471689328044\n",
      "Value 843: 0.052267294448223756\n",
      "Value 844: 0.0572783656254372\n",
      "Value 845: 0.062300658867919356\n",
      "Value 846: 0.06733414748030081\n",
      "Value 847: 0.07237880441760225\n",
      "Value 848: 0.07743460227775001\n",
      "Value 849: 0.08250151329386934\n",
      "Value 850: 0.08757950932636627\n",
      "Value 851: 0.09266856185477829\n",
      "Value 852: 0.0977686419693895\n",
      "Value 853: 0.10287972036260362\n",
      "Value 854: 0.10800176732006489\n",
      "Value 855: 0.11313475271151091\n",
      "Value 856: 0.1182786459813619\n",
      "Value 857: 0.12343341613902531\n",
      "Value 858: 0.12859903174890686\n",
      "Value 859: 0.1337754609201156\n",
      "Value 860: 0.13896267129586526\n",
      "Value 861: 0.14416063004253504\n",
      "Value 862: 0.1493693038384027\n",
      "Value 863: 0.15458865886201573\n",
      "Value 864: 0.15981866078020607\n",
      "Value 865: 0.16505927473571558\n",
      "Value 866: 0.17031046533443522\n",
      "Value 867: 0.17557219663222057\n",
      "Value 868: 0.18084443212129325\n",
      "Value 869: 0.18612713471618736\n",
      "Value 870: 0.19142026673924095\n",
      "Value 871: 0.1967237899055948\n",
      "Value 872: 0.20203766530769862\n",
      "Value 873: 0.20736185339929164\n",
      "Value 874: 0.2126963139788351\n",
      "Value 875: 0.21804100617237726\n",
      "Value 876: 0.2233958884158309\n",
      "Value 877: 0.2287609184366265\n",
      "Value 878: 0.23413605323472225\n",
      "Value 879: 0.2395212490629458\n",
      "Value 880: 0.24491646140662565\n",
      "Value 881: 0.2503216449624919\n",
      "Value 882: 0.25573675361681103\n",
      "Value 883: 0.2611617404227198\n",
      "Value 884: 0.26659655757671424\n",
      "Value 885: 0.27204115639426985\n",
      "Value 886: 0.27749548728453843\n",
      "Value 887: 0.2829594997240833\n",
      "Value 888: 0.28843314222961547\n",
      "Value 889: 0.2939163623296666\n",
      "Value 890: 0.2994091065351613\n",
      "Value 891: 0.3049113203088302\n",
      "Value 892: 0.3104229480334056\n",
      "Value 893: 0.31594393297854645\n",
      "Value 894: 0.321474217266413\n",
      "Value 895: 0.32701374183584503\n",
      "Value 896: 0.33256244640505905\n",
      "Value 897: 0.3381202694327833\n",
      "Value 898: 0.343687148077764\n",
      "Value 899: 0.34926301815655\n",
      "Value 900: 0.35484781409946115\n",
      "Value 901: 0.36044146890464923\n",
      "Value 902: 0.3660439140901463\n",
      "Value 903: 0.37165507964379063\n",
      "Value 904: 0.37727489397091163\n",
      "Value 905: 0.3829032838396515\n",
      "Value 906: 0.3885401743237907\n",
      "Value 907: 0.3941854887429299\n",
      "Value 908: 0.3998391485998866\n",
      "Value 909: 0.4055010735151305\n",
      "Value 910: 0.41117118115809953\n",
      "Value 911: 0.41684938717519904\n",
      "Value 912: 0.4225356051142853\n",
      "Value 913: 0.42822974634543076\n",
      "Value 914: 0.4339317199777301\n",
      "Value 915: 0.43964143277190626\n",
      "Value 916: 0.44535878904845383\n",
      "Value 917: 0.45108369059102743\n",
      "Value 918: 0.45681603654478564\n",
      "Value 919: 0.4625557233093389\n",
      "Value 920: 0.46830264442596464\n",
      "Value 921: 0.4740566904586968\n",
      "Value 922: 0.4798177488688744\n",
      "Value 923: 0.4855857038827088\n",
      "Value 924: 0.4913604363513751\n",
      "Value 925: 0.49714182360311054\n",
      "Value 926: 0.5029297392867399\n",
      "Value 927: 0.5087240532060223\n",
      "Value 928: 0.5145246311441358\n",
      "Value 929: 0.5203313346775718\n",
      "Value 930: 0.526144020978643\n",
      "Value 931: 0.5319625426057395\n",
      "Value 932: 0.5377867472803708\n",
      "Value 933: 0.5436164776499735\n",
      "Value 934: 0.5494515710353391\n",
      "Value 935: 0.555291859161415\n",
      "Value 936: 0.5611371678701249\n",
      "Value 937: 0.5669873168136947\n",
      "Value 938: 0.5728421191268439\n",
      "Value 939: 0.578701381076012\n",
      "Value 940: 0.5845649016836209\n",
      "Value 941: 0.5904324723251443\n",
      "Value 942: 0.59630387629654\n",
      "Value 943: 0.6021788883492942\n",
      "Value 944: 0.6080572741900763\n",
      "Value 945: 0.6139387899416178\n",
      "Value 946: 0.6198231815610633\n",
      "Value 947: 0.6257101842115956\n",
      "Value 948: 0.6315995215826372\n",
      "Value 949: 0.6374909051533675\n",
      "Value 950: 0.6433840333936335\n",
      "Value 951: 0.6492785908955907\n",
      "Value 952: 0.6551742474285542\n",
      "Value 953: 0.6610706569085494\n",
      "Value 954: 0.6669674562729176\n",
      "Value 955: 0.6728642642490064\n",
      "Value 956: 0.6787606800044375\n",
      "Value 957: 0.6846562816646667\n",
      "Value 958: 0.6905506246814612\n",
      "Value 959: 0.6964432400334514\n",
      "Value 960: 0.702333632237062\n",
      "Value 961: 0.7082212771426892\n",
      "Value 962: 0.714105619486977\n",
      "Value 963: 0.7199860701672218\n",
      "Value 964: 0.7258620031981847\n",
      "Value 965: 0.7317327523047126\n",
      "Value 966: 0.7375976070952011\n",
      "Value 967: 0.7434558087508731\n",
      "Value 968: 0.749306545153533\n",
      "Value 969: 0.7551489453593815\n",
      "Value 970: 0.7609820733079258\n",
      "Value 971: 0.7668049206319981\n",
      "Value 972: 0.7726163984061869\n",
      "Value 973: 0.7784153276349468\n",
      "Value 974: 0.7842004282360142\n",
      "Value 975: 0.7899703062166364\n",
      "Value 976: 0.7957234386653613\n",
      "Value 977: 0.8014581560852219\n",
      "Value 978: 0.8071726214672892\n",
      "Value 979: 0.8128648053357921\n",
      "Value 980: 0.8185324557717228\n",
      "Value 981: 0.8241730621183926\n",
      "Value 982: 0.8297838106566107\n",
      "Value 983: 0.8353615299592108\n",
      "Value 984: 0.8409026228191391\n",
      "Value 985: 0.8464029804747801\n",
      "Value 986: 0.8518578731446289\n",
      "Value 987: 0.857261808328456\n",
      "Value 988: 0.8626083444290067\n",
      "Value 989: 0.8678898411287574\n",
      "Value 990: 0.8730971180750313\n",
      "Value 991: 0.8782189769249478\n",
      "Value 992: 0.8832415131495608\n",
      "Value 993: 0.8881470919295033\n",
      "Value 994: 0.8929127625986452\n",
      "Value 995: 0.8975076815543946\n",
      "Value 996: 0.9018886593361912\n",
      "Value 997: 0.9059918290430851\n",
      "Value 998: 0.9097152723434719\n",
      "Value 999: 0.9128765787383412\n",
      "Value 1000: 0.9150784181920585\n",
      "Value 1001: 0.9149590922643053\n"
     ]
    }
   ],
   "source": [
    "extracted_values = [value[0].item() for value in total_cost1]\n",
    "\n",
    "# Extract every second item to get 1001 items\n",
    "extracted_values_1001 = extracted_values[::2]\n",
    "\n",
    "# Print the extracted values\n",
    "for i, value in enumerate(extracted_values_1001):\n",
    "    print(f\"Value {i+1}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33bb27b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example data (replace with your actual data)\n",
    "x_values = np.linspace(0, 2, 100)  # Example x values\n",
    "extracted_values_1001 = np.random.rand(100) * 10  # Example extracted values (scaled for visualization)\n",
    "\n",
    "# Reshape extracted_values_1001 to be a column vector (needed for imshow)\n",
    "extracted_values_1001 = extracted_values_1001[:, np.newaxis]\n",
    "\n",
    "# Plotting the 2D color map with smooth gradient\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(extracted_values_1001.T, extent=[np.min(x_values), np.max(x_values), np.min(extracted_values_1001), np.max(extracted_values_1001)], aspect='auto', cmap='viridis', interpolation='bicubic')\n",
    "plt.colorbar(label='Extracted Values')\n",
    "plt.title('2D Color Map of Extracted Values vs x')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Index')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Print lengths for debugging\n",
    "print(len(x_values))\n",
    "print(len(extracted_values_1001))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7121d1b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m extracted_values_1001 \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtotal_cost1\u001b[49m\u001b[43m]\u001b[49m[::\u001b[38;5;241m2\u001b[39m]\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.float64' object is not iterable"
     ]
    }
   ],
   "source": [
    "extracted_values_1001 = [value[0].item() for value in total_cost1][::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5267db5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cost = -529.1261937325775\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "num_qubits = 6\n",
    "dev = qml.device(\"default.qubit\", wires=num_qubits)\n",
    "@qml.qnode(dev)\n",
    "def variational_circuit1(params, num_layers, variable_values):\n",
    "\n",
    "    # feature maps\n",
    "    for i, value in enumerate(variable_values):\n",
    "        qml.RY(2 * np.arccos(np.clip(value, -1, 1)), wires=i)\n",
    "\n",
    "    # paramterized variational circuits\n",
    "    for layer in range(num_layers):\n",
    "        for i in range(len(variable_values)):\n",
    "            qml.RZ(params[layer, i, 0], wires=i)\n",
    "            qml.RX(params[layer, i, 1], wires=i)\n",
    "        for i in range(len(variable_values) - 1):\n",
    "            qml.CNOT(wires=[i, i + 1])\n",
    "\n",
    "    \n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(len(variable_values))]\n",
    "global fn_values        \n",
    "# Function to calculate the cost fucntion\n",
    "def cost_fn1(params, num_layers, variable_values):\n",
    "    fn_values =[] \n",
    "    total_cost = 0\n",
    "    num_iterations = variable_values.shape[1] if len(variable_values.shape) > 1 else variable_values.shape[0]\n",
    "    for i in range(num_iterations):\n",
    "        selected_values = variable_values[:, i] if len(variable_values.shape) > 1 else variable_values\n",
    "        outputs = variational_circuit1(params, num_layers, selected_values)\n",
    "        fn_values.append(outputs)\n",
    "        # print(outputs,'      ',selected_values)\n",
    "        cost = np.sum(outputs)\n",
    "        total_cost += cost\n",
    "    return total_cost\n",
    "\n",
    "num_layers = 4\n",
    "params = np.full((num_layers, num_qubits, 2), 0.10861666144252709)\n",
    "\n",
    "# To choose variables to encode\n",
    "chosen_variables = input(f\"Choose the variables to encode from the list {variable_names} (comma-separated): \")\n",
    "chosen_variables = [v.strip() for v in chosen_variables.split(',')]\n",
    "selected_values = np.concatenate([variable_values[v] for v in chosen_variables], axis=0)\n",
    "\n",
    "# To reshape\n",
    "selected_values = selected_values.reshape(1, -1)\n",
    "total_cost1 = cost_fn1(params, num_layers, selected_values)\n",
    "print(f\"Total cost = {total_cost1}\")\n",
    "# print(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6c675a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('t', 1, 0.0), ('t', 2, 0.0), ('x', 1, 0.0), ('x', 2, 0.0)]\n"
     ]
    }
   ],
   "source": [
    "shift = 3.14\n",
    "derivatives1 = compute_derivatives_for_variables(cost_fn1, variable_names, variable_values, shift, num_layers, params)\n",
    "print(derivatives1)\n",
    "# The first value is the variable, then the order of differentiation, and final value is the derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f8d6bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e507cfbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2021a9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d67e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
